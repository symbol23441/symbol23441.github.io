{"pages":[],"posts":[{"title":"C++刷题笔记","text":"该文是在刷C++算法题，对常用方法、模版进行记录 7、常用头文件12345678910#include &lt;cmath&gt; // abs(double/float)#include &lt;algorithm&gt; // max, min#include&lt;bits/stdc++&gt; //万能头文件using namespace std;int main(){ return 0;} 1、Vector123456789101112131415vector&lt;&gt; vec;//长度vec.size();//添加vec.push_back();//删除vec.erase(vec.begin()+index)//排序 std::sort(nums.begin(), nums.end());sort(height.begin(),height.end()，greater&lt;int&gt;()); //从大到小 我不知道vector最终会多大，但我也不能通过push_back ,因为可能还未加入索引为0,1，2，就需要先记录索引为3 的数据。我在做算法题是如何写代码更好 方法1 resize() 动态补位. 方法2（更高效）：配合 reserve() + resize() 123456std::vector&lt;int&gt; v;// v.reserve(1000); // 如果预计大概会用到1000个if (index &gt;= v.size()) { v.resize(index + 1);}v[index] = x; 2、hashmap123456map&lt;int,int&gt; map;map['xx'] = 1;map.find(x) != map.end(); 3、set1234567891011121314151617set&lt;int&gt; s;# 添加s.insert(1);#c查询s.cout(1);#删除s.erase(1);# 判空s.empty();# 遍历for(int v: s);s.size(); 4、string1234string s;# 获取子串s.substr(start_index,length); //to string int num = 42; double pi = 3.14159; std::string s1 = std::to_string(num); std::string s2 = std::to_string(pi); 5、priority_queue12345678910111213141516171819202122232425262728// 默认为大根堆std::priority_queue&lt;T&gt; q;//推入q.push(x);//获取auto x = q.top();//弹出q.pop();//要实现小根对可以如下定义操作符&lt;struct Status { int val; ListNode *ptr; bool operator &lt; (const Status &amp;rhs) const { return val &gt; rhs.val; // 小的在前，最小堆 }};//另一种小跟堆写法std::priority_queue&lt; int, // ① 存储的元素类型（Type） std::vector&lt;int&gt;, // ② 底层容器类型（Container） std::greater&lt;int&gt; // ③ 比较器（Compare）&gt; minHeap; 7、struct &lt;12345678910111213141516struct project { int index; int capital; int profits; project(int i, int c, int p) { index = i; capital = c; profits = p; } // 自定义比较运算符（用于排序等） bool operator &lt; (const project&amp; other) const { return capital &lt; other.capital; }}; 注意： 1、在 C++ 中，struct 默认就会把类型名暴露出来，不需要像 C 那样加 typedef。 2、this 是指针用-&gt;，此处可省略 6.pair使用std::vector&lt;std::pair&lt;int, int&gt;&gt; v = {{2, 3}, {1, 5}, {1, 2}, {2, 1}}; std::sort(v.begin(), v.end()); // 默认排序：先比 first，再比 second std::sort(v.begin(), v.end(), [](const auto&amp; a, const auto&amp; b) { return a.second &lt; b.second; }); 算法模版1、广度优先、层序遍历123456789101112131415161718192021222324void bfs(int start) { queue&lt;int&gt; q; // 队列，存储待访问的节点 vector&lt;bool&gt; visited(n, false); // 标记数组，防止重复访问 vector&lt;int&gt; distance(n, -1); // 可选，记录 start 到每个点的距离 q.push(start); visited[start] = true; //vector&lt;int&gt; distance(n, -1); // 可选，记录 start 到每个点的距离 while (!q.empty()) { int u = q.front(); q.pop(); // 访问操作 //添加后续节点 for (auto v : graph[u]) { // 遍历 u 的邻居 if (!visited[v]) { visited[v] = true; //distance[v] = distance[u] + 1; // 如果需要层数或者最短路径 q.push(v); } } }} 1234567891011121314151617//树的层序遍历（带层数）void levelOrderWithLevel(TreeNode* root) { if (!root) return; queue&lt;pair&lt;TreeNode*, int&gt;&gt; q; q.push({root, 0}); // 根节点是第0层 while (!q.empty()) { auto [node, level] = q.front(); q.pop(); cout &lt;&lt; &quot;Node value: &quot; &lt;&lt; node-&gt;val &lt;&lt; &quot;, Level: &quot; &lt;&lt; level &lt;&lt; endl; if (node-&gt;left) q.push({node-&gt;left, level + 1}); if (node-&gt;right) q.push({node-&gt;right, level + 1}); }} 2、建图 有向边 123456789101112131415vector&lt;double&gt; calcEquation(vector&lt;vector&lt;string&gt;&gt;&amp; equations, vector&lt;double&gt;&amp; values, vector&lt;vector&lt;string&gt;&gt;&amp; queries) {int nvars = 0;unordered_map&lt;string,int&gt; v_map;for(auto e:equations){ if(v_map.find(e[0])==v_map.end())v_map[e[0]]=nvars++; if(v_map.find(e[1])==v_map.end())v_map[e[1]]=nvars++;}vector&lt;vector&lt;pair&lt;int,double&gt;&gt;&gt; edges(nvars);for(int i=0;i&lt;equations.size();i++){ auto e = equations[i]; int x = v_map[e[0]],y=v_map[e[1]]; edges[x].push_back(pair(y,values[i])); edges[y].push_back(pair(x,1.0/values[i]));} 例题：leetcode 199二叉树的右视图 2、并查集模板123456789101112131415161718struct UnionFind { vector&lt;int&gt; parent; UnionFind(int n) : parent(n) { for(int i = 0; i &lt; n; ++i) parent[i] = i; } int find(int x) { if (parent[x] != x) parent[x] = find(parent[x]); // 路径压缩 return parent[x]; } void merge(int x, int y) { int fx = find(x); int fy = find(y); if (fx != fy) parent[fx] = fy; }}; 例题：leetcode 399除法求值 3、快排模版1234567891011121314151617181920vector&lt;int&gt; sortArray(vector&lt;int&gt;&amp; nums) { quickSort(nums,0,nums.size()-1); return nums;}void quickSort(vector&lt;int&gt; &amp; nums,int l,int r){ if(l&gt;=r)return; int k=nums[l],i=l,j=r; while(i&lt;j){ while(i&lt;j &amp;&amp; nums[j]&gt;=k)j--; if(i&lt;j)nums[i]=nums[j]; while(i&lt;j &amp;&amp; nums[i]&lt;=k)i++; if(i&lt;j)nums[j]=nums[i]; } nums[i]=k; quickSort(nums,l,i-1); quickSort(nums,i+1,r);} 进改变while中的&lt;、&gt;反向即可改变数组从小到大、从大到小 快排思想定位 1234567891011121314151617181920212223int findKthLargest(vector&lt;int&gt;&amp; nums, int k) { return quickselect(nums,0,nums.size()-1,k-1);}int quickselect(vector&lt;int&gt; &amp;nums,int l,int r,int k){ if(l==r)return nums[k]; int key=nums[l],i=l,j=r; while(i&lt;j){ while(i&lt;j &amp;&amp; nums[j]&lt;=key)j--; if(i&lt;j)nums[i]=nums[j]; while(i&lt;j &amp;&amp; nums[i]&gt;=key)i++; if(i&lt;j)nums[j]=nums[i]; } nums[i]=key; if(k&lt;=i){ return quickselect(nums,l,i,k); }else{ return quickselect(nums,i+1,r,k); }} hoare分区 (key 不归最终位置) 123456789101112131415161718192021class Solution {public: int quickselect(vector&lt;int&gt; &amp;nums, int l, int r, int k) { if (l == r) return nums[k]; int partition = nums[l], i = l - 1, j = r + 1; while (i &lt; j) { do i++; while (nums[i] &lt; partition); do j--; while (nums[j] &gt; partition); if (i &lt; j) swap(nums[i], nums[j]); } if (k &lt;= j)return quickselect(nums, l, j, k); else return quickselect(nums, j + 1, r, k); } int findKthLargest(vector&lt;int&gt; &amp;nums, int k) { int n = nums.size(); return quickselect(nums, 0, n - 1, n - k); }}; 4、大根堆模版1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253class Solution {public: int findKthLargest(vector&lt;int&gt;&amp; nums, int k) { int heapSize = nums.size(); buildMaxHeap(nums,heapSize); for(int i=0;i&lt;k-1;i++){ cout&lt;&lt;popHeap(nums,heapSize)&lt;&lt;endl; } return popHeap(nums,heapSize); } void buildMaxHeap(vector&lt;int&gt; &amp;nums,int heapSize){ for(int i=heapSize/2-1;i&gt;=0;i--){ maxHeap(nums,i,heapSize); } } void maxHeap(vector&lt;int&gt; &amp;nums,int i,int heapSize){ int largest_i = i,l=i*2+1,r=i*2+2; if(l&lt; heapSize &amp;&amp;nums[i*2+1]&gt;nums[largest_i]){ largest_i = i*2+1; } if(r&lt; heapSize &amp;&amp; nums[i*2+2]&gt;nums[largest_i]){ largest_i = i*2+2; } if(largest_i!=i){ swap(nums[largest_i],nums[i]); maxHeap(nums,largest_i,heapSize); } } int popHeap(vector&lt;int&gt; &amp;nums,int &amp;heapSize){ int res=nums[0]; nums[0]=nums[--heapSize]; maxHeap(nums,0,heapSize); return res; } void pushHeap(vector&lt;int&gt;&amp; nums, int&amp; heapSize, int val) { nums[heapSize++] = val; // 添加到末尾（已预留空间），或用 nums.push_back(val) 也行 int i = heapSize - 1; while (i &gt; 0) { int parent = (i - 1) / 2; if (nums[i] &gt; nums[parent]) { swap(nums[i], nums[parent]); i = parent; } else { break; } } }}; 设计完全二叉树的几个性质： 1、最后一个非叶节点为 heapSize/2-1 2、左右子节点为i*2+1、i*2+2 建堆的复杂度为O（N）。 建堆思路：从最后非叶节点开始往前遍历，逐个递归下沉 递归下沉：选出左右孩子和i自己最大的。若i非最大，则交换，且需继续递归下沉。 出堆思路：堆顶nums[0]返回，将堆最后的nums[heapSize]换到对顶，递归下沉即可，heapSize–。 5、回溯模版1234567891011void backtracking(参数) { if (终止条件) { 存放结果; return; } for (选择 : 本层集合中的元素) { 处理节点; backtracking(路径, 选择列表); // 递归 撤销处理; // 回溯 }} 6、拓扑排序思路：1、入度表 找无前置的节点，将无前置推入队列。 2、先访问，并为后续节点入度表–。若到0则，推入队列。 3、直至列表空。访问次数小于节点个数则失败，否则给出排序。 12345678910111213141516171819202122232425262728293031vector&lt;int&gt; findOrder(int numCourses, vector&lt;vector&lt;int&gt;&gt;&amp; prerequisites) { vector&lt;int&gt; rudu(numCourses,0); vector&lt;vector&lt;int&gt;&gt; next(numCourses); vector&lt;int&gt; res; for(auto p :prerequisites){ rudu[p[0]]++; next[p[1]].push_back(p[0]); } queue&lt;int&gt; q; for(int i=0;i&lt;numCourses;i++){ if(rudu[i]==0)q.push(i); } int visit_num = 0; while(!q.empty()){ int x = q.front(); q.pop(); visit_num++; res.push_back(x); for(auto n: next[x]){ rudu[n]--; if(rudu[n]==0)q.push(n); } } if(visit_num!=numCourses){ return {}; }else{ return res; }} 7、归并排序123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172/** * Definition for singly-linked list. * struct ListNode { * int val; * ListNode *next; * ListNode() : val(0), next(nullptr) {} * ListNode(int x) : val(x), next(nullptr) {} * ListNode(int x, ListNode *next) : val(x), next(next) {} * }; */ ListNode* sortList(ListNode* head) { if(head==nullptr || head-&gt;next==nullptr)return head; guibing(head,nullptr); return v-&gt;next; } void guibing(ListNode * head,ListNode * tail){ //单个数直接返回 if(head-&gt;next==tail)return; //虚拟节点 （前置节点）统一操作 ListNode* v = new ListNode(0,head) ListNode *mid = getMid(head,tail); ListNode* v2 = new ListNode(0,mid); //先访问子树 guibing(head,mid); guibing(mid,tail); //子都有序，合并 merge(v,v2,mid,tail); } //快慢指针找中点 ListNode* getMid(ListNode * h,ListNode * t){ ListNode *fast=h,*slow=h; while(fast!=t){ slow = slow-&gt;next; fast = fast-&gt;next; if(fast!=t){ fast = fast-&gt;next; } } return slow; } //合并 void merge(ListNode * v1,ListNode * v2,ListNode * tail1,ListNode * tail2){ ListNode * h1=v1-&gt;next, *h2=v2-&gt;next,*cur = v1; while(h1!=tail1 &amp;&amp; h2!=tail2){ if(h1-&gt;val &lt;= h2-&gt;val){ cur-&gt;next=h1; h1=h1-&gt;next; cur=cur-&gt;next; }else{ cur-&gt;next=h2; h2=h2-&gt;next; cur=cur-&gt;next; } } ListNode * preTail; if(h1!=tail1){ cur-&gt;next = h1; while(h1!=tail1){ preTail = h1; h1 = h1-&gt;next; } preTail-&gt;next = tail2; } if(h2!=tail2){ cur-&gt;next = h2; } }","link":"/2025/03/25/C-%E5%88%B7%E9%A2%98%E7%AC%94%E8%AE%B0/"},{"title":"DB的聚簇与非聚簇索引（基于Mysql InnoDB引擎）","text":"在数据库调优中，索引扮演着至关重要的角色。而在MySQL中，尤其是使用最广泛的InnoDB存储引擎时，理解聚簇索引（Clustered Index）和非聚簇索引（Non-clustered Index）的原理，对于优化查询性能至关重要。 一、MySQL索引底层结构 —— B+树在MySQL的InnoDB存储引擎中，无论是聚簇索引还是非聚簇索引，底层的数据结构都是B+树。 B+树是一种多路平衡查找树，相比于普通的二叉树或B树，B+树具有以下优势： 磁盘友好：每个节点可以存储大量数据，减少IO次数。 高效范围查询：叶子节点之间通过链表连接，快速支持范围查询。 所有数据存储在叶子节点：查询路径统一，便于优化。 因此，B+树结构非常适合数据库大规模存储和高并发查询的场景。 二、聚簇索引（Clustered Index）2.1 定义聚簇索引决定了数据行在磁盘上的实际存储顺序。数据记录与索引组织在一起，叶子节点保存完整的行数据。 在InnoDB中： 主键索引就是聚簇索引。 如果没有定义主键，InnoDB会自动生成一个隐藏的6字节的主键（DB_ROW_ID）。 2.2 结构示意图12345678910 (内节点) +-----------------+ | 主键K10 | 主键K20 | +-----------------+ / | \\(叶子节点) (叶子节点) (叶子节点)+-------+ +-------+ +-------+| K1 | | K11 | | K21 || DATA | | DATA | | DATA |+-------+ +-------+ +-------+ 中间节点：存储主键值及子节点指针 叶子节点：存储主键+完整行数据 2.3 特点总结 索引即数据，查询主键非常高效。 范围查询（BETWEEN、&lt;、&gt;）性能优秀。 由于物理存储顺序固定，一张表只能有一个聚簇索引。 插入新数据可能导致页分裂，维护成本略高。 三、非聚簇索引（Non-clustered Index）3.1 定义非聚簇索引将索引键值与实际数据行的存储物理位置分开。非聚簇索引指向实际数据行的指针，其索引键值可以是唯一的，也可以是非唯一的。 MyISAM：只支持非聚簇索引。 在InnoDB中： 辅助索引（Secondary Index）就是非聚簇索引。 非聚簇索引查到的数据只是记录的主键，因此需要再次回表查询（主键DB索引）。 3.2 结构示意图123456789 (内节点) +-------------------+ | 索引a5 | 索引a15 | +-------------------+ / | \\(叶子节点) (叶子节点) (叶子节点)+-------------+ +-------------+ +-------------+| a1 | PK_K1 | | a6 | PK_K11 | | a16 | PK_K21 |+-------------+ +-------------+ +-------------+ 中间节点：存储索引列值及子节点指针 叶子节点：存储索引列值+主键值 3.3 特点总结 一张表可以创建多个非聚簇索引。 查询时可能需要回表，带来额外的I/O和CPU消耗。 非聚簇索引特别适合多字段组合查询、覆盖索引查询优化。 四、如何避免回表带来的性能损耗？在使用非聚簇索引时，为了减少回表，提高查询效率，可以采用以下两种优化策略： 4.1 索引覆盖（Covering Index）核心思想：只查用于索引的列，避免回表 如果查询所需字段全部在索引中，可以直接从索引中返回数据，无需回表。 示例： 12-- 联合索引 (a, b)SELECT a, b FROM table_A WHERE a = 'xxx'; a和b字段都在索引中，直接返回数据，无需回表。 4.2 索引下推（Index Condition Pushdown，ICP）核心思想:用索引内容做筛选 MySQL 5.6 引入的新特性，允许在存储引擎层提前过滤部分条件，减少不必要的回表。 示例： 12-- 联合索引 (a, b)SELECT a, b FROM table_A WHERE a LIKE '麦%' AND b = 10; 在5.6以前： 先根据a like '麦%'拿到主键列表，再回表一条条判断b=10。 在5.6以后： 直接在索引中筛选符合b=10的记录，减少回表次数。","link":"/2025/04/17/DB%E7%9A%84%E8%81%9A%E7%B0%87%E4%B8%8E%E9%9D%9E%E8%81%9A%E7%B0%87%E7%B4%A2%E5%BC%95%EF%BC%88%E5%9F%BA%E4%BA%8EMysql-InnoDB%E5%BC%95%E6%93%8E%EF%BC%89/"},{"title":"DHCP头格式","text":"整体包： 链路层头 IP头 20bytes UDP头 DHCP报文 DHCP报文头格式： 8 bits 16 bits 24 bits 32 bits Op Htype Hlen Hops Xid(4 bytes) Secs(2 bytes) Flags(2 bytes) Ciaddr(4 bytes) Yiaddr(4 bytes) Siaddr(4 bytes) Giaddr(4 bytes) Chaddr (16 bytes) Sname (64 bytes) File (128 bytes) magic（4bytes） Option (variable) Op：消息操作代码，1byte，既可以是引导请求（BOOTREQUEST）也可以是引导答复（BOOTREPLY），1为请求报文；2为响应报文。具体的报文类型在option字段中标识。 Htype：硬件地址类型，1byte，表示client硬件地址的类型，1表示以太网类型。 Hlen：硬件地址长度，1byte，以太网的硬件地址长度为6bytes。 Xid：处理ID，1byte，由client端产生的随机数，用于匹配请求和应答报文，就是匹配应答报文是对哪个请求报文做出应答。 Secs：从获取到IP地址或者续约过程开始到现在所消耗的时间，2bytes，客户端进入IP地址申请进程的时间或者更新IP地址进程的时间；由客户端软件根据情况设定。目前没有使用，固定为0。 Flags：标记，2bytes，16bit中只使用了最高位比特（即最左边的比特），这个个比特是广播响应标识位，用来标识DHCP服务器发出的响应报文是广播还是单播，0是单播，1是广播。其余的比特位保留不用，都为0. Ciaddr：客户机IP地址，4bytes，可以是client自己的IP地址，也可以是server分配给client的IP地址。 Yiaddr：“你的”（客户机）IP地址，4bytes，是server分配给client的IP地址。 Siaddr：在bootstrap中使用的下一台服务器的IP地址，4bytes，是client端获取IP地址等信息的server端的地址。 Giaddr：用于导入的接替代理IP地址，4bytes，是client发出请求报文后经过的第一个中继的IP地址。 Chaddr：客户机硬件，16bytes，是client端的硬件地址，在client发出报文时会把自己网卡的硬件地址写进这个字段。 Sname：任意服务器主机名称，空终止符，64bytes，是client端获取IP地址等信息的服务器名称。 File：DHCP发现协议中的引导文件名、空终止符、属名或者空，DHCP供应协议中的受限目录路径名， Magic Cookie：一个固定的值，用于指示 DHCP 选项的开始。 options：可选参数字段**。用于包含其他重要的信息，如 Lease 时间、DNS 服务器、NTP 服务器等。选项长度可变。 c结构体表示：1234567891011121314151617181920typedef struct tag_dhcp{ unsigned char op; //报文的操作类型1：请求报文，2：应答报文 unsigned char ht; //硬件地址类型，表示硬件地址的类型，如以太网。 unsigned char hl; //硬件地址长度，表示硬件地址的长度。 unsigned char ho; //跳数，通常为 0，用于在消息转发时计数。 unsigned int xid; //事务 ID，用于唯一标识一个 DHCP 事务。 unsigned short secs; //DHCP客户端从获取到IP地址或者续约过程开始到现在所消耗的时间，以秒为单位。在没有获得IP地址前该字段始终为0.(DHCP客户端开始DHCP请求后所经过的时间。目前尚未使用，固定为0。) unsigned short flag; //标志位:0表示采用单播发送方式，1表示采用广播发送方式。其余位尚未使用。 unsigned int ciaddr; //DHCP客户端的IP地址（未分配通常为 0.0.0.0） unsigned int yiaddr; //DHCP服务器分配给客户端的IP地址 unsigned int siaddr; //服务器 IP 地址。 unsigned int giaddr; //网关 IP 地址。DHCP客户端发出请求报文后经过的第一个DHCP中继的IP地址。如果没有经过DHCP中继，则显示为0。(转发代理（网关）IP地址) unsigned char chaddr[6]; //DHCP客户端的MAC地址。在每个报文中都会显示对应DHCP客户端的MAC地址。 unsigned char dummy[10]; // unsigned char sname[64]; //为DHCP客户端分配IP地址的DHCP服务器名称（DNS域名格式）。在Offer和ACK报文中显示发送报文的DHCP服务器名称，其他报文显示为0。 unsigned char file[128]; //DHCP服务器为DHCP客户端指定的启动配置文件名称及路径信息。仅在DHCP Offer报文中显示，其他报文中显示为空。 unsigned char magic[4]; unsigned char data[0]; //options:可选项字段，长度可变，格式为&quot;代码+长度+数据&quot;。} dhcp_t; 参考博客： https://cloud.tencent.com/developer/article/2089724","link":"/2023/11/24/DHCP%E5%A4%B4%E6%A0%BC%E5%BC%8F/"},{"title":"InnoDB索引深度剖析：代价、回表、索引优化指南","text":"在MySQL中，索引是提高查询效率的重要武器，但索引也不是”越多越好”。在这篇文章中，我将基于一个500W+大数据量表user_innodb，带你全面理解索引的优势与代价，深入探讨回表、索引覆盖、索引下推、索引失效的真实细节，并总结一套实用的索引设计与优化原则。 1. 索引的代价虽然索引能大幅提升查询速度，但它也带来空间代价和时间代价。 1.1 空间上的代价每新建一个索引，都会创建一棵独立的B+树结构。每个数据页默认占用16KB空间，树越大，数据页越多，占用的磁盘空间也越大。 大量无用索引 = 磁盘空间的灾难！ 1.2 时间上的代价索引带来额外的维护成本： 每次插入、删除、更新数据，都要同步维护对应的所有索引B+树。 删除操作虽然会延迟真正的记录清理，但最终需要整理链表顺序。 插入操作若空间不足还会触发数据页分裂，影响性能。 更新索引字段，会先删除旧索引，再插入新索引。 更严重的是，索引数量过多，会导致MySQL查询优化器生成执行计划时成本大增，因为优化器需要逐个尝试索引，评估各自代价（Cost Based Optimizer）。 ✅ 总结：索引不是越多越好，合适才是关键。 2. 回表的代价2.1 什么是回表？在InnoDB中： 二级索引（非主键索引）的叶子节点只保存索引列+主键值，而不是完整一行数据。 通过二级索引找到记录后，需要拿主键值再去主键索引（聚簇索引）取完整数据——这个过程就是回表。 2.2 回表的性能问题 二级索引内部的数据分布较连续，扫描时比较快。 主键索引的数据页分布可能较离散，回表需要频繁随机IO，磁盘跳跃开销大。 如果目标数据不在内存缓存中（Buffer Pool未命中），每次回表都需要一次磁盘IO（16KB页），非常昂贵！ ✅ 优化策略：能不回表就不回，必须回表就尽量减少回表次数。 3. 索引优化技巧：覆盖索引与索引下推3.1 索引覆盖（Covering Index）如果查询的列全部包含在索引中，可以直接从索引叶子节点返回结果，无需回表。 1SELECT id, name, phone FROM user_innodb WHERE name = &quot;小明&quot;; 联合索引(name, phone)已覆盖了查询列+主键id，无需回表。 3.2 索引下推（Index Condition Pushdown，ICP）索引下推是MySQL 5.6引入的重要优化： 在扫描索引叶子节点时，直接用WHERE子句中的部分条件进行筛选，减少回表。 索引下推的条件是：被用于筛选的列必须在索引中存在。 例子： 1SELECT * FROM user_innodb WHERE name = &quot;小明&quot; AND phone LIKE &quot;%6606&quot;; 由于LIKE以%开头，无法利用phone字段索引顺序。 但phone字段在索引中，可以在索引扫描过程中直接筛选，只将符合条件的记录回表，极大减少回表次数！ ✅ 总结：索引覆盖彻底避免回表，索引下推减少回表数量。 4. 什么情况下索引会失效？4.1 违反最左前缀原则 联合索引必须按最左列优先使用。 只按phone列查询会导致索引失效。 1EXPLAIN SELECT * FROM user_innodb WHERE phone = '13203398311'; 4.2 使用反向条件（!=、&lt;&gt;、NOT LIKE） 反向条件通常导致索引无法有效利用。 4.3 LIKE以%开头 LIKE '%沐风' 无法定位索引起点，只能全表扫描。 4.4 对索引列做操作 使用函数、表达式、隐式类型转换等。 例： 1EXPLAIN SELECT * FROM user_innodb WHERE LEFT(name, 3) = '小明'; 正确做法：可以建函数索引（MySQL 8.0+支持）。 4.5 OR连接查询 如果OR两边字段使用的索引不同，可能导致全表扫描。 ✅ 总结：索引失效常由查询写法不规范导致，EXPLAIN是发现问题的利器。 5. 索引设计原则5.1 避免给低离散度列建索引 比如gender字段（0/1值），重复值太多，索引效率低。 此外，低离散度列即使建了索引，查询时匹配的数据量通常非常大，导致需要进行大量回表。要知道： 全表扫描至少是顺序IO，磁盘读写相对连贯，性能尚可接受。 大量回表则意味着近乎完全的随机IO，每次根据主键值去主键索引找完整记录，频繁磁盘跳跃，极大增加IO延迟。 如果内存缓存（Buffer Pool）命中率不高，那么每次回表都需要磁盘IO，读取速度将比全表扫描更慢，系统负载大幅上升。 ✅ 总结：低离散度列不仅索引利用率低，还可能带来更高的随机IO开销，应避免为其单独建立索引。 5.2 只给搜索、排序、分组列建索引 SELECT列表中的列通常不需要单独建索引。 5.3 联合索引优先最常用列 最常作为过滤条件的列排在最左边。 5.4 使用前缀索引优化超长字段 长文本字段可只索引前缀（比如phone(3)），节省空间。 5.5 频繁更新的值，不要作为主键或索引 频繁更新的字段如果作为主键或索引列，会导致频繁的B+树节点调整。 插入或更新过程中可能引起数据页分裂，增加维护成本，严重影响写入性能。 特别是主键索引，由于聚簇索引的特性，主键值变化还会导致整行数据物理位置的变动，开销更大。","link":"/2025/04/28/InnoDB%E7%B4%A2%E5%BC%95%E6%B7%B1%E5%BA%A6%E5%89%96%E6%9E%90%EF%BC%9A%E4%BB%A3%E4%BB%B7%E3%80%81%E5%9B%9E%E8%A1%A8%E3%80%81%E7%B4%A2%E5%BC%95%E4%BC%98%E5%8C%96%E6%8C%87%E5%8D%97/"},{"title":"JMM(Java内存模型)","text":"​ 现代CPU往往通过多级缓存与指令重排加速处理，但这些设计在多线程情况下导致并发的数据问题。并且，为保证JAVA跨平台运行特性，对不同操作系统的内存结构进行了抽象表示，提出了JMM (Java内存模型)。 ​ JMM 本质上是 Java 定义的并发编程中对==共享变量==的读写操作的行为规范。除了抽象了线程和主内存之间的关系之外，其还规定了从 Java 源代码到 CPU 可执行指令的这个转化过程要遵守哪些和并发相关的原则和规范。其主要目的是为了简化多线程编程，增强程序可移植性的。 本文主要通过一下几个方面进行讨论 背景：并发问题与解决 多级缓存–&gt;内存缓存不一致问题–&gt;MESI等一致性协议 指令重排–&gt;内存屏障–&gt;抽象：happen-before原则 不同内存结构，操作实现不同–&gt;JMM抽象层表示 JMM定义与抽象内存结构 主、副本内存的交互协议 happen-before原则保证指令的有序性 JMM中实现的volatile、synchronized、final的关键字与实现原理 1. 背景 JMM主要目的：JVM为解决多级缓存的不可见问题、指令重排、跨平台多OS抽象统一的三个主要问题 1.1 CPU多级缓存–&gt;共享变量“不可见问” ​ CPU通过速度更快的缓存对CPU的执行过程（取数据）进行加速。 ​ CPU Cache 的工作方式： 首次使用数据会缓存到 CPU Cache 中，后续缓存命中可直接用，在合适的时候（不一定运算完成后立即），再将运算得到的数据写主存中。 ​ 当内存中的一个变量，被多个线程共享都载入到各个核心的缓存时候，不同核心线程对这个数据的更改就会不可见，从而导致一系列问题（如写丢失、无法感知数据变化等等）。 123456789101112131415161718192021public class kejianxing { public static boolean flag = true; public static void main(String[] args) throws InterruptedException { Thread t1 = new Thread(() -&gt; { while (flag) { // xxx } System.out.println(&quot;t1 finished&quot;); }); t1.start(); Thread.sleep(1000); flag = false; System.out.println(&quot;main set flag to false&quot;); t1.join(); System.out.println(&quot;main thread finished&quot;); }} 运行的结果只有main set flag to false，因为主线程对flag 的修改，子线程不可见。 1.2 指令重排为了提升执行速度/性能，计算机在执行程序代码的时候，会对指令进行重排序。 常见的指令重排序有下面 2 种情况： 编译器优化重排：编译器（包括 JVM、JIT 编译器等）在不改变单线程程序语义的前提下，重新安排语句的执行顺序。 指令并行重排：现代处理器采用了指令级并行技术(Instruction-Level Parallelism，ILP)来将多条指令重叠执行。如果不存在数据依赖性，处理器可以改变语句对应机器指令的执行顺序。 内存系统也会有“重排序”，但又不是真正意义上的重排序。在 JMM 里表现为主存和本地内存的内容可能不一致，进而导致程序在多线程下执行可能出现问题。 ​ Java 源代码会经历 编译器优化重排 —&gt; 指令并行重排 —&gt; 内存系统重排 的过程，最终才变成操作系统可执行的指令序列。在单线程情况可以执行加速，但是多线程情况产生并发错误 例如，在单例模式DCL问题下，指令重排导致的问题。 1234567891011121314public class Singleton { private static Singleton instance; // 不使用 volatile public static Singleton getInstance() { if (instance == null) { // 第一次检查（非同步） synchronized (Singleton.class) { if (instance == null) { // 第二次检查（同步） instance = new Singleton(); // 可能发生指令重排！ } } } return instance; }} 问题分析 ​ instance = new Singleton() 在字节码层面分为3步：① 分配内存空间 ② 初始化对象（调用构造方法）③ 将引用赋值给 instance 如果发生指令重排（②和③交换）： 线程A 执行 instance = new Singleton()，但 instance 先被赋值（③），而对象未初始化（②未执行）。 线程B 进入 getInstance()，发现 instance != null，直接返回一个未初始化完成的对象，导致程序错误。其他线程，便会使用这个未初始化的对象， 解决方案 volatile 确保： 可见性：线程A的修改对线程B立即可见。 禁止指令重排：new Singleton() 的步骤不会被重排。 1.3 操作系统内存实现的多样性​ ==结构统一==：不同的硬件、缓存的结构并不相同（如寄存器，多级缓存等等），因此JMM抽象成了主内存和工作内存。 ​ ==缓存数据一致性==：为解决内存缓存的不一致，不同的CPU采用缓存一致性协议通常也会有所不同。有些使用MESI协议来保证数据的“可见性”。 ​ MESI 是一种典型的多核 CPU 缓存一致性协议，用于保证多个 CPU 核访问共享内存时保持一致。它的名字来自 4 种缓存行的状态： 状态 含义 Modified（已修改） 缓存中有最新数据，主内存中是旧的，这个缓存行是独占的，必须将数据写回主内存后，其他 CPU 才能读到 Exclusive（独占） 缓存中与主内存一致，但只有当前 CPU 拥有这个缓存行，可以直接读写，不需要通知别人 Shared（共享） 缓存中与主内存一致，可能被多个 CPU 缓存，只能读，不能写 Invalid（无效） 缓存行无效，必须重新从主内存加载数据 情境：Core 0 想写一个变量（写操作） 步骤如下： Core 0 检查缓存行状态。当前状态是 Shared，不能直接写。 Core 0 向其他 CPU 发出总线请求（Bus Upgrading）。它发出一个“写意图通知（Invalidate Request）”，广播到总线（Bus）上。 其他 CPU 接收到请求。Core 1 收到后，将该缓存行的状态变为 Invalid（无效）。 Core 0 把缓存行状态从 Shared 升级为 Modified。它现在拥有该缓存行的唯一副本，可以放心修改了；写操作发生在自己的缓存中，之后可以异步写回主内存。 ==禁止指令乱序==：内存屏障（Memory Barrier） 是一种用于控制 CPU 和编译器对内存操作重排序和缓存行为的指令，目的是在多线程环境下确保内存可见性和执行顺序的正确性。 类型 作用描述 LoadLoad 保证前一个读取完成后，才能读取下一个 StoreStore 保证前一个写操作完成后，才能执行后一个写 LoadStore 防止写操作提前于前面的读执行 StoreLoad 最强屏障，阻止写后的读操作被重排序（跨线程通信常用） Java 的 volatile 和 synchronized 底层正是依赖内存屏障来实现其内存语义的。**** volatile 写操作插入 StoreStore + StoreLoad 屏障； 读操作插入 LoadLoad + LoadStore 屏障； 作用：确保变量在多线程之间及时可见，并防止重排序。 synchronized 进入临界区时插入读相关屏障； 退出临界区时插入写相关屏障； 作用：配合锁的语义，建立 Happens-Before 保证。 2. JMM定义与抽象内存结构​ 一般来说，编程语言也可以直接复用操作系统层面的内存模型。不过，不同的操作系统内存模型不同。如果直接复用操作系统层面的内存模型，就可能会导致同样一套代码换了一个操作系统就无法执行了。Java 语言是跨平台的，它需要自己提供一套内存模型以屏蔽系统差异。 ​ JMM，全称 Java Memory Model（Java 内存模型），是 Java 语言对多线程环境中 共享变量的读写操作的行为规范。主要解决跨平台通用的并发问题，如多级缓存与指令重排。 JMM抽象的内存结构： 主内存（Main Memory）：存放所有共享变量。 工作内存（每个线程独有）：存储主内存中共享变量的副本。实际可能是寄存器、缓存、写缓冲区等等地方。 此外，线程对变量的操作，必须在自己的工作内存中进行，不允许一个线程直接访问另一个线程的工作内存。 3. 内存的交互协议*（了解即可，无需记） 关于主内存与工作内存直接的具体交互协议，即一个变量如何从主内存拷贝到工作内存，如何从工作内存同步到主内存之间的实现细节，Java 内存模型定义来以下八种同步操作 锁定（lock）: 作用于主内存中的变量，将他标记为一个线程独享变量。 解锁（unlock）: 作用于主内存中的变量，解除变量的锁定状态，被解除锁定状态的变量才能被其他线程锁定。 read（读取）：作用于主内存的变量，它把一个变量的值从主内存传输到线程的工作内存中，以便随后的 load 动作使用。 **load(载入)**：把 read 操作从主内存中得到的变量值放入工作内存的变量的副本中。 **use(使用)**：把工作内存中的一个变量的值传给执行引擎，每当虚拟机遇到一个使用到变量的指令时都会使用该指令。 assign（赋值）：作用于工作内存的变量，它把一个从执行引擎接收到的值赋给工作内存的变量，每当虚拟机遇到一个给变量赋值的字节码指令时执行这个操作。 store（存储）：作用于工作内存的变量，它把工作内存中一个变量的值传送到主内存中，以便随后的 write 操作使用。 write（写入）：作用于主内存的变量，它把 store 操作从工作内存中得到的变量的值放入主内存的变量中。 4. JMM的happen-before原则*（了解即可，无需记） as-if-serial是针对单线程语义的重排序规则。编译器和 CPU 可以对指令优化重排，只要单线程的执行结果与顺序执行结果一致，就符合 as-if-serial 原则。 指令重排序就可能会让多线程程序的执行出现问题，为此针对多线程并发的内存可见性规则，JMM 抽象了 happens-before 原则。 happens-before规则 描述 程序顺序规则 单线程内，代码按顺序执行 锁规则 解锁先于加锁（释放锁前的修改，对后面拿锁可见） volatile 规则 写 volatile 先于读 线程启动规则 start() 先于子线程动作 线程终止规则 join() 先于线程结果可见 传递性规则 A → B，B → C，则 A → C 📌 只要两个操作之间存在 happens-before，就保证： 前者的修改对后者是可见的 前者的执行顺序在后者之前 5.JMM 与关键字的关系 关键字 与 JMM 的关系 volatile 保证 可见性、禁止重排序 synchronized 保证 可见性 + 原子性 + 有序性（通过 lock/unlock） final 保证 构造过程中的可见性（不可变对象） 5.1 volatilevolatile 是 Java 提供的一种轻量级的同步机制，它主要有两个功能： 保证变量的可见性 禁止指令重排序 volatile 底层通过内存屏障实现。 内存屏障实现 在底层实现上，volatile 主要通过插入内存屏障（Memory Barrier）来实现其功能： 写操作：在 volatile 写操作后会插入一个 StoreStore 屏障和 StoreLoad 屏障 StoreStore 屏障：确保 volatile 写之前的普通写操作对其他处理器可见。（ volatile 写操作之前的所有普通写操作先完成，并刷新到主内存。） StoreLoad 屏障：确保 volatile 写操作立即刷新到主内存，并且使其他 CPU 的缓存失效（例如MESI缓存一致协议）。 读操作：在 volatile 读操作前会插入 LoadLoad 屏障和 LoadStore 屏障 LoadLoad 屏障：确保 volatile 读操作先于后续的所有读操作 LoadStore 屏障：确保 volatile 读操作先于后续的所有写操作 JMM中抽象的动作定义为： JMM定义的操作 行为 写（赋值） 线程 直接将值写入主内存（store + write），并刷新工作内存中的副本 读（取值） 线程 从主内存中强制读取最新值（read + load），不使用工作内存中的旧副本 JMM规定（happens-before 规则中的 volatile 特殊规则）： 对一个 volatile 变量的写操作，happens-before 后续对这个变量的读操作。 这意味着：如果线程 A 写了一个 volatile 变量，线程 B 读这个变量，那么线程 A 之前对内存的写入对线程 B 是可见的。 5.2 synchronized​ synchronized 是通过对象锁从 JVM 层面实现的，其底层依赖对象头中的 Mark Word 和 Monitor（监视器锁）。 在字节码层面，synchronized 的实现依赖于 JVM 的指令和对象头的监视器锁（Monitor）机制： 同步代码块：编译后会生成 monitorenter 和 monitorexit 字节码指令。 同步方法：方法的 access_flags 中会有 ACC_SYNCHRONIZED 标志。 对象头与 Monitor 每个 Java 对象都有一个对象头，其中包含： Mark Word：存储对象的哈希码、GC 分代年龄、锁状态等信息 Klass Pointer：指向对象所属类的元数据 ​ 在Java中，Object类提供了wait和notify，因此所有的对象都可以作为一把锁。在同步状态下，Mark Word 会指向一个 Monitor 对象（也称为管程或监视器锁）。 进入和退出 synchronized 块时，JVM 会通过插入内存屏障来保障线程之间的可见性和有序性。线程在进入同步块前必须从主内存中重新读取变量值，退出时则会将变量值刷新到主内存。 ​ 具体来说：monitorenter 指令前插入了Store Barrier（写屏障）；monitorexit 指令后插入了Load Barrier（读屏障）。保证写入主内存、读取最新值，防止指令重排序。 Synchronized优化 Jdk1.5 提出了rentrantlock 性能远高于synchronized。因为synchronized 未抢到锁会进行挂起，等待资源。因此在jdk1.6 进行优化（锁消除、锁膨胀、锁升级），目前和reentrantlock性能差不多，但reentrantlock更灵活。 锁消除：消除不必要的锁（例如用的全是局部变量） 所膨胀：扩大锁的范围，从而避免频繁加锁解锁 锁升级：无锁—&gt;偏向锁-&gt;CAS锁-&gt;重量锁（挂起）。（锁一但升级不可降级） 5.3 finalfinal 在JMM中具有非常特殊的语义，主要是为了保证对象构造过程中的“初始化安全性”。 final通过插入屏障防止指令重排序，避免其他线程看到未初始化的字段： 在构造函数中对 final 字段的写操作，在字节码中会在写入后插入一个StoreStore 屏障，防止该写入与对象引用的发布发生重排序； 在其他线程第一次读取包含 final 字段的对象引用时，会插入一个LoadLoad 屏障，保证能看到构造函数中对 final 字段的写操作。 这种规则不适用于非-final 字段，所以构造对象时即使正确发布了引用，如果字段不是 final，可能仍会看到未初始化或旧的值。","link":"/2025/04/24/JMM-Java%E5%86%85%E5%AD%98%E6%A8%A1%E5%9E%8B/"},{"title":"JVM GC(垃圾回收)","text":"Java 一开始出现的目的：去掉C++繁琐的东西，如指针、内存管理~ GC（Garbage Collection，垃圾回收） 是 JVM 中非常核心的一项功能，关系到 性能、内存安全、程序稳定性。只针对JVM运行内存中的堆区进行回收。 一、什么是 GC（垃圾回收）？ GC 是 JVM 自动管理内存的机制，它负责回收堆中程序不再使用的对象（无引用的对象、生命周期结束的对象（如局部变量、临时对象）），释放内存空间，避免内存泄漏和内存溢出。 你无需手动 free() 或 delete 对象（像 C/C++ 中那样），Java 的 JVM 会自动完成这些操作。 二、堆的分区结构（默认分代）为了更高效地 管理对象生命周期、优化 GC 性能，堆又被进一步划分为几个“区域”。 JVM 的堆通常被划分为两个主要区域： 12345Java Heap├── Young Generation（年轻代）│ ├── Eden Space（伊甸园）│ └── Survivor Space（S0 和 S1）└── Old Generation（老年代） 1. 年轻代（Young Generation）特点：大多数新创建的对象会先进入这里 GC 频率：高（因为对象死亡率高） GC 类型：Minor GC（小型垃圾回收） 目标：快速清除生命周期短的对象，减少对老年代的压力 进一步划分为 3 个区： 区域 说明 Eden 区 对象最初创建时进入这里，绝大多数对象会在这里被回收 Survivor 0 / Survivor 1（S0 / S1） 复制式 GC 交替使用（一个做 From，一个做 To） 📌 新生代回收策略：复制算法（from → to） Eden → S0 → S1 → Old Eden 区空间不足时，会触发 YGC（轻GC） 存活对象会被复制到 Survivor 区 多次 Minor GC 后仍然存活的对象晋升到 老年代(默认15次存活后) 2. 老年代（Old / Tenured Generation） 特点：存放生命周期较长、经历多次 GC 仍存活的对象 GC 频率：低（相比年轻代） GC 类型：Major GC / Full GC（停顿时间长） 回收策略：标记清除 +标记压缩 的混合策略 3. 元空间（Metaspace）（JDK 8+）虽然不在 Java 堆中，但它取代了 JDK 7 之前的 永久代（PermGen），用于存储： 类的结构信息 字节码（class 文件解析） 方法、字段、常量池等 📌 元空间使用 本地内存（Native Memory），不再受堆大小限制。 三、GC算法与总体流程3.1 如何判断对象还”活着“（引用计数 &amp; 可达性分析）3.1.1. ❌ 引用计数法（已淘汰） 原理：每个对象有个引用计数器，引用 +1，解除引用 -1，计数为 0 就可以回收。 问题：无法处理循环引用（A -&gt; B, B -&gt; A） 3.1.2.✅ 可达性分析（JVM 使用）核心思想： 通过一组称为 “GC Roots” 的对象作为起点，从这些点出发，向下遍历所有能访问到的对象链。 只要一个对象能被这些 GC Roots 直接或间接引用到，就说明它是“活的”。 反之，如果对象在引用图中无法从 GC Roots 到达，说明它是“不可达的” → 垃圾 → 可被回收。 1234567GC Roots │ ├─→ objA ──→ objB │ └─→ objC ──→ objD✗ objE ─→ objF（没有 GC Roots 指向它们，被判定为垃圾） 对象不可达 → 标记为“可回收” 3.2 复制算法核心思想： 把内存分成两块，每次只使用其中一块。当这一块满了，就把活着的对象复制到另一块，然后整个旧区域一次性清理掉。 年轻代通常划分为： Eden Survivor From Survivor To 每次 GC： Eden + From 中存活对象 → 复制 → To 区 复制完毕，清空 Eden 和 From To 区变成新的 From，原 From 变成 To（角色互换） 🌟 优点： 不用标记和清理，只复制“活着”的对象，效率高。 不会有内存碎片！ ⚠️ 缺点： 浪费内存，一次只能用一半空间。 3.3 标记-清除算法（Mark-Sweep）核心思想： 两个阶段完成回收： 标记（Mark）：从 GC Roots 出发，标记所有活着的对象 清除（Sweep）：遍历整个内存，把未标记的对象清掉 结构应用： 多用于老年代 老年代中对象存活时间长，用复制算法浪费太大，因此用“清理”的方式节省空间 🌟 优点： 不需要额外空间，内存利用率高 ⚠️ 缺点： 会产生内存碎片（碎片可能导致大对象分配失败） 清理后内存不连续，可能引发频繁 Full GC 核心思想： 是“标记-清除”的改进版，在清除之后把存活对象压缩到一块，使内存连续，解决碎片问题。 回收过程： 标记存活对象 将所有存活对象移动到左侧（压缩） 清除边界后的所有无效空间 结构应用： 常用于老年代的 Major GC Full GC 时常采用该算法（如 G1、CMS 的失败回收） 🌟 优点： 不会产生碎片，内存整理整齐 ⚠️ 缺点： 移动对象需要 更新所有引用指针，开销较大，性能低于复制算法 3.4 整体流程对象在堆中的“生命周期旅程” 123456789new 对象 → Eden（新生代） | ↓ |Survivor S0（存活一次） | 轻GC，复制算法 ↓ |Survivor S1（存活多次） | ↓老年代（长期存活） ↓Full GC（最后的回收机会） JVM 通过一个叫 年龄计数（Tenuring Threshold） 的机制来决定对象是否晋升到老年代。 轻GC触发条件（Minor GC）： 当 Eden 区满了，就会触发一次 Minor GC。 具体过程如下： 对象被创建 → 分配在 Eden 区 Eden 区没有足够空间时，JVM 触发一次 Minor GC GC 会将 Eden 和 From Survivor 中 存活的对象复制到 To Survivor 对象经历多次 Minor GC 后，年龄达到阈值（默认为 15），晋升到老年代 Major GC / Old GC（重 GC）什么时候触发 场景 说明 老年代空间不足时 比如对象晋升时，老年代空间不足 Minor GC 后对象晋升失败 Survivor → Old Gen，发现 Old Gen 装不下 调用 System.gc() 显式触发 Full GC（但只是建议，JVM 可忽略） 元空间溢出或频繁加载类 类加载太多，Metaspace 爆满（Full GC） CMS GC 执行失败时 CMS 是“并发清除”，失败后会退化为 Full GC 特点： 主要清理老年代 停顿时间长，耗时大（涉及复杂算法如标记-压缩） 可能伴随年轻代 GC（但不是必须） Full GC（完全 GC） 其实 Full GC 不是单独的一种 GC 类型，而是指一次包含 老年代 + 年轻代 + 元空间 的全面回收操作。 元空间不足，加载了太多类信息等等","link":"/2025/04/24/JVM-GC-%E5%9E%83%E5%9C%BE%E5%9B%9E%E6%94%B6/"},{"title":"JVM沙箱机制","text":"我们现在来讲讲 JVM 沙箱机制（Java Sandbox Mechanism），这是 Java 提供安全执行环境的核心之一，尤其在运行来自不可信源的代码时至关重要。 一、什么是沙箱机制？ JVM 的“沙箱”是一种 安全隔离机制，用于防止 Java 程序（尤其是不受信任的代码）访问系统资源或进行破坏性操作。 📌关键词：限制能力 + 隔离资源 + 控制权限它就像一个“沙盒”：你可以在里面玩，但你出不去，不能动外面的系统资源。 二、为什么需要沙箱机制？在早期 Java 应用中，特别是： Java Applet（网页小程序） 动态加载的第三方代码 插件系统 我们不能信任所有代码，所以需要 JVM 强制隔离权限，以防止恶意操作，比如： 删除文件 发送网络请求 修改系统属性 执行本地命令（Runtime.exec()） 三、JVM 沙箱机制的组成（3 大核心组件）JVM 的沙箱机制主要通过以下三个系统组件实现： 1. 类加载器（ClassLoader） 负责隔离代码来源，决定谁可以加载什么类。 自定义类加载器可以限制只加载指定路径下的类 不同加载器加载的类是“隔离”的（类名一样也不等于同一个类） 📌 是沙箱的第一道防线，起到代码来源的隔离作用。 2. 字节码验证器（Bytecode Verifier） 加载 .class 文件后，JVM 会验证其字节码是否合法、安全。 包括： 不允许访问非法内存 方法调用是否合法 操作数栈类型匹配 不允许越界访问数组 📌 这是第二道防线，防止恶意或损坏的字节码搞破坏。 3. 安全管理器（SecurityManager）+ 权限控制器（AccessController） 控制运行时行为权限（如文件、网络、反射等）。 通过 SecurityManager 检查：是否允许操作系统资源 结合 AccessController.doPrivileged() 机制，细粒度控制权限范围 权限策略配置文件如： 123grant { permission java.io.FilePermission &quot;/tmp/*&quot;, &quot;read&quot;;}; 📌 这是沙箱的最后防线，用于权限控制。 四、沙箱中的典型限制行为（除非被授权） 操作 是否允许（默认） 读取系统属性 ❌ 被拦截 访问文件系统 ❌ 被拦截 打开网络连接 ❌ 被拦截 使用反射访问私有字段 ❌ 被拦截 退出 JVM ❌ 被拦截 加载 native 本地代码 ❌ 被拦截 五、真实应用中的沙箱场景✔️ 1. Applet（网页 Java 小程序） 浏览器中执行的 Java 代码不允许接触用户硬盘或系统 ✔️ 2. Java 插件机制 / 动态脚本 比如 Groovy、JavaScript 脚本，运行在 JVM 中需沙箱保护 ✔️ 3. 企业系统的插件平台 大型系统允许用户扩展插件，但必须沙箱运行（不能越权） 六、现代沙箱机制的演变 SecurityManager 和 AccessController 是 Java 传统沙箱核心 JDK 17 开始，SecurityManager 被标记为 “Deprecated”（弃用） 原因：管理复杂、滥用反射绕过 替代方案：更推荐使用 模块系统（JPMS）、容器技术（Docker） 来做隔离 更细粒度的控制可用 java.policy 文件 + 安全框架（如 OSGi） 七、总结一句话： JVM 沙箱机制是由类加载器、字节码校验器和安全管理器组成的一套系统，用于隔离、限制不可信代码的行为，确保 Java 运行环境的安全性。","link":"/2025/04/24/JVM%E6%B2%99%E7%AE%B1%E6%9C%BA%E5%88%B6/"},{"title":"JVM运行时数据区和对象实例化过程","text":"Java 程序运行时，JVM 会划分出一套专用的内存结构，叫做 运行时数据区（Runtime Data Areas），它是理解 JVM 内部原理的核心之一。 一、JVM 运行时数据区概览JVM 将运行内存划分为以下 5 大核心区域（JDK 8 后略有变化）： 区域名称 是否线程私有 主要存储 程序计数器（PC寄存器） 是 记录当前线程执行的字节码地址 虚拟机栈（JVM Stack） 是 存储方法调用的栈帧（局部变量、操作数栈等） 本地方法栈 是 支持调用 Native 方法 堆（Heap） 否（共享） 存储所有对象实例、数组 方法区（Method Area） / 元空间（Metaspace） 否（共享） 类信息、静态变量、常量、运行时常量池 二、每个区域的详细解释1. 程序计数器（Program Counter Register） 线程私有 保存当前线程正在执行的字节码指令地址 每个线程都有一个独立的 PC 寄存器，线程切换时可以恢复执行位置（类似 CPU 中的 PC） 2. 虚拟机栈（JVM Stack） 线程私有 每调用一个方法，都会在栈中创建一个 栈帧（Stack Frame） 栈帧结构包括： 局部变量表：基本数据类型、对象引用、方法参数 操作数栈：用于字节码指令的中间计算 动态链接：指向常量池的方法引用 方法返回地址 📌 方法执行完后，栈帧出栈。 3. 本地方法栈（Native Method Stack） 线程私有 用于支持 Java 调用本地（Native）方法（如调用 C/C++ 函数） 类似 JVM Stack，但服务于本地代码（JNI） Class 类中 方法如果带了native，指Java方位管不到了，要调用C底层库了 4. 堆（Heap） 线程共享 存储所有对象实例和数组 是 GC（垃圾回收器）管理的主要区域 通常划分为： 年轻代（Young Generation）：Eden + Survivor（新对象） 老年代（Old Generation）：长期存活对象 5. 方法区（Method Area） / 元空间（JDK 8+） 线程共享 存储： 类的结构信息（类名、字段、方法） 静态变量（static） 常量池（Runtime Constant Pool） 字节码（方法代码） JDK 8 开始：方法区移出堆，成为本地内存中的「元空间（Metaspace） 123456789线程私有： ├─ 程序计数器（PC寄存器） ├─ JVM 栈（局部变量、操作数栈） └─ 本地方法栈线程共享： ├─ 堆（对象实例） └─ 方法区（类信息、常量池、静态变量） └─ 元空间（JDK 8+） 三、对象实例化过程 对象在内存中实例化的过程: 程序执行时，JVM会为每一个线程创建一个栈，在初始化对象时，会将当前方法的栈帧（stack frame）压入栈中 在new对象时，JVM会检查目标类是否已经加载到方法区中，如果没有，则会通过类加载器（class loader）将其加载到方法区中。 JVM会在堆中开辟一块内存，用于存储对象实例数据 JVM会将对象的实例变量初始化为默认值，在执行构造方法时，会进一步初始化对象 在堆中创建对象后，JVM会生成一个指向该对象的引用地址，并将对象的引用地址压入栈中","link":"/2025/04/24/JVM%E8%BF%90%E8%A1%8C%E6%97%B6%E6%95%B0%E6%8D%AE%E5%8C%BA%E5%92%8C%E5%AF%B9%E8%B1%A1%E5%AE%9E%E4%BE%8B%E5%8C%96%E8%BF%87%E7%A8%8B/"},{"title":"Linux socket","text":"1、基本流程linux-gun/sys/socket使用的基本流程： 创建socket socket设置参数 socket绑定一个地址:端口 发送与接收 以及一个技巧，多socket下的监控——select。 2、创建socketUDP示例： 1234567891011int fd, opt;struct sockaddr_in sin;memset( &amp;sin, 0, sizeof( struct sockaddr_in ) );sin.sin_family = AF_INET;sin.sin_addr.s_addr = ip;sin.sin_port = htons( port ); if ( ( fd = socket( AF_INET, SOCK_DGRAM, IPPROTO_UDP ) ) == -1 ) { LOG_S( &quot;socket&quot; ); return -1; } 3、socket设置参数socketopt int setsockopt(int sockfd, int level, int optname, const void *optval, socklen_t optlen); sockfd 是套接字文件描述符，用于标识要设置选项的套接字。 level 表示选项所在的协议层级。常见的是 SOL_SOCKET，表示套接字层级选项，也有其他层级，比如 IPPROTO_TCP 或 IPPROTO_IP。 optname 是要设置的选项名称，如 SO_REUSEADDR 或 SO_KEEPALIVE 等。 optval 是指向包含新选项值的缓冲区的指针。 optlen 表示选项值的长度。 返回-1为设置失败 3.1 SO_REUSEADDR12int optval = 1;setsockopt(socket_fd, SOL_SOCKET, SO_REUSEADDR, &amp;optval, sizeof(optval)); 3.2 nonblock1234567891011121314int sock_setnonblock( int fd, int nonblock ){ int opt; opt = fcntl( fd, F_GETFL ); if ( nonblock == 0 )opt &amp;= ~O_NONBLOCK; else opt |= O_NONBLOCK; if ( fcntl( fd, F_SETFL, opt ) == -1 ) { return -1; } return 0;} 3.3 SO_SNDTIMEO&amp;1234struct timeval tv;tv.tv_sec = msecs / 1000;tv.tv_usec = ( msecs % 1000 ) * 1000;setsockopt( fd, SOL_SOCKET, SO_SNDTIMEO, ( const void* )&amp;tv, sizeof( struct timeval ) 1234struct timeval tv;tv.tv_sec = msecs / 1000;tv.tv_usec = ( msecs % 1000 ) * 1000;setsockopt( fd, SOL_SOCKET, SO_RCVTIMEO, ( const void* )&amp;tv, sizeof( struct timeval ) ) 3.4 SO_LINGER123456int onoffint lingerstruct linger lg;lg.l_onoff = !!onoff;lg.l_linger = linger;setsockopt( fd, SOL_SOCKET, SO_LINGER, ( const void* )&amp;lg, sizeof( struct linger ) ) 3.5 SO_BROADCAST123int opt;opt = !!onoff;setsockopt( fd, SOL_SOCKET, SO_BROADCAST, ( const void* )&amp;opt, sizeof( opt ) ) 4、socket绑定地址:端口udp绑定示例： 123456struct sockaddr_in sin;memset( &amp;sin, 0, sizeof( struct sockaddr_in ) );sin.sin_family = AF_INET;sin.sin_addr.s_addr = ip;sin.sin_port = htons( port );bind( fd, ( struct sockaddr* )&amp;sin, sizeof( struct sockaddr_in ) 5、发送与接收udp示例： 发送 123456struct sockaddr_in sin;memset( &amp;sin, 0, sizeof( struct sockaddr_in ) );sin.sin_family = AF_INET;sin.sin_addr.s_addr = INADDR_BROADCAST;sin.sin_port = htons( 67 );while ( ( nwrite = sendto( fd, buff, len , 0, ( const struct sockaddr* )&amp;sin, sizeof( struct sockaddr_in ) ) ) == -1 &amp;&amp; errno == EINTR ); 接收： 1234567net68 = htons( 68 );struct sockaddr_in sin;memset( &amp;sin, 0, sizeof( struct sockaddr_in ) );sin.sin_family = AF_INET;sin.sin_addr.s_addr = INADDR_BROADCAST;sin.sin_port = net68;while ( ( nwrite = sendto( g_fd, buff, len1, 0, ( const struct sockaddr* )&amp;sin, sizeof( struct sockaddr_in ) ) ) == -1 &amp;&amp; errno == EINTR ); 5、selectselect 是一个用于多路复用 I/O 操作的系统调用，用于监视多个文件描述符的状态，判断它们是否处于可读、可写或错误等状态。 基本语法如下： 1int select(int nfds, fd_set *readfds, fd_set *writefds, fd_set *exceptfds, struct timeval *timeout); nfds 是被监视的文件描述符的数量。 readfds、writefds 和 exceptfds 是分别指向读、写和异常描述符集合的指针。这些集合用于传递你感兴趣的文件描述符。 timeout 是一个指向 struct timeval 结构的指针，表示 select 的超时时间。如果设置为 NULL，select 将一直阻塞，直到有描述符就绪。 select 会阻塞等待，直到文件描述符集合中的一个或多个描述符就绪，或者超时。 123456struct timeval tv;tv.tv_sec = 0;tv.tv_usec = 100 * 1000;FD_ZERO( &amp;readfd );FD_SET( g_fd, &amp;readfd );while ( ( rc = select(fd + 1, &amp;readfd, NULL, NULL, &amp;tv ) ) == -1 &amp;&amp; errno == EINTR ); 补充： 阻塞与非阻塞： 直接循环 recvfrom 可能会导致阻塞，因为它会一直等待数据到达。而 select 可以使程序在等待数据时不阻塞整个进程，可以同时监视多个套接字，哪个套接字有数据到达就会通知程序。 select的优越性主要表现在它可以实现一个线程监听多个socket句柄，而阻塞模型则需要多线程来达到这个目的，所以在并发的大量请求的情况下，这样是能节省很多开销的。还有在设置好timeout后，超过这个时间select将不再阻塞，会返回错误，这样可以接着执行别的操作，一定程度上能达到异步的目的。所以你看，这样就和并发和异步联系上了。","link":"/2023/11/24/Linux-socket/"},{"title":"Linux基本操作","text":"linux基本操作 虚拟机网络连接的三种模式 1 桥接模式 虚拟系统可以喝外部系统通信，但是容易造成IP冲突 2 NAT模式 网络地址转换模式，虚拟系统可以和外部通讯，由主机再次路由转发 3 主机模式：独立系统 虚拟机克隆 虚拟机快照 Linux 目录结构 /bin 常用命令 /sbin 系统管理员使用的系统管理程序 /home 普通用户主目录 /boot 启动相关 /last+found 一般情况下空的，当系统非法关机后， /lib 动态链接库 /etc 所有系统管理所需要的配置文件和子目录，比如mysql的my.conf /usr 用户很多应用程序和文件都放在这个目录下，类似于windows的program files目录 /root root用户 /proc 这个目录是一个虚拟牡蛎，他是系统映射，访问这个目录来获取系统信息 /srv service缩写，该目录存放一些服务启动后需要提取的数据 /sys 该目录下安装了2.6内核中出现的新文件系统sysfs /tmp 存放一些临时文件 /dev 设备管理器：硬盘、cpu等等 /mnt 为了让用户临时挂载别的文件系统，可以将外部存储挂载在/mnt/上，然后进入目录就可以看到里面的内容了。 /opt 这是给主机额外安装软件所存放的目录。 /usr/local 另一个安装软件所安装的目录。一般是通过源码编译方式安装的程序、与目标安装目录。 /var 存放不断扩充的东西，习惯将经常修改的目录存放在该目录等下。如log /selinux SELinux是一个安全子系统，他们控制程序智能访问特定文件。 vim 普通模式； 拷贝 yy 向下5行：5yy，粘贴 （输入p） 删除 dd，删除向下5行：5yy 定位文件开头（gg），定位文件末尾（G） 快速定位某一行 例如：输入“20”，shift+g 撤销一个操作 u 插入模式（按i进入） 命令行（“:”开启）： w q ！ 匹配：/+关键字 n查找下一个，N上一个 设置文件行号：“:set nu” 取消：“：set nonu” 关机重启 shutdown -h now Shutdown -h 1 #一分钟后关机，不带参数默认为此 shutdown -r now #现在重启 halt #关机 reboot #现在重启计算机 sync #把内存数据同步到磁盘 ls ls -l ll l -a l -lh 用户的登录和逐项 建议不要用root登录，普通账户登录再su -用户名（su -root） logout可以注销用户 注意： 1、logout命令图形界面无效，只在运行级别3下有效 添加用户 useradd 用户名 会自动创建与用户名同名的home目录 useradd -d 目录名 指定home目录创建用户名 如:useradd milan -d test 指定修改密码 passwd 密码 用户删除 userdel 用户名 删除用户，但是保留home目录 userdel 用户名 删除用户与相应home userdel -r 用户名 用户查询 id 用户名 切换用户 su - 用户名 注意： 权限高的用户切换低权限用户 需要密码；反之 返回原来的用户，logout/exit 查看当前用户 whoami who am i 同时显示登录信息 用户组 类似于角色，系统可以对一组用户统一进行权限管理 用户组添加 groupadd 组名 用户组删除 groupdel 组名 增加用户时直接加上组 useradd -g 用户组 用户名 修改用户的组 usermod -g 用户组 用户和组相关的文件 /etc/passwd 用户的配置文件，记录用户的各种信息 每行的含义：用户名：口令：用户标识号：组号：注释性描述：主目录：登录shell（bash为主） /etc/shadow 口令配置文件 每行含义：登录名：密码：最后一次修改时间：最小时间间隔：最大时间间隔：警告时间：不活动时间：失效时间：标志 /etc/group group的配置文件 每行含义：组名；口令；租号；组内用户列表 指定运行级别： 0：关机 1：单用户【找回丢失密码】 2：多用户无网络服务 3：多用户有网络服务 4：系统未使用保留给用户 5：图形界面 6：系统重启 切换运行级别 init 级别 指定系统登录后的默认运行级别 Centos7以前，在/etc/inittab文件中 进行了简化，如： mult-user.target:analogous to runlevel 3 graphical.target:analogous to runlevel 5 看当前默认级别 systemctl get-default 设置默认级别 systemctl set-default TARGET.targrt 如何找回用户密码 重启后输入e，修改进入单用户运行级别，修改用户密码 帮助指令 man [命令或配置文件] 案例：查看ls帮助信息 man ls help 语法：help 命令 （功能描述：获得shell内置命令的帮助信息） cd指令 cd 参数 cd ~ cd / cd .. mkdir 创建目录 mkdir 要创建的目录 -p :创建多级目录（即中间目录也会同时创建，不会报未找到文件的草屋） mkdir /root/files1 mkdir /root/files2/files3 rmdir 删除空目录 rmdir [选项] 目录名 若要删除非空目录，则rm -rf 删除的目录 touch 创建空文件 touch /root/hello.txt cp指令 cd [选项] source dest -r 递归复制整个文件夹 cp /root/hello.txt /tmp/hello.txt cp -r /root /tmp/root 强制覆盖不提示： \\cp -r /root /tmp/root rm指令 删除文件 rm [选项] 要删除的文件或目录 常用选项： -r：递归删除整个文件夹 -f：强制删除不提示 rm /home/hello.txt rm -rf /home/bbb mv 移动文件目录或重命名 mv oldNameFile newNameFile mv /temp/movefile /targetFolder cat指令 cat查看文件指令。只能浏览，不能修改，更安全 cat [选项] 文件名 常用选项 -n 显示行号 为了浏览方便，一般带上 管道命令|more Enter键 下一行 空格键 下一页 q 退出 cat -n /root/hello.txt | more less 指令 与more现实类似，但更强大。动态加载。 语法：Less 要查看的文件 空格 向下一个 /字串 向下匹配查询 ？字串 向上匹配查询 q 退出 echo指令 echo [选项] [输出内容] 例如输出环境变量 echo $HOSTNAME echo $PATH head head显示文件的开头部分内容，默认情况下head指令显示文件的前10性内容 head 文件 head -n 5 文件 看前5行 tail指令 用于输出文件尾部的内容，默认尾部10行 基本语法： tail file tail -n 5 文件 tail -f 文件 （实时追踪该文档的所有更新，看实时文档很合适） &gt;指令和&gt;&gt;指令 &gt;输出重定向&gt;&gt;追加 ls -l &gt;文件 (功能描述：列表的内容写入文件a.txt（覆盖写）) ls -al &gt;&gt; 文件(功能描述：列表的内容追加到文件aa.txt的末尾) Cat 文件1&gt;文件2 （功能描述：将文件1的内容覆盖到文件2） echo “内容”&gt;&gt;文件 例：将/home目录下的文件列表写入到/home/info.txt中，覆盖写入 ls -l /home &gt; /home/info.txt [如果info.txt没有，会自动创建] ln 指令 软链接也称符号链接，类似于windows的快捷方式，存放了链接其他文件的路径 基本语法 ln -s [源文件或目录] [软链接名] 例；在/home目录下创建一个软链接myroot,链接到/root目录 ln -s /root /home/myroot 例：删除软链接 myroot rm /home/myroot 细节说明：当我们使用pwd指令查看目录时，仍然看到的是软链接的目录 history指令 查看已经执行过的历史命令，也可以执行历史指令 例：显示所有的历史指令 history 例2：显示最近使用过的10个指令 history 10 例3：直行历史编号为5的指令 !5 时间日期类 data 指令-显示当前的日期 基本语法： data data +%Y data +%m data +%d data “+%Y-%m-%d %H:%M%S” 设置日期 data -s 字符串时间 例如： data -s “2020-11-03 20:02:10” cal 指令 cal [选项] 不加选项显示本月日历 显示2020年的日历 cal 2020 搜索查找类： find 指令 find指令将指定目录向下递归遍历各个子目录，将满足文件或者目录显示在终端 find [搜索范围] [选项] 选项说明： -name &lt;查询方式&gt; 按照指定的文件名查找模式查找文件 -user &lt;用户名&gt; 查找属于制定用户名所有的文件 -size &lt;文件大小&gt; 按照指定的文件大小查找（+n 大于 -n小于 n等于，单位有k，M，G） 案例1；按文件名：根据名称查找/home 目录下的hello.txt文件 find /home -name hello.txt 案例2：按拥有者：查找/opt目录下，用户名称为nobody的文件 find /opt -user nobody 案例3：查找整个linux系统下大于200M的文件 find / -size +200M locate指令 locate指令可以快速定位文件的路径。locate指令利用实现建立的系统中所有文件名称和路径的locate数据库实现快速定位。不再边路整个文件系统，在创建的数据库中实现快速检索。 使用： updatedb locate hello.txt which指令 可以查看摸个指令在哪个目录下 例如 which ls grep指令和管道符号| grep 过滤查找，管道符，“l”，表示将前一个命令的处理结果输出给后面的命令处理 grep [选项] 查找内容 源文件 选项： -n 显示匹配行和行号 -i 忽略字母大小写 例：在hello.txt 文件中查找“yes” 所在行 cat /home/hello.txt | grep “yes” Linux组的基本介绍 在linux中的每个用户必须属于一个组，不能独立于组外。 文件有： 1、所有者 2、所在组 3、其他组 一般谁创建了文件，就自然成为了该文件的所有者。 查看文件的所有者： ls -ahl 修改文件的所有者 chown 用户名 文件名 组的创建 基本指令 groupadd 组名 实例： 创建一个组monster groupadd monster 创建一个fox用户，并加到monster组中 useradd -g monster fox 修改文件所在组 chgrp 组名 文件名 例如： 使用root用户创建文件orange.txt，看看当前这个文件属于哪个组，然后将这个文件所在组修改到fruit组 groupadd fruit touch orange.txt 看到当前文件属于root组 chgrp fruit orange.txt 其他组：除了文件所有者和文件所在组，其余都是文件的其他组 改变用户的所在组 usermod -g 新组名 用户名 usermode -d 目录名 用户名 改变用户登录的初始目录。特别说明，用户需要有进到新目录的权限 权限的基本介绍 1234drwx------ 9 ubuntu ubuntu 4096 Nov 30 16:58 . drwxr-xr-x 4 root root 4096 Apr 13 2021 .. -rw-r--r-- 1 root root 0 Nov 25 12:25 1.pcapng -rw-r--r-- 1 ubuntu ubuntu 10169 Dec 6 15:02 .bash_history 0-9位说明 1、第0位确定文件类型（d,-,l,c,b） d 目录 - 普通文件 l 链接 c 字符设备 b 块设备 2、1-3位确定所有者拥有文件的权限。 –User 3、第4-6位确定所属组拥有该文件的权限 —Group 4、7-9位确定其他用户拥有该文件的权限 —other rwx作用到文件： [r]代表可读(read)：查看 [w]代表可写(write)：可修改内容，但不一定可以删除文件。删除文件需要对所在目录有写权限，才能删除文件 [x]代表可执行(execute):可以被执行 rwx作用到目录 [r]代表可读(read):可以读取，ls查看目录内容 [w]代表可写(write)：可以修改（目录内创建+删除+重命名文件） [x]代表可执行(execute):可以进入该目录 修改权限 chmod指令，可以修改文件或者目录的权限 第一种方式：+、-、=变更权限 u:所有者 g：所在组 o：其他人 a：所与人(u,g,o的总和) 1)chmod u=rwx,g=rx,o=x 文件/目录名 2)chmod o+w 文件/目录名 3)chmod a-w 文件/目录名 第二种方式：通过数字变更权限 r=4 w=2 x=1 rwx=4+2+1=7 chmod u=rwx,g=rx,o=x 相当于 chmod 751 文件目录名 修改文件所有者 改变所有者： chown newowner 文件/目录 改变文件所有者和所在组： chown newowner:newgroup -R 如果是目录，则使其下的所有子文件或者目录递归生效 例： chown tom /home/abc.txt chown -R tom /home/test Linux 分区 Linux硬盘分为IDE硬盘和SCSI硬盘，目前基本上是SCSI硬盘 对于IDE硬盘，驱动器符号为“hdx~” 对于SCSI硬盘，驱动器符号为“sdx~” “x”为盘号(a为基本盘，b为基本从属盘，c为辅助主盘，d为辅助从属盘) “~”代表分区，前面分区数字为1到4，它们是主分区或者扩展分区，从5开始就是逻辑分区了。 查看所有设备的挂载情况 命令：lsblk或者lsblk -f -f 显示UUID 硬盘分区标识号 Vm虚拟机可以模拟添加硬盘 分区命令 fdisk /dev/sdb 开始对/sdb分区 m 显示命令列表 p 显示磁盘分区 同fdisk -l n 新增分区 d 删除分区 w 写入并退出 说明：开始分区后输入n，新增分区，然后选择p，分区类型为主分区。两次回车默认剩余全部空间。最后输入w写入分区并退出，若不保存则输入q。 格式化磁盘 分区命令：mkfs -t ext4 /dev/sdb1 其中ext4为分区类型 挂载 将一个分区与一个目录联系起来，使得可以访问。 mount 设备名称 挂载目录 例如：mount /dev/sdb1 /newdisk unmount 设备名称 或者 unmoount /newdisk 注意：用命令行挂载重启后会失效 永久挂载：通过修改/etc/fstab实现挂载 添加完后，mount -a 即即刻生效 磁盘情况插叙 查询系统整体磁盘的使用情况 基本语法 df -h 查看指定目录的磁盘占用情况 du -h 查询指定目录的磁盘占用情况，默认为当前目录 -s 指定目录占用大小汇总 -h 带计量单位 -a 含文件 –max-depth=1 子目录深度 -c 列出明细的同时，增加汇总值 例如：查询/opt 目录的磁盘占用情况，深度为1 du -hac –max-depth=1 /opt 磁盘情况 1、统计/opt文件夹下普通文件的个数 ls -l /opt| grep “^-“ | wc -l 2、统计/opt文件下的目录个数 ls -l /opt| grep “^d” | wc -l 3、统计/opt文件夹下普通文件的个数，包括子文件夹里的 ls -lR /opt | grep “^-“ | wc -l 4、以树状结构显示目录结构tree目录，注意，如果没有tree，则需安装 显示系统执行的进程 ps ps命令用来查看目前系统中，有哪些正在执行，以及它们的执行状况。可以不加参数 ps [选项] ps -a：显示当前终端的所有进程 ps -u：以用户的格式显示进程 ps -x：显示后台进程运行的桉树 ps详细 ps -aux | grep xxx , 比如我看看有没有sshd服务 指令说明 System V 展示风格 USER；PID；%CPU；%MEM；VSZ；RSS；TT；STAT；STARTED；TIME；COMMAND 用户名称；进程号；进程CPU占用比；内存占用比；进程虚拟内存大小KB；进程物理内存大小；终端名称，缩写；进程状态，S-睡眠，s-会话的先导进程，N-表示进程拥有比普通有些急更低的优先级，R-正在运行，D-短期等待，Z-僵死进程，T-被跟踪或被停止等；进程启动时间；CPU时间，即CPU使用总时间；进程启动所有的命令与参数，会被截断显示 ps-ef 以全格式显示当前的所有进程 以全格式查看所有进程，查看进程的父进程。例如查看sshd的父进程信息 -e 显示所有进程 -f 全格式 ps -ef|grep xxx 是BSD风格 UID：用户ID PID：进程ID PPID：父进程ID C：CPU用于执行计算的优先级因子。数值越大，表示是CPU密集型运算，优先级会降低；数值越小，表示IO密集型运算，优先级会提高 STIME：开始时间 TTY：所属终端 TIME：运行时间 CMD：启动命令与参数 kill指令 kill [选项] 进程号（通过进程号杀死进程） killall 进程名称 （通过进程名杀死进程，也支持通配符，这在系统负载过大很慢时有用） 常用选项： -9：表示强迫进程立即终止（-9信号量无法被捕获，不能被忽略） 例：踢掉摸个非法登录进程 kill 11421 例：终止远程登录服务sshd，在适当时候在重启sshd服务 kill sshd对应的进程号 /bin/systemctl start sshd.service 例：终止多个gedit killall gedit 例：强制删掉一个终端 kill -9 进程号 查看进程树 树状结构看进程信息 pstree [选项] 常用选项 -p:显示进程PID -u：显示进程的所属用户 例如： pstree -p pstree -u 服务管理 服务(service)本质就是进程，但是是运行在后台的，通常都会监听某个端口，等待其它程序的请求，比如(mysgld,sshd 防火墙等)，因此我们又称为守护进程，是Linux中非常重要的知识点。 service管理指令service 服务名 [start | stop |restart | reload | status] 1.在CentOS7.0后 很多服务不再使用service ,而是 systemctl2.service 指令管理的服务在 /etc/init.d 查看 service管理指令案例 请使用service指令，查看，关闭，启动network service network status service network stop service network restart 查看服务名 方式1； setup 方式2：/etc/init.d 看到service指令管理的服务 ls -l /etc/init.d 服务的运行级别（runlevel） Linux系统有7种运行级别(runlevel): 常用的是级别3和5运行级别0:系统停机状态，系统默认运行级别不能设为0，否则不能正常启动运行级别1: 单用户工作状态，root权限，用于系统维护，禁止远程登陆运行级别 2: 多用户状态(没有NFS)，不支持网络运行级别 3:完全的多用户状态(有NFS)，无界面，登陆后进入控制台命令行模式运行级别 4 :系统未使用，保留运行级别 5 :X11控制台，登陆后进入图形GUI模式运行级别 6: 系统正常关闭并重启，默认运行级别不能设为6，否则不能正常启动 开机流程： 开机-&gt;BIOS-&gt;/boot -&gt; /systemd进程1 -&gt;运行级别 -&gt;运行级对应的服务 查看当前运行级别 systemctl get-default 设置运行级别 systemctl set-default TARGET.targert systemctl set-default graphical.targert chkconfig指令 1、通过chkconfig命令可以给服务的各个运行级别设置 启动/关闭 2、chkconfig指令的服务在/etc/init.d查看 3、centos7.0后，很多服务用systemctl进行管理 基本语法： chkconfig –list chkconfig –level 5 服务名 on/off 案例演示：对network服务，进行各种操作，把network在3运行级别，关闭自启动 chkconfig –level 3 network off chkconfig –level 3 network on chkconfig重新设置服务后自启动或关闭，需要重启机器reboot生效 systemctl指令 systemctl 对3和5运行级别同时设置，为此不必指明。 1、基本语法 systemctl [start|stop|restart|status] 服务名 systemctl指令管理的服务在/usr/lib/systemd/system 查看 systemctl设置服务的自启动状态 1.systemctl list-unit-files [lgrep 服务名](查看服务开机启动状态, grep 可以进行过滤2.systemctl enable 服务名(设置服务开机启动) 3.systemctl disable 服务名(关闭服务开机启动) 4.systemctl is-enabled 服务名 (查询某个服务是否是自启动的 应用案例： 查看防火墙的状况，关闭防火墙和重启防火墙 systemctl status firewalld systemctl stop firewalld systemctl start firewalld 基本指令的start、stop当系统重启后便失效了，按照自动启动内容生效。若要保证重启后生效，使用自启动状态设置即可，如systemctl enable 服务名 防火墙打开或关闭指定端口 firewall指令： 打开端口： firewall-cmd –permanent –add-port=端口号/协议 关闭端口： firewall-cmd –permanent –remove-port=端口号/协议 重新载入，才能生效： firewall-cmd –reload 查询端口是否开放：firewall-cmd –query-port=端口/协议 例如：开放111端口 firewall-cmd –permanent –add-port=111/tcp firewall-cmd –reload firewall-cmd –query-port=111/tcp 动态监控进程： top指令 top与ps命令很相似。它们都用来显示正在执行的进程。Top与ps最大的不同之处，在于top在执行一段时间可以更新正在运行的的进程。 top [选项] 选项： -d 秒数 指定top命令每隔几秒更新。默认是3秒 -i 是top不显示任何闲置或者僵死进程 -p 通过指定监控进程ID来仅仅监控某个进程的状态 动态监控交互操作 P 以CPU使用率排序，默认就是此项 M 以内存的使用率排序N 以PID排序q 退出top 应用示例： 1、监控特定用户，比如我们监控tom用户 top输入回车 然后输入u回车 在输入用户名 2、终止指定进程 top kill 进程ID 3、10秒更新top top -d 10 网络监控状态 查看系统网络使用情况netstat netstat [选项] 选项： -an 按一定顺序排序输出 -p 显示哪个进程在调用 例：请查看服务名为sshd的服务信息 netstat -anp | grep sshd 检测主机连接的命令ping 主要用于检测元辰主机是否正常，或者两部主机间的网线或网卡故障 如：ping 对方ip地址 网络配置 查看网络配置 linux ifconfig windows ipconfig Linux网络环境配置 第一种（DHCP自动获取）：每次获取的Ip不一样 第二种（指定ip）：直接修改配置文件来指定IP，并可以连接到外网（程序员推荐） 编辑 vi /etc/sysconfig/network-scripts/ifcfg-ens33 要求：将ip地址配置的静态的，比如：ip地址为192.168.20.130 ifcif-ens33 文件说明 DEVICE=etho#接口名(设备,网卡） HWADDR=00:0C:2x:6x:0x:xx #MAC地址 TYPE=Ethernet #网络类型(通常是Ethemet ) UUID=926a57ba-92c6-4231-bacb-f27e5e6a9f44#随机id #系统启动的时候网络接口是否有效 (yes/no )ONBOOT=yes #IP的配置方法[nonelstatic bootpldhcp](引导时不使用协议|静态分配IP|BOOTP协议|DHCP协议） BOOTPROTO=static #IP地址 IPADDR=192.168.200.130#网关 GATEWAY=192.168.200.2 #域名解析器DNS1=192.168.200.2 重启网络服务或者重启系统生效 service network restart 或 reboot 设置主机名和hosts映射 1、为了方便记忆，可以给linux系统设置主机名,也可以根据需要修改主机名2、指令 hostname :查看主机名 3、修改文件在 /etc/hostname 指定 4、修改后，重启生效 设置主机映射 思考：如何通过主机名能够找到（比如ping）摸个linux系统 windows 在C:\\Windows\\System32\\drivers\\etc\\hosts 文件指定即可 例如：192.168.200.130 hspedu100 linux 在/etc/hosts文件指定 案例：192.168.200.1 thinkpad-pc 测试：ping hespedu100 Hosts是一个文本文件，用来记录IP和Hostname（主机名）的映射关系 DNS： 1、DNS，Domain Name System的缩写，翻译过来是域名系统 2、是互联网上域名和IP相互映射的分布式数据库 浏览器先检查浏览器缓存中有没有该域名解析IP地址，有就先调用这个IP完成解析，如果没有检查操作系统DNS解析器缓存，如果有直接返回IP完成解析。这两个缓存，可以理解为 本地解析器缓存。 一般来说，当电脑第一次成功访问某一网站后，在一定时间内，浏览器或操作系统会缓存他的IP地址(DNS解析记录).如 在cmd窗口中输入。 ipconfig /displaydns //DNS域名解析缓存 ipconfig /flushdns //手动清理dns缓存如果本地解析器缓存没有找到对应映射，检查系统中hosts文件中有没有配置对应的域名IP映射，如果有，则完成解析并返回。如果 本地DNS解析器缓存 和 hosts文件 中均没有找到对应的IP则到域名服务DNS进行解析域。 apt命令 advanced package tools apt-get update 更新源 apt-get install package 安装包 apt-get remove package 删除包 apt-cache search package 搜索包 apt-cache show package 获取包的相关信息如说明、大小、版本 apt-get remove package –purge 删除、包括配置文件 apt-get build-dep package 安装相关的编译环境 apt-get upgrade 更新已经安装的包 apt-get dist-update 升级系统 apt-cache depends package 了解使用依赖了哪些包 apt-cache rdepends package 查看被哪些包依赖 apt-get source package 下载该包的源代码 更换镜像源 /etc/apt/sources.list 1、备份上述文件，修改上述文件，查找清华镜像源写入 2、apt-get update 更新源地址 crond定时任务调度(周期性) crontab定时任务的设置 任务调度：系统在某个时间执行的特定命令或程序 任务调度分类：1、系统工作 2、用户任务：如定时mysql备份 crontab [选项] 常用选项： -e 编辑crontab定时任务 -l 列出crontab任务 -r 删除当前用户的所有crontab任务 设置任务调度文件：/etc/crontab 设置个人任务调度： 1、crontab -e命令 2、内容输入，如：*/1**** ls -l /etc/ &gt; /temp/to.txt 解释：每小时的每分钟执行ls -l /etc/ &gt; /temp/to.txt命令 cron规则： 特殊符号的说明 示例： 案例1：每隔一分钟，就将当前日期信息，追加到/tmp/mydate文件中 */1 * * * * data&gt;&gt;/temp/mydate 案例2：每隔一分钟，将当前日期和日立都追加到/home/mycal 文件中 Vim /home/my.sh 写入内容 data &gt;&gt; /home/mycal 和 cal &gt;&gt; /home/mycal 给my.sh 增加执行权限，chmod u+x /home/my.sh crontab -e 增加： */1 * * * * /home/my.sh crontab相关命令 crontab -r : 终止调度 crontab -l ：列出当前有哪些任务调度 at定时任务 只执行一次 at命令是一次性定时计划任务，at的守护进程atd会以后台模式运行。 检查作业队列来运行默认情况下，atd守护进程每60秒检查作业队列，有作业时，会检查作业运行时间，如果时间与当前时间匹配，则运行此作业 at命令是一次性定时计划任务，执行完一个任务后不再执行此任务了 在使用at命令的时候，一定要保证atd进程的启动，可以使用相关指令来查看 ps -ef I grep atd //可以检测atd是否在运行 查看已有任务命令 atq at命令格式 at [选项] [时间] ctrl+D 结束at命令输入 例如：两天后的下午5点执行 ls /home at 5pm + 2 days at&gt; /bin/ls /home 例如：两分钟红输出时间到指定文件内 at now + 2 minutes at&gt;data &gt; /root/data200.log Shell 编程 Shell是一个命令行解释器，它为用户提供了一个向Linux内核发送请求以便运行程序的界面系统级程序，用户可以用Shell来启动、挂起、停止甚至是编写一些程序。 脚本格式要求： 1、脚本以#!/bin/bash开头 例如： 12#!/bin/bashecho &quot;hello,world!&quot; sh hello.sh chmod u+x hello.sh ./hello.sh 脚本常用的执行方式： 方式1（输入相应路径） 说明：需要赋予helloworld.sh 脚本执行权限，在执行脚本 方式2（sh+脚本） 说明：不用赋予脚本+x权限，直接执行 Shell 变量: 1、Linux Shell中的变量分为，系统变量和用户自定义变量2、系统变量: $HOME、$PWD、$SHELL、$USER等等，比如: echo $HOME 等等. 3、显示当前shell中所有变量: set shell变量的定义： 1、定义变量：变量名=值 2、撤销变量：unset 变量 3、声明静态变量： readonly变量，注意：不能unset 定义变量的规则1、变量名称可以由字母、数字和下划线组成，但是不能以数字开头。5A=200(x) 2、等号两侧不能有空格3、变量名称一般习惯为大写，这是一个规范，我们遵守即可 将命令的返回值赋给变量 1、A=`date`反引号，运行里面的命令，并把结果返回给变量 2、A=$(date) 等价于A=`date` 示例 123456789101112131415161718#!/bin/bash#定义变量A#!!!等号两侧不能有空格A=100#输出变需要加上$echo A=$Aecho &quot;A=$A&quot;#撤销变量Aunset Aecho &quot;A=$A&quot;#声明静态变量B=2,不能unsetreadonly B=2echo &quot;B=$B&quot;#unset BC=`date`echo $CD=$(date)echo $D 设置环境变量（全局变量） 基本语法1、export 变量名=变量值(功能描述:将shell变量输出为环境变量/全局变量 2、source 配置文件 (功能描述:让修改后的配置信息立即生效 ) 3、echo $变量名 （功能描述:查询环境变量的值 ) 快速入门 1、在/etc/profile文件中定义TOMCAT_HOME环境变量 2、查看环境变量TOMCAT_HOME的值 3、在另外一个shell程序中使用 TOMCAT_HOME注意: 在输出TOMCAT_HOME 环境变量前，需要让其生效source /etc/profile shelI脚本的多行注释 123:&lt;&lt;! 内容! 位置参数： 介绍 当我们执行一个shelI脚本时，如果希望获取到命令行的参数信息，就可以使用到位置参数变量比如 :./myshell.sh 100 200，这个就是一个执行shell的命令行，可以在myshell 脚本中获取到参数 信息基本语法 $n (功能描述 :n为数字，$0代表命令本身，$1-$9代表第一到第九个参数，十以上的参数，十以上的参数需要用大括号包含，如${10]) $*(功能描述:这个变量代表命令行中所有的参数，$*把所有的参数看成一个整体) $@(功能描述:这个变量也代表命令行中所有的参数，不过$@把每个参数区分对待) $# (功能描述:这个变量代表命令行中所有参数的个数) 案例： 12345#!/bin/bashecho &quot;0=$0 1=$1 2=$2&quot;echo &quot;所有参数=$*&quot;echo &quot;$@&quot;echo &quot;参数的个数=$#&quot; sh cavr.sh 100 200 预定义变量 运算符 以下内容如在过多介绍： 条件判断 单分支多分支 基本语法如下： 单分支： 123if [ 条件判断式 ]; then 当条件成立时，可以进行的命令工作内容fi # 将if 反过来写，就成为fi，意思就是结束if 多分支： 1234567if [ 条件判断式 ]; then 当条件判断式成立时，可执行的命令elif [ 条件判断式2 ]; then 当条件判断式2成立时，可执行的命令else 当条件判断式1与2均不成立时，可执行的命令fi 示例 1234567891011121314151617#!/bin/bash#echo &quot;----选择下列的系统----&quot;echo &quot;linux&quot;echo &quot;windows&quot;echo &quot;mac&quot;echo &quot;----------------------&quot;read -p &quot;请输入系统：&quot; systemif [ &quot;$system&quot; = &quot;linux&quot; ]; then echo &quot;该系统为：RedHat System&quot;elif [ &quot;$system&quot; = &quot;windows&quot; ]; then echo &quot;该系统为：Microsoft System&quot;elif [ &quot;$system&quot; = &quot;mac&quot; ]; then echo &quot;该系统为：Apple System&quot;else echo &quot;其他操作系统&quot;fi case语句 case 语句是 Shell 脚本中用于多重条件判断的一种结构。它可以对变量的不同值进行匹配，并执行相应的操作。通常与 esac 配对使用，用于结束 case 语句块。 语法大致如下： 12345678910111213case expression in pattern1) # 如果 expression 匹配 pattern1，执行对应操作 # 可以包含多条命令 ;; pattern2) # 如果 expression 匹配 pattern2，执行对应操作 ;; ... *) # 默认情况，如果 expression 与上述所有 pattern 都不匹配，执行对应操作 ;;esac expression 是要进行匹配的值或变量。 pattern1, pattern2, … 是要匹配的模式。 ;; 用于结束每个模式的操作，类似于 break 的作用，表示当前模式匹配结束。 *) 表示默认情况，如果 expression 与之前的模式都不匹配，则执行对应的操作。 示例1： 1234567891011121314151617181920#!/bin/bashecho &quot;请选择一个数字（1-3）：&quot;read numcase $num in 1) echo &quot;你选择了数字 1&quot; ;; 2) echo &quot;你选择了数字 2&quot; ;; 3) echo &quot;你选择了数字 3&quot; ;; *) echo &quot;请在 1 到 3 之间做出选择&quot; ;;esac 示例2： 12345678910111213141516171819#!/bin/bashecho &quot;请输入一个字符：&quot;read charcase $char in [a-z]) echo &quot;小写字母&quot; ;; [A-Z]) echo &quot;大写字母&quot; ;; [0-9]) echo &quot;数字&quot; ;; *) echo &quot;其他字符&quot; ;;esac for循环 for 循环是 Shell 编程中用于重复执行一系列命令的结构。它能够遍历一组值或集合中的每个元素，并对每个元素执行指定的操作。 基本语法如下： 1234567for var in value1 value2 value3 ... valuendo # 执行针对每个值的操作 command1 using $var command2 using $var # ...done var 是循环中的变量名，用于存储每次循环中的当前值。 value1 value2 ... valuen 是一个值列表或集合，for 循环将遍历这些值并执行相应的操作。 示例1： 123456789101112#!/bin/bashecho &quot;遍历数组中的值：&quot;# 定义一个数组fruits=(&quot;apple&quot; &quot;banana&quot; &quot;orange&quot;)# 使用 for 循环遍历数组元素for fruit in &quot;${fruits[@]}&quot;do echo &quot;水果：$fruit&quot;done 示例2： 123456789#!/bin/bashecho &quot;打印数字 1 到 5：&quot;# 使用 for 循环遍历数字范围for num in {1..5}do echo &quot;$num&quot;done while循环 while 循环是 Shell 脚本中用于重复执行一系列命令的结构，它会在给定条件为真时执行循环体。 1234567while [ condition ]do # 在条件为真时执行的命令或操作 command1 command2 # ...done 示例： 123456789101112131415#!/bin/bashecho &quot;倒计时开始：&quot;count=5# 使用 while 循环进行倒计时while [ $count -gt 0 ]do echo &quot;$count&quot; count=$((count - 1)) # 更新 count 的值 sleep 1 # 暂停 1 秒doneecho &quot;倒计时结束&quot; read获取输入 在 Shell 脚本中，read 命令用于从标准输入（键盘）中读取用户的输入，并将输入的内容赋值给一个变量。 1read [-options] [variable...] -options 是 read 命令的选项，常用的选项包括 -p（用于显示提示信息）和 -r（用于禁止反斜杠转义）等。 variable 是一个或多个变量名，用于存储用户输入的内容。 示例： 12345#!/bin/bashread -p &quot;请输入您的年龄：&quot; ageecho &quot;您的年龄是 $age 岁。&quot; 自定义函数 语法如下： 1234function name() {statements[return value]} 示例 12345678#!/bin/bash#函数定义function url(){echo &quot;http://c.biancheng.net/shell/&quot;}#函数调用url","link":"/2023/12/06/Linux%E5%9F%BA%E6%9C%AC%E6%93%8D%E4%BD%9C/"},{"title":"Mysql如何实现ACID","text":"MySQL 是怎么实现 ACID 的 InnoDB 引擎。 先简单回顾一下： ACID 是指数据库事务需要满足的四个特性： A（Atomicity）原子性 C（Consistency）一致性 I（Isolation）隔离性 D（Durability）持久性 1. Atomicity（原子性）含义：事务中的操作要么全部成功，要么全部失败。 MySQL实现方式： Undo Log（回滚日志）：在执行事务之前，InnoDB 会把数据的旧版本写到 Undo Log 中。如果事务中途失败或回滚了，就可以利用 Undo Log 恢复到事务开始前的状态。 事务控制：事务提交之前，所有修改都在私有空间（缓冲区）进行，只有提交后才真正写入数据库。 2. Consistency（一致性）含义：事务必须使数据库从一个一致性状态变到另一个一致性状态。 MySQL实现方式： 外键、约束、触发器：这些数据库规则本身可以保证数据的一致性。 事务本身的原子性 + 隔离性：事务执行时，即使出现中断或并发问题，利用回滚和隔离控制，依然可以保持一致性。 简单说就是，Consistency 是靠数据库本身的规则 + ACID 其他三个特性一起保证的。 3. Isolation（隔离性）含义：并发执行的事务之间互不干扰。 MySQL实现方式： 多版本并发控制（MVCC）：InnoDB 默认采用 MVCC，给每行数据打上版本号，读操作读自己能看到的版本，写操作修改新版本，互不影响。 锁机制： 行锁（Record Lock）：锁定一行。 间隙锁（Gap Lock）：锁定一段范围，防止幻读。 意向锁（Intention Lock）：事务想加锁，先声明意向，提高锁管理效率。 隔离级别（事务隔离级别）： READ UNCOMMITTED READ COMMITTED REPEATABLE READ（InnoDB默认） SERIALIZABLE InnoDB 通过 MVCC + 锁机制结合实现了事务隔离。 4. Durability（持久性）含义：事务一旦提交，就永久保存，即使宕机也不丢失。 MySQL实现方式： Redo Log（重做日志）： InnoDB 在事务提交前，会先把修改写到 Redo Log（物理日志）。 Redo Log 是持久保存的，即使 MySQL 崩了，重启时可以用 Redo Log 重放最近的修改。 两阶段提交（特别重要）： 第一步：事务准备好后，写入 Redo Log 并打上 “prepare” 标记。 第二步：事务真正提交，Redo Log 打上 “commit” 标记。 保证即使宕机在 prepare 和 commit 之间，恢复时也能正确决定要回滚还是提交。","link":"/2024/05/06/Mysql%E5%A6%82%E4%BD%95%E5%AE%9E%E7%8E%B0ACID/"},{"title":"Linux文件锁","text":"1、linux文件锁简介Linux中软件、硬件资源都是文件（一切皆文件），文件在多用户环境中是可共享的。 文件锁是用于解决资源的共享使用的一种机制：当多个用户需要共享一个文件时，Linux通常采用的方法是给文件上锁，来避免共享的资源产生竞争的状态。 文件锁包括劝告锁和强制性锁： 劝告锁：要求每个使用上锁文件的进程都要检查是否有锁存在，并且尊重已有的锁。在一般情况下，内核和系统都不使用建议性锁，它们依靠程序员遵守这个规定。 强制锁：是由内核执行的锁，当一个文件被上锁进行写入操作的时候，内核将阻止其他任何文件对其进行读写操作。采用强制性锁对性能的影响很大，每次读写操作都必须检查是否有锁存在。 在Linux中，实现文件上锁的函数有lockf()和fcntl()。fcntl()不仅可以施加建议性锁，还可以施加强制锁。 fcntl()还能对文件的某一记录上锁，也就是记录锁。 劝告锁的加锁规则： 强制锁的加锁规则： 记录锁又可分为读取锁和写入锁，其中读取锁又称为共享锁，它能够使多个进程都能在文件的同一部分建立读取锁。（上面两个图也可以看出） 写入锁又称为排斥锁，在任何时刻只能有一个进程在文件的某个部分建立写入锁。 在文件的同一部分不能同时建立读取锁和写入 2、相关函数目前跟文件加锁相关的系统调用主要有两个： flock与fcntl, 二者在应用范围方面也存在着一些差别，早起的flock函数只能处理劝告锁，在Linux 2.6版本中将其功能扩充至强制锁，另外 flock函数只能对整个文件加锁，不能加记录锁，而fcntl函数则不仅完全支持加劝告锁与强制锁，还支持记录锁，另外因为它符合POSIX标准，具有很好的可移植性。 注意点： 在给文件加锁之前,一定要保证文件以相应的访问模式打开。例如要对一个文件加上共享锁,一定要首先按读模式打开文件,若要给文件加上排他锁,则首先要按写模式打开对应文件若想加两种锁，则需要按读写模式打开. 锁的释放：锁与进程和文件紧密相连，若进程终止，则有它创建的所有锁将会自动释放掉；若关闭文件描述符，则进程由此描述符引用的文件上的任何锁也将会被释放； 由fork产生的子进程不会继承父进程的文件锁； 1 flock123#include &lt;sys/file.h&gt;int flock(int fd, int operation) 相对于fcntl函数，flock显得更加简单，因为所加的锁会影响整个文件，其中operation参数规定了所加锁的类型： LOCK_SH:表示加共享锁 LOCK_EX：表示排他锁 LOCK_UN：表示释放锁 LOCK_MAND：表示强制锁 2 fcntl1234#include &lt;unistd.h&gt;#include &lt;fcntl.h&gt; int fcntl(int fd, int cmd, ... /* struct flock *flockptr */ ); 与锁相关的 cmd 为 F_SETLK、F_SETLKW、F_GETLK，第三个参数 flockptr 是一个 struct flock 结构体指针。使用 fcntl()实现文件锁功能与 flock()有两个比较大的区别： flock()仅支持对整个文件进行加锁/解锁；而 fcntl()可以对文件的某个区域（某部分内容）进行加锁 /解锁，可以精确到某一个字节数据。 flock()仅支持建议性锁类型；而 fcntl()可支持建议性锁和强制性锁两种类型。 1、struct flock我们先来看看 struct flock 结构体，如下所示： 123456789struct flock { ... short l_type; /* Type of lock: F_RDLCK,F_WRLCK, F_UNLCK */ short l_whence; /* How to interpret l_start: SEEK_SET, SEEK_CUR, SEEK_END */ off_t l_start; /* Starting offset for lock */ off_t l_len; /* length, in bytes; 0 means lock to EOF */ pid_t l_pid; /* PID of process blocking our lock(set by F_GETLK and F_OFD_GETLK) */ ...}; 对 struct flock 结构体说明如下： l_type：所希望的锁类型，可以设置为 F_RDLCK、F_WRLCK 和 F_UNLCK 三种类型之一，F_RDLCK 表示共享性质的读锁，F_WRLCK 表示独占性质的写锁，F_UNLCK 表示解锁一个区域。 l_whence 和 l_start：这两个变量用于指定要加锁或解锁区域的起始字节偏移量，与lseek()函数中的 offset 和 whence 参数相同，这里不再重述。 l_len：需要加锁或解锁区域的字节长度。 l_pid：一个 pid，指向一个进程，表示该进程持有的锁能阻塞当前进程，当 cmd=F_GETLK 时有效。 以上便是对 struct flock 结构体各成员变量的简单介绍，对于加锁和解锁区域的说明，还需要注意以下几项规则： 锁区域可以在当前文件末尾处开始或者越过末尾处开始，但是不能在文件起始位置之前开始。若参数 l_len 设置为 0，表示将锁区域扩大到最大范围，也就是说从锁区域的起始位置开始，到文 件的最大偏移量处（也就是文件末尾）都处于锁区域范围内。而且是动态的，这意味着不管向该文件追加写了多少数据，它们都处于锁区域范围，起始位置可以是文件的任意位置。如果我们需要对整个文件加锁，可以将 l_whence 和 l_start 设置为指向文件的起始位置，并且指定参数 l_len 等于 0。 2、cmdfcntl函数专门用来对文件描述符操作的，具体的操作行为取决于cmd值，与本文文件锁相关的cmd值主要有： F_GETLK：获取文件锁 这种用法一般用于测试，测试调用进程对文件加一把由参数 flockptr 指向的 struct flock 对象所描述的锁是否会加锁成功。如果加锁不成功，意味着该文件的这部分区域已经存在一把锁， 并且由另一进程所持有，并且调用进程加的锁与现有锁之间存在排斥关系，现有锁会阻止调用进程想要加的锁，并且现有锁的信息将会重写参数 flockptr 指向的对象信息。如果不存在这种情况，也就是说 flockptr 指向的 struct flock 对象所描述的锁会加锁成功，则除了将 struct flock 对象的 l_type 修改为 F_UNLCK 之外，结构体中的其它信息保持不变。 F_SETLK：设置文件锁（非阻塞版） 对文件添加由 flockptr 指向的 struct flock 对象所描述的锁。譬如试图对文件的某一区域加读锁（l_type 等于 F_RDLCK）或写锁（l_type 等于 F_WRLCK），如果加锁失败，那么 fcntl() 将立即出错返回，此时将 errno 设置为 EACCES 或 EAGAIN。也可用于清除由 flockptr 指向的 struct flock 对象所描述的锁（l_type 等于 F_UNLCK）。 F_SETLKW：设置文件锁（阻塞版） F_GETLK 命令一般很少用，事先用 F_GETLK 命令测试是否能够对文件加锁，然后再用 F_SETLK或F_SETLKW 命令对文件加锁，但这两者并不是原子操作，所以即使测试结果表明可以加锁成功，但是在使 用 F_SETLK 或 F_SETLKW 命令对文件加锁之前也有可能被其它进程锁住。 3、代码示例1、flock1234567891011121314151617181920212223242526272829303132333435363738void *pth_fun(void *pth_arg){ int fd; fd = open(&quot;./hello&quot;, O_RDWR|O_CREAT|O_TRUNC, 0664); if (fd == -1) print_err(&quot;./hello&quot;, __LINE__, errno); while(1) { flock(fd, LOCK_EX); write(fd, &quot;hello &quot;, 6); write(fd, &quot;world\\n&quot;, 6); flock(fd, LOCK_UN); } return NULL;} int main(int argc, char *argv[]){ int fd = -1; int ret = -1; pthread_t tid; fd = open(&quot;./hello&quot;, O_RDWR|O_CREAT|O_TRUNC, 0664); if (fd == -1) print_err(&quot;./hello&quot;, __LINE__, errno); ret = pthread_create(&amp;tid, NULL, pth_fun, NULL); if (ret == -1) print_err(&quot;pthread_create fail&quot;, __LINE__, ret); while(1) { flock(fd, LOCK_EX); write(fd, &quot;hello &quot;, 6); write(fd, &quot;world\\n&quot;, 6); flock(fd, LOCK_UN); } return 0;} 2、fcntl123456789101112131415161718192021222324252627282930313233343536373839404142434445464748#include &lt;stdio.h&gt;#include &lt;stdlib.h&gt;#include &lt;sys/types.h&gt;#include &lt;sys/stat.h&gt;#include &lt;fcntl.h&gt;#include &lt;unistd.h&gt;#include &lt;string.h&gt; int main(int argc, char *argv[]){ struct flock lock = {0}; int fd = -1; char buf[] = &quot;Hello World!&quot;; /* 校验传参 */ if (2 != argc) { fprintf(stderr, &quot;usage: %s &lt;file&gt;\\n&quot;, argv[0]); exit(-1); } /* 打开文件 */ fd = open(argv[1], O_WRONLY); if (-1 == fd) { perror(&quot;open error&quot;); exit(-1); } /* 对文件加锁 */ lock.l_type = F_WRLCK; //独占性写锁 lock.l_whence = SEEK_SET; //文件头部 lock.l_start = 0; //偏移量为 0 lock.l_len = 0; if (-1 == fcntl(fd, F_SETLK, &amp;lock)) { perror(&quot;加锁失败&quot;); exit(-1); } printf(&quot;对文件加锁成功!\\n&quot;); /* 对文件进行写操作 */ if (0 &gt; write(fd, buf, strlen(buf))) { perror(&quot;write error&quot;); exit(-1); } /* 解锁 */ lock.l_type = F_UNLCK; //解锁 fcntl(fd, F_SETLK, &amp;lock); /* 退出 */ close(fd); exit(0);}","link":"/2023/12/03/Linux%E6%96%87%E4%BB%B6%E9%94%81/"},{"title":"Redis主从复制(高可用)","text":"在 Redis 的高可用架构设计中，主从复制（Replication）是一个核心机制。通过主从复制，Redis 可以实现读写分离、故障恢复、数据备份等能力，是构建高可用、高性能系统的基础。 本文将系统讲解 Redis 主从复制的实现原理，包括全量复制、基于长连接的命令传播、以及增量复制三大部分。 一、Redis 主从复制概览在 Redis 中，一个主节点（master）可以有多个从节点（slave）。从节点通过复制主节点的数据和命令，实现与主节点的数据同步。 一旦配置了主从关系，从节点将不断从主节点同步数据，并保持尽可能一致的状态。 1234567891011121314 客户端 | +--------+--------+ | | |写/读操作 读操作 读操作 | | | 主服务器 从服务器 从服务器 | (只读) (只读)写操作同步 | 从服务器 | (只读) Redis 复制的大致流程可以分为： 初次连接时进行全量复制 后续保持基于长连接的命令传播 在连接中断恢复后，进行增量复制 下面逐一详细展开。 二、全量复制（Full Resync）场景： 从节点第一次连接主节点 从节点重启或与主节点断连后重新连接，且无有效增量复制缓存时 流程： 从节点发送 PSYNC 命令请求同步。 如果主节点判定需要全量同步，则： 主节点执行 BGSAVE 操作生成一个RDB快照。 同时将生成 RDB 期间的新写入命令缓存在内存中（复制缓冲区）。 主节点将生成的 RDB 文件通过网络发送给从节点。 从节点收到 RDB 文件后，清空当前数据库并重新载入快照数据。 主节点再把 BGSAVE 期间累积的写命令发送给从节点，保证最终数据一致。 主从连接建立成功，进入持续同步阶段。 注意：全量复制开销大，尤其是数据量很大时，会导致主节点阻塞，影响性能。 三、基于长连接的命令传播（Continuous Command Propagation）场景： 全量复制完成后，主从保持同步状态 主节点持续处理客户端写操作 机制： 主节点将所有写命令实时发送给从节点。 通信基于持久化的 TCP 长连接，使用异步方式。 命令传播使用 Redis 自己的协议（RESP 协议格式）。 从节点接收到命令后，直接在自己的数据库中重新执行这些命令，从而保证数据的一致性。 举例： 如果主节点执行： 1SET key1 value1 主节点会立即将这个命令以协议格式推送给从节点，从节点收到后在本地数据库执行 SET key1 value1。 这种机制可以确保主从之间的数据变化能实时同步。 四、增量复制（Partial Resync）场景： 主从之间的连接短暂中断后（如网络闪断） 从节点重新连接，且主节点仍保留了中断期间的写命令日志 机制： Redis 主节点维护一个复制积压缓冲区（Replication Backlog Buffer）。 它是一个固定大小的环形缓冲区，记录最近一段时间内主节点的写命令。 从节点重连时，带上自己上次同步的位置（offset）请求同步。 主节点比对 offset，如果积压区内仍有需要的数据，就直接发送缺失的命令，无需全量复制。 如果 offset 匹配失败（积压区数据已被覆盖），则退回执行全量复制。 增量复制大大减少了因网络抖动引起的重同步开销，是 Redis 复制机制优化的重要部分。 五、总结Redis 主从复制通过全量复制、基于长连接的命令传播、和增量复制三种机制，实现了高效、实时的数据同步。整体特点是： 初次连接或严重异常时使用全量复制。 正常情况下，基于长连接持续传播命令，保持同步。 短时断连后，使用增量复制快速恢复同步。","link":"/2025/04/21/Redis%E4%B8%BB%E4%BB%8E%E5%A4%8D%E5%88%B6-%E9%AB%98%E5%8F%AF%E7%94%A8/"},{"title":"Redis Cluster 在线扩容","text":"redis采用主从复制+哨兵模式实现高可用，但是主从复制各个节点内数据是一致的。因此，如果需要实现在线扩容就要采用Redis Cluster进行切片集群。 1. 分片机制、哈希槽Redis Cluster方案采用哈希槽（Hash Slot），来处理数据和实例之间的映射关系。 一个分片集群被分为16384个slot（槽），每个进入Redis的键值对，根据key进行散列，分配到这16384插槽中的一个。 然后将各个区间槽分配给不同的节点。 2. MOVED重定向和ASK重定向客户端给一个Redis实例发送数据读写操作时，如果这个实例上并没有相应的数据，示例回复MOVED重定向和ASK重定向。 2.1 Moved 重定向客户端给一个Redis实例发送数据读写操作时，如果计算出来的槽不是在该节点上**(客户端分片访问错误)**，这时候它会返回MOVED重定向错误，MOVED重定向错误中，会将哈希槽所在的新实例的IP和port端口带回去。这就是Redis Cluster的MOVED重定向机制。 2.2 ASK 重定向Ask重定向一般发生于集群伸缩的时候。集群伸缩会导致槽迁移，当我们去源节点访问时，此时数据已经可能已经迁移到了目标节点，使用Ask重定向可以解决此种情况。 2.3 处理流程当客户端向 Redis Cluster 发送请求时，节点按照以下步骤处理请求： 通过哈希槽映射定位 根据 Redis key 计算哈希槽（slot），检查该 slot 是否由当前节点负责。 判断节点是否负责此哈希槽 如果哈希槽不是当前节点负责，直接返回 MOVED 重定向，告诉客户端正确的节点地址。 如果哈希槽是当前节点负责，进入下一步。 检查 key 是否存在于哈希槽中 如果 key 存在，直接返回 key 对应的数据结果。 如果 key 不存在，继续判断。 检查哈希槽是否正在迁出（MIGRATING） 如果该哈希槽正在迁出，说明数据正在从本节点迁移到其他节点。 判断 key 是否正在迁移： 如果 key 正在迁移，返回 ASK 错误，引导客户端临时访问迁移目标节点。 如果 key 没有迁移，继续下一步。 检查哈希槽是否正在导入（IMPORTING） 如果哈希槽正在导入，需要确认客户端是否发送了 ASKING 命令： 如果客户端已经发送了 ASKING 标记，允许直接访问数据。 如果没有 ASKING 标记，返回 MOVED 错误，引导客户端重新访问正确节点。","link":"/2025/04/21/Redis-Cluster-%E5%9C%A8%E7%BA%BF%E6%89%A9%E5%AE%B9/"},{"title":"Redis分布式锁","text":"一、分布式锁的背景需求在单机环境下，我们可以使用synchronized或ReentrantLock来解决多线程并发问题。以库存扣减为例： 123456// 单机版库存扣减public synchronized void deductStock() { if (stock &gt; 0) { stock--; }} 但在微服务架构中，服务部署在多台机器上，JVM级别的锁无法跨进程工作，这时就需要分布式锁来保证集群环境下的互斥访问。 二、Redis分布式锁基础实现1. 最简实现：SETNX + DEL12345# 获取锁（SET if Not eXists）SETNX lock:stock 1# 执行业务逻辑...# 释放锁DEL lock:stock 2. 基础实现的问题问题1：死锁风险如果获取锁后客户端崩溃，锁永远不会释放，导致系统不可用。 解决方案：添加过期时间 12SETNX lock:stock 1EXPIRE lock:stock 10 # 10秒后自动过期 问题2：非原子操作SETNX和EXPIRE是两个命令，中间可能崩溃。 解决方案：使用Redis 2.6.12+的扩展参数 1SET lock:stock 1 NX PX 10000 # 原子操作 三. Redisson实现Redisson是 Redis 官方推荐的 Java 客户端，封装了高可用、可重入、自动续期等完整的分布式锁实现。 1. 基本实现的一些问题问题 1：锁过期但业务仍未完成 如果业务处理耗时超过锁的过期时间，锁将被 Redis 自动释放。此时另一个线程可能获得锁并执行业务，而上一个线程的逻辑还未完成，从而导致业务重叠 解决方案:Redisson的Watch dog（看门狗）自动续租。 Redisson 默认给锁加一个 30 秒的 TTL，并启动一个后台“看门狗”线程，在业务未完成前会自动续租，避免锁过期被提前释放。 默认续期间隔为 10 秒（1/3）； 如果业务超时或宕机，锁也会最终自动释放，避免死锁。 问题2：继3后的连锁反应，当前线程释放别的线程的锁。（上一个未完成却过期释放的线程释放锁，会导致下一个业务也提前释放锁，连锁反应，出现超卖。） 解决方案：唯一 ID 防止误删。Redisson 给每个锁设置一个UUID + 线程ID 的唯一标识，只有持有锁的线程才能解锁，防止误删他人锁。 2.Redisson 实现可重入在 Java 中，我们习惯使用可重入锁（如 ReentrantLock）。Redisson 同样提供了类似特性： 核心思路： 使用 Redis 的 Hash 数据结构，记录线程 ID 与重入次数； 每次加锁时判断当前线程是否已持有锁，若是则递增计数； 解锁时递减计数，只有计数为 0 时才真正删除锁。 实际Hash结构如： lock_key =&gt; {threadId1: count1, threadId2: count2} lua脚本： 1234567891011121314151617181920212223242526-- 可重入分布式锁加锁逻辑-- KEYS[1]：锁的 key，如 &quot;lock:order:123&quot;-- ARGV[1]：锁的过期时间（单位：毫秒），如 30000-- ARGV[2]：唯一标识（例如线程 UUID）-- 第一种情况：锁不存在，说明当前无线程持有锁if (redis.call('exists', KEYS[1]) == 0) then -- 创建一个哈希结构记录线程唯一标识及重入次数为 1 redis.call('hset', KEYS[1], ARGV[2], 1); -- 设置锁的过期时间，避免死锁 redis.call('pexpire', KEYS[1], ARGV[1]); return nil; -- 表示加锁成功end;-- 第二种情况：锁存在，但是当前线程（重入）if (redis.call('hexists', KEYS[1], ARGV[2]) == 1) then -- 当前线程重入加锁，重入计数 +1 redis.call('hincrby', KEYS[1], ARGV[2], 1); -- 每次重入都要重置过期时间 redis.call('pexpire', KEYS[1], ARGV[1]); return nil; -- 表示加锁成功（重入）end;-- 第三种情况：锁存在，且不是当前线程（被别人占用）-- 返回剩余过期时间（毫秒），供调用方决定是否等待或失败返回return redis.call('pttl', KEYS[1]); 3. Redisson 如何安全释放锁（Lua 脚本 + 发布订阅机制）(1) 使用 Lua 脚本释放锁确保释放的是自己加的锁： 123if redis.call(&quot;hget&quot;, KEYS[1], ARGV[1]) then -- 递减计数，如果为 0 则删除整个 keyend 这样可以保证原子性操作，防止并发误删。 (2) 阻塞与唤醒机制：Redis Pub/SubRedisson 锁还支持阻塞等待功能（类似 Java 的 lock.lock() 阻塞式获取锁）： 如果获取锁失败，Redisson 会订阅一个 Redis Channel； 一旦锁被释放，会发布解锁消息； 阻塞线程收到消息后会被唤醒继续尝试获取锁。 这种方式避免了“死循环轮询”，实现高效的锁等待。 4.Redlock 分布式锁算法（多节点一致性)如果 Redis 是主从结构，在主节点写入成功但还没同步到从节点时主挂了，锁数据就可能丢失。 为了解决 Redis 主从架构下的数据一致性问题，Redlock 应运而生。 Redlock 核心思路： 同时向 多个独立 Redis 实例 写入锁（推荐 5 个节点）； 超过半数节点成功则认为加锁成功； 总耗时必须小于锁超时时间； 失败时回滚已获得的锁。 四. 基于Redis分布式锁总结 阶段 实现方式 特性 存在的问题 简单版 SETNX + EXPIRE + DEL 实现基础互斥 存在超时释放/误删风险 优化版 SET + NX + PX + 唯一ID + Lua 保证原子释放 无重入/续期机制 Redisson Watchdog + 可重入 + 唤醒阻塞 + Lua 企业级封装，支持高并发 引入第三方依赖 Redlock 多 Redis 节点写入 + 半数成功 高可用高一致性 实现复杂，易争议 参考资料：https://www.bilibili.com/video/BV1nk4y1u781/?spm_id_from=333.1387.favlist.content.click&amp;vd_source=0ff05116367aae8f8480fddf5a565ea6 https://www.bilibili.com/video/BV1Yz421r74Z/?spm_id_from=333.337.search-card.all.click&amp;vd_source=0ff05116367aae8f8480fddf5a565ea6","link":"/2025/05/06/Redis%E5%88%86%E5%B8%83%E5%BC%8F%E9%94%81/"},{"title":"Redis哨兵机制(高可用)","text":"Redis 哨兵机制（Sentinel）是 Redis 官方提供的一种高可用解决方案，旨在实现主从架构下的自动故障转移和系统监控。本文将深入解析哨兵机制的原理、关键组件及其工作流程。 什么是 Redis 哨兵机制？Redis 哨兵机制是一个独立的进程，专门用于监控 Redis 主从架构中的各个节点状态。其主要功能包括： 监控（Monitoring）：持续检查主节点和从节点的运行状态，进行主观下线、客观下线的判断。 自动故障转移（Automatic Failover）：当主节点无法正常工作时，哨兵会自动将其中一个从节点升级为新的主节点，并让其他从节点改为复制新的主节点。 通知（Notification）：当被监控的 Redis 实例出现问题时，哨兵可以通过 API 向管理员或其他应用程序发送通知。 配置提供者（Configuration Provider）：客户端在初始化时，可以通过连接哨兵来获得当前 Redis 服务的主节点地址。 注意：哨兵的个数需大于等于3（由于选举机制需要）, 且与节点数量无直接关系。 哨兵机制的核心原理1. 主观下线与客观下线 主观下线（Subjective Down, SDOWN）：当某个哨兵节点在指定时间内未能与主节点通信（ping-pong机制），认为主节点不可用。 客观下线（Objective Down, ODOWN）：通过哨兵间通信，当多个哨兵节点都认为主节点不可用，并达成一致意见后，确认主节点确实不可用。 哨兵通过配置项 down-after-milliseconds 来设置判断主观下线的时间阈值。而 quorum 参数则指定了确认客观下线所需的最少哨兵数量。 2. 领导者选举与故障转移当主节点被判定为客观下线后，哨兵集群会通过投票选举出一个领导者哨兵（Leader Sentinel），由其负责执行故障转移操作： 选择新主节点：从现有的从节点中选择一个最合适的节点升级为主节点。 重新配置复制关系：将其他从节点配置为复制新的主节点。 通知客户端：更新客户端的主节点信息，确保其连接到新的主节点。 在选择新的主节点时，哨兵会考虑从节点的优先级、复制偏移量等因素，以确保数据的完整性和一致性。 领导者哨兵选举： ​ 为解决同时有多个哨兵同时发现客观下线，进行冲突的主节点选取。因此在判断主节点客观下线后，进行leader哨兵选举（进行主节点选择）。 ​ 具体原理：通过特定协议，每个哨兵只能投1次票（先发送投票请求的候选者优先），但票数大于半数或设置值，则选为leader哨兵。 总结流程： 监控：哨兵节点定期向主从节点发送 PING 命令，检测其是否在线。 判断下线：如果在 down-after-milliseconds 时间内未收到响应，哨兵将该节点标记为主观下线。 协商一致：多个哨兵节点通过通信，确认主节点是否客观下线。 选举领导者：通过投票机制选出一个领导者哨兵，负责执行故障转移。 故障转移：领导者哨兵选择新的主节点，重新配置复制关系，并通知客户端。","link":"/2025/04/21/Redis%E5%93%A8%E5%85%B5%E6%9C%BA%E5%88%B6-%E9%AB%98%E5%8F%AF%E7%94%A8/"},{"title":"Redis缓存与数据库一致性问题","text":"1. 背景随着网站用户量和访问量的增加，数据库IO性能逐渐成为系统服务的瓶颈。为了缓解数据库压力、加速数据访问，通常会引入Redis缓存组件。其主要目标是： 减少数据库查询次数 加速系统查询响应 提升整体并发处理能力 缓存思想在计算领域广泛应用，例如通过打表法（预先计算并存储结果），避免重复计算，提升访问效率，本质上就是一种缓存策略的体现。 应用场景：热点数据（计数器、统计等）、要求响应速度极快的数据读取注意：redis+DB只支持弱一致性（最终一致）。对于写频繁、一致性要求高（如支付等）应尽量避免。 Redis缓存与数据库数据不一致的问题：缓存与数据库之间存在天然的双写问题，因此可能出现缓存中的数据与数据库实际数据不同步的情况。 可以将缓存类型分为两种进行分析： 2. 读写缓存读写缓存，即对缓存同时有读和修改操作。在数据增删改时，同时操作缓存，并根据策略同步或异步更新数据库。 同步直写策略（推荐）：同时写缓存和数据库，可保持数据一致性。 异步写回策略：只写缓存，不同步写数据库，等数据淘汰再写回数据库，容易引发数据丢失问题。 结论：读写缓存建议使用同步直写策略。 3. 只读缓存（redis更常用）在实际项目中，Redis更常作为只读缓存。 Redis主要承担加速读取、减少数据库读压力的角色。 数据写入只操作数据库，由数据库负责数据一致性和持久化，Redis只做副本缓存。好处在于：保证数来源单一、 避免复杂的同步逻辑 新增数据直接写数据库，不操作缓存；修改或删除数据时，需要更新数据库并删除缓存。 一致性解决方案： 先删除缓存，再更新数据库（不推荐） 先更新数据库，再删除缓存（推荐） 延时双删（推荐，由先删后更新改进） 3.1 “先删除缓存，再更新数据库”的潜在风险具体步骤如下： 线程A执行删除缓存（成功）。 线程B立刻发起查询请求，发现缓存没有（缓存 miss），于是去数据库查询。 此时，线程A还没有更新数据库（更新还在进行或未完成），线程B查询到的是旧数据。 线程B把这个旧数据回写到缓存中（缓存重新构建，但内容是旧的！）。 最后线程A更新数据库完成，但缓存中却保存着旧值，数据不一致！ 1234567891011线程A（写操作） 线程B（读操作） ↓ ↓[1] 删除缓存 (Redis.del) | ↓ |[2] （还没来得及更新DB） [3] 查询缓存，发现没有 ↓ [4] 读取数据库（旧值） ↓ [5] 将旧值写入缓存 ↓[6] 更新数据库（写入新值） 3.2 ”先更新数据库，再删除缓存“潜在风险风险1：删除缓存失败 数据库已经更新成功，但是删除缓存失败（比如Redis故障、网络波动、程序异常），导致缓存中仍然保留着旧数据。 后果：用户查询时，命中的是过期的缓存数据，而不是更新后的数据库内容，出现数据不一致。如果缓存设置了较长的TTL，旧数据可能持续存在，影响时间较长。 风险2：并发读请求导致短暂不一致 线程A正在执行”更新数据库 -&gt; 删除缓存” 中间这段时间窗口，如果线程B发起了读请求 线程B可能命中了还没被删除的旧缓存 1234567线程A（写操作） 线程B（读操作） ↓ ↓[1] 更新数据库 (成功) | ↓ |[2] 准备删除缓存 [3] 查询缓存 (此时缓存未删) ↓ ↓[4] 删除缓存成功或失败 [5] 命中旧缓存，读取到旧数据 后果：虽然缓存最终会被删除，但在很短的时间窗口内，读取到的是旧数据。 3.3 延时双删删除缓数据，更新数据库，延迟（如几百毫秒）再删除缓存。 解决了先删后更更新导致的长时间数据不一致问题。 优点: 在高并发环境下，能有效减少数据不一致的概率。 通过第二次删除缓存，清除可能被并发线程回写的旧数据，增强数据一致性。 虽然不能完全杜绝异常，依旧是弱一致性（最终一致），但能有效降低数据不一致的时间窗口，适合大部分业务场景。 3.4 总结”先删缓存后更新数据库”其隐含的并发问题更严重，因为窗口期（删除缓存到更新完数据库）读数据、更新了 缓存，且长时间的保持着旧数据（直到下一个写或过期）。 而“先更新数据库后删除缓存”，窗口期小（更新完数据库到删除缓存），因此并发问题概率更小，并且即使并发问题，也只会很短暂的窗口期读到错误数据。 延迟双删策略适合于那些需要在高并发环境下保证缓存与数据库一致性的场景，特别是在更新操作频繁的系统中，如电商、社交平台等需要对大量缓存数据进行频繁更新的应用场景。","link":"/2025/04/18/Redis%E7%BC%93%E5%AD%98%E4%B8%8E%E6%95%B0%E6%8D%AE%E5%BA%93%E4%B8%80%E8%87%B4%E6%80%A7%E9%97%AE%E9%A2%98/"},{"title":"Scanner的用法","text":"scanner的用法1.1常用a= s.next; b= s.nextLine(); c= s.nextInt(); 1.2例子：12345678910111213141516171819202122232425public class Text { public static void main(String []args) { Scanner input = new Scanner(System.in); System.out.println(&quot;请输入一个字符串(中间能加空格或符号)&quot;); String a = input.nextLine(); System.out.println(&quot;请输入一个字符串(中间不能加空格或符号)&quot;); String b = input.next(); System.out.println(&quot;请输入一个整数&quot;); int c; c = input.nextInt(); System.out.println(&quot;请输入一个double类型的小数&quot;); double d = input.nextDouble(); System.out.println(&quot;请输入一个float类型的小数&quot;); float f = input.nextFloat(); System.out.println(&quot;按顺序输出abcdf的值：&quot;); System.out.println(a); System.out.println(b); System.out.println(c); System.out.println(d); System.out.println(f); input.close(); }} 1.3判断是否输入​ 程序会在 123if(hasNext()；){ String a=s.next} 位置等待输入，然后继续程序 此类代码有： hasNext(); hasNextLine(); 1.4注：IO流工具用完后必须关闭如上述例子中：input.close();","link":"/2020/12/05/Scanner%E7%9A%84%E7%94%A8%E6%B3%95/"},{"title":"Spring IOC(控制反转) 与 DI(依赖注入)","text":"本文总结了Spring中的IoC（控制反转）与DI（依赖注入）机制， 介绍了IoC和DI的基本概念、三种常见的依赖注入方式及其优缺点 源码解析了Spring IoC容器的整体流程，包括配置解析、Bean注册、实例化、依赖注入与初始化的核心步骤。 一、IOC、DI 是什么IOCIOC（Inversion of Control，控制反转）思想，把对象控制权从自己手里反转交给容器。 一句话解释： IOC 是把对象的创建、管理交给 Spring 容器来负责，而不是自己在代码里 new 出来。 更细一点： 在传统开发中，我们需要自己控制对象的创建和依赖，比如 new 一个服务对象。而自己new服务对象、传入依赖对象、管理生存周期是一件复杂繁琐的事情。 在有了 IOC 之后，Spring 容器负责： 帮你创建对象（比如 Service、Repository 等） 维护对象之间的依赖关系 管理对象的生命周期（创建、销毁等） 这样，开发者只关心怎么用对象，不关心怎么创建对象。 DIDI（Dependency Injection，依赖注入） 是实现IOC的手段，容器主动把依赖对象注入进来。 在Spring中，常用的三种注入方式： 注入方式 说明 优缺点 构造器注入 通过构造函数注入 推荐 ✅，依赖不可变，适合强制依赖 Setter注入 通过setter方法注入 可选依赖时使用，灵活但可能出现半初始化 字段注入 直接在属性上用 @Autowired 简洁但不利于测试（一般开发中最常用） 示例： ✅ 构造器注入（推荐写法，尤其在现代Spring Boot里） 123456789@Servicepublic class UserService { private final UserRepository userRepository; @Autowired public UserService(UserRepository userRepository) { this.userRepository = userRepository; }} ✅ Setter注入 123456789@Servicepublic class UserService { private UserRepository userRepository; @Autowired public void setUserRepository(UserRepository userRepository) { this.userRepository = userRepository; }} ✅ 字段注入（最常见） 12345@Servicepublic class UserService { @Autowired private UserRepository userRepository;} 缺点在于不适合测试，含不可预见因素。原因在于基于反射，暴力赋值。 12345// 伪代码解释Spring干了什么UserService userService = new UserService(); // 直接new，没有注入Field field = UserService.class.getDeclaredField(&quot;userRepository&quot;);field.setAccessible(true); // 暴力破解privatefield.set(userService, userRepositoryBean); // 把依赖塞进去 二、Spring IoC 原理与核心源码解析2.1 IOC原理整体流程，主要分成4步： 阶段 做什么事情 1. 读取配置 读取 XML/注解/JavaConfig，解析 Bean 元数据 2. 注册Bean定义 扫描出相关bean描述，并把Bean定义（BeanDefinition）注册到容器内部（Map里） 3. 实例化对象 按需实例化Bean（调用构造器/工厂方法） 4. 注入依赖 &amp; 初始化 依赖注入 + 调用初始化方法等，最终Bean可用 简易流程图： 1配置 --&gt; 扫描BeanDefinition --&gt; 注册到容器 --&gt; bean实例化--&gt;依赖注入 --&gt; 初始化 --&gt; Bean使用 --&gt; Bean销毁 2.2 IOC核心源码解析这部分是最硬核的，我带你看一遍真正Spring（比如5.x）的源码思路。 1. 容器启动入口：refresh()一般我们启动容器是这样： 12AnnotationConfigApplicationContext context = new AnnotationConfigApplicationContext(AppConfig.class);context.refresh(); 实际上容器启动的核心逻辑都在refresh()方法里。 refresh()做了哪些事情？ （略简化版） 1234567891011121314public void refresh() throws BeansException, IllegalStateException { prepareRefresh(); // 1.准备工作（环境、监听器、验证配置） ConfigurableListableBeanFactory beanFactory = obtainFreshBeanFactory(); // 2.创建BeanFactory，并加载BeanDefinition定义 ** prepareBeanFactory(beanFactory); // 3.设置一些常用类到容器，比如ApplicationContext本身 postProcessBeanFactory(beanFactory); // 4.BeanFactory后置处理器（留给子类扩展） invokeBeanFactoryPostProcessors(beanFactory); // 5.执行所有BeanFactoryPostProcessor registerBeanPostProcessors(beanFactory); // 6.注册所有BeanPostProcessor initMessageSource(); // 7.国际化相关 initApplicationEventMulticaster(); // 8.事件广播器初始化 onRefresh(); // 9.留给子类扩展 registerListeners(); // 10.注册应用监听器 finishBeanFactoryInitialization(beanFactory); // 11.初始化剩余的单例Bean ** finishRefresh(); // 12.容器刷新完成事件} ➡️ 重点是 obtainFreshBeanFactory() 和 finishBeanFactoryInitialization(beanFactory) 这两步。 2. BeanDefinition加载：obtainFreshBeanFactory()这一步干的事： 创建一个新的DefaultListableBeanFactory 解析配置（XML、注解、JavaConfig） 把每个Bean的信息封装成BeanDefinition 注册到容器里的Map里（beanDefinitionMap） 重要类： BeanDefinitionReader AnnotatedBeanDefinitionReader XmlBeanDefinitionReader 核心数据结构： 1Map&lt;String, BeanDefinition&gt; beanDefinitionMap; // BeanName,BeanDefinition 相当于提前把【蓝图】画好了，随时可以造。 3. 实例化Bean：finishBeanFactoryInitialization(beanFactory)这一步最重要！ 创建真正的Bean实例，并做依赖注入、初始化。 核心方法： 1beanFactory.preInstantiateSingletons(); 它会遍历所有的BeanDefinition，把单例的Bean提前实例化好。 具体怎么实例化的？ 调用了： 1createBean(beanName, mbd, args); ➡️ 进入了AbstractAutowireCapableBeanFactory里的超重要方法！ 4. createBean()核心流程1234567891011121314protected Object createBean(String beanName, RootBeanDefinition mbd, @Nullable Object[] args) { Object bean; try { // 1.实例化Bean（构造器 or 工厂方法） bean = resolveBeforeInstantiation(beanName, mbd);//前置代理创建，如AOP if (bean == null) { bean = doCreateBean(beanName, mbd, args);//实例化Bean } } catch (Exception ex) { throw new BeanCreationException(...); } return bean;} 继续追进doCreateBean： 123456789protected Object doCreateBean(String beanName, RootBeanDefinition mbd, @Nullable Object[] args) { // 1.创建实例 Object beanInstance = createBeanInstance(beanName, mbd, args); // 2.依赖注入（填充属性） populateBean(beanName, mbd, instanceWrapper); // 3.初始化（调用@PostConstruct、InitializingBean等） initializeBean(beanName, exposedObject, mbd); return exposedObject;} 也就是说： createBeanInstance() —— 实例化对象 populateBean() —— 注入依赖 initializeBean() —— 初始化方法 5. 核心源码总结流程整体大概是这样： 12345678910111213refresh() --&gt; obtainFreshBeanFactory() --&gt; 加载BeanDefinition --&gt; 注册到beanDefinitionMap --&gt; finishBeanFactoryInitialization() --&gt; preInstantiateSingletons() --&gt; getBean(beanName) --&gt; doGetBean() --&gt; createBean() --&gt; doCreateBean() --&gt; createBeanInstance() //实例化 【构造器注入】 --&gt; populateBean() //填充属性【setter注入、字段注入】 --&gt; initializeBean() //初始化方法 总结：🔵 目的： 自动管理对象创建和依赖关系，提高解耦，灵活扩展。 🟢 原理： 先读取配置，解析成BeanDefinition注册，延迟到用时实例化，自动依赖注入，自动初始化。 🟣 核心源码： refresh()是大总管，createBean()是造对象的大核心。","link":"/2025/04/22/Spring%20IOC(%E6%8E%A7%E5%88%B6%E5%8F%8D%E8%BD%AC)%E4%B8%8EDI(%E4%BE%9D%E8%B5%96%E6%B3%A8%E5%85%A5)/"},{"title":"Spring Boot启动内嵌Tomcat 的全过程","text":"本质上是： Spring Boot 在应用启动过程中，通过自动配置创建 TomcatWebServer，并在容器 refresh() 阶段通过生命周期管理器自动调用 Tomcat.start() 启动 Web 服务。 本源码分析基于springboot 3.4.2 12345678910111213SpringApplication.run(...) 【应用入口】 └── 创建 ApplicationContext（Servlet 类型） └── context.refresh() 【启动核心】 ├── onRefresh() 【步骤①：创建 WebServer】 │ └── createWebServer() │ └── TomcatWebServer(...) ← 创建但尚未启动 └── finishRefresh() └── lifecycleProcessor.onRefresh() 【步骤②：启动 WebServer】 └── startBeans() └── WebServerStartStopLifecycle.start() └── TomcatWebServer.start() └── tomcat.start() ✅ 正式监听端口 🔍 详细流程拆解① 创建 TomcatWebServer（但不启动）位置：ServletWebServerApplicationContext#createWebServer() 1this.webServer = factory.getWebServer(getSelfInitializer()); // 创建 TomcatWebServer 这里实例化了 TomcatWebServer 调用了构造方法，但 没有主动调用 .start() 同时注册了两个管理 bean： 1getBeanFactory().registerSingleton(&quot;webServerStartStop&quot;, new WebServerStartStopLifecycle(...)); 这个 WebServerStartStopLifecycle 是个关键对象，它实现了 Lifecycle 接口，会由 Spring 自动启动。 ② Spring 容器 refresh() 过程中自动启动 WebServer位置：AbstractApplicationContext#refresh() → finishRefresh() 12345protected void finishRefresh() { ... getLifecycleProcessor().onRefresh(); // 触发生命周期 bean 的 start() ...} getLifecycleProcessor() 返回的是 DefaultLifecycleProcessor，它会扫描容器中所有实现了 Lifecycle 的 bean，调用它们的 start() 方法。 ③ 启动 Tomcat 的地方位置：WebServerStartStopLifecycle#start() 1this.webServer.start(); // 最终调用 → 对象是 TomcatWebServer，继续跟进去： 位置：TomcatWebServer#start() 1this.tomcat.start(); // ✅ 真正启动内嵌 Tomcat 这一步包括： 启动 Connector 绑定端口（默认 8080） 启动 servlet 容器线程池 应用开始监听请求 ✅ 最核心的两个调用点 阶段 调用点 作用 创建 createWebServer() 创建 Tomcat 实例，但不启动 启动 WebServerStartStopLifecycle#start() 触发 TomcatWebServer.start() 启动 Tomcat","link":"/2025/04/23/Spring-Boot%E5%90%AF%E5%8A%A8%E5%86%85%E5%B5%8CTomcat-%E7%9A%84%E5%85%A8%E8%BF%87%E7%A8%8B/"},{"title":"Typora添加数学公式","text":"参考博客https://blog.csdn.net/wjr1229/article/details/128055766参考博客 一、添加方式1.点击“段落”→“公式块”2.快捷Ctrl+Shift+m3.“$$”+Enter4.”$$“在中间输入代码(内联)二、常用公式代码 详细见参考博客","link":"/2023/11/02/Typora%E6%B7%BB%E5%8A%A0%E6%95%B0%E5%AD%A6%E5%85%AC%E5%BC%8F/"},{"title":"UnixDomainSocket","text":"unixDomainSocket简介unixDomainSocket是同一机器上进程间通信的方式。USD通过同网络Socket几乎相同的操作，在内存上，实现进程间通信。USD不必实现网络协议栈、也无需拷贝到内核缓冲区，因此比127.0.0.1的网络socket通信更快。 UDS使用​ Unix Domain Socket（后面统一简称 UDS） 使用起来和传统的 socket 非常的相似。 ​ 第一，在创建 socket 的时候，普通的 socket 第一个参数 family 为 AF_INET， 而 UDS 指定为 AF_UNIX 即可。 ​ 第二，Server 的标识不再是 ip 和 端口，而是一个路径，例如 /dev/shm/fpm-cgi.sock。 服务端：1、包含头文件： 12#include &lt;sys/socket.h&gt; // 套接字相关函数和结构#include &lt;sys/un.h&gt; // Unix域套接字相关结构 2、创建套接字： 1234int sockfd = socket(AF_UNIX, SOCK_STREAM, 0);if (sockfd == -1) { // 处理套接字创建失败的情况} 3、绑定套接字到文件路径： 12345678struct sockaddr_un addr;memset(&amp;addr, 0, sizeof(struct sockaddr_un));addr.sun_family = AF_UNIX;strncpy(addr.sun_path, &quot;/path/to/socket&quot;, sizeof(addr.sun_path) - 1);if (bind(sockfd, (struct sockaddr*)&amp;addr, sizeof(struct sockaddr_un)) == -1) { // 处理套接字绑定失败的情况} 4、监听连接： 123if (listen(sockfd, backlog) == -1) { // 处理监听失败的情况} 5、接收连接请求 1234int clientfd = accept(sockfd, nullptr, nullptr);if (clientfd == -1) { // 处理接受连接失败的情况} 6、数据读写 12345678910char buffer[1024];ssize_t bytesRead = recv(clientfd, buffer, sizeof(buffer), 0);if (bytesRead == -1) { // 处理接收数据失败的情况}ssize_t bytesWritten = send(clientfd, buffer, bytesRead, 0);if (bytesWritten == -1) { // 处理发送数据失败的情况} 7、关闭套接字： 12close(sockfd);close(clientfd); 客户端：1、包含头文件： 12#include &lt;sys/socket.h&gt; // 套接字相关函数和结构#include &lt;sys/un.h&gt; // Unix域套接字相关结构 2、创建套接字： 1234int sockfd = socket(AF_UNIX, SOCK_STREAM, 0);if (sockfd == -1) { // 处理套接字创建失败的情况} 3、连接到服务器： 12345678struct sockaddr_un serverAddr;memset(&amp;serverAddr, 0, sizeof(struct sockaddr_un));serverAddr.sun_family = AF_UNIX;strncpy(serverAddr.sun_path, &quot;/path/to/socket&quot;, sizeof(serverAddr.sun_path) - 1);if (connect(sockfd, (struct sockaddr*)&amp;serverAddr, sizeof(struct sockaddr_un)) == -1) { // 处理连接失败的情况} 4、进行数据读写： 12345678910char buffer[1024];ssize_t bytesRead = recv(sockfd, buffer, sizeof(buffer), 0);if (bytesRead == -1) { // 处理接收数据失败的情况}ssize_t bytesWritten = send(sockfd, buffer, bytesRead, 0);if (bytesWritten == -1) { // 处理发送数据失败的情况} 5、关闭套字节 1close(sockfd); 整体示例：服务端 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485868788#include &lt;iostream&gt;#include &lt;unistd.h&gt;//1、包含两个头文件#include &lt;sys/socket.h&gt; // 套接字相关函数和结构#include &lt;sys/un.h&gt; // Unix域套接字相关结构#define SOCKET_PATH &quot;./unix_socket_demo&quot;int main(){ // 2、创建套接字 int sockfd = socket(AF_UNIX, SOCK_STREAM, 0); if (sockfd == -1) { std::cerr &lt;&lt; &quot;Failed to create socket&quot; &lt;&lt; std::endl; return 1; } // 3、绑定套接字到文件路径 struct sockaddr_un serverAddr; memset(&amp;serverAddr, 0, sizeof(struct sockaddr_un)); serverAddr.sun_family = AF_UNIX; unlink(SOCKET_PATH); // arnold add 20230608 // 要unlink一下，否则无法重新绑定 strncpy(serverAddr.sun_path, SOCKET_PATH, sizeof(serverAddr.sun_path) - 1); if (bind(sockfd, (struct sockaddr *)&amp;serverAddr, sizeof(struct sockaddr_un)) == -1) { std::cerr &lt;&lt; &quot;Failed to bind socket&quot; &lt;&lt; std::endl; close(sockfd); return 1; } // 4、监听连接 if (listen(sockfd, 5) == -1) { std::cerr &lt;&lt; &quot;Failed to listen&quot; &lt;&lt; std::endl; close(sockfd); return 1; } while (true) { std::cout &lt;&lt; &quot;Waiting for client connection...&quot; &lt;&lt; std::endl; // 5、接受连接请求 int clientfd = accept(sockfd, nullptr, nullptr); if (clientfd == -1) { std::cerr &lt;&lt; &quot;Failed to accept connection&quot; &lt;&lt; std::endl; close(sockfd); return 1; } std::cout &lt;&lt; &quot;Client connected!&quot; &lt;&lt; std::endl; // 6、接收和发送数据 char buffer[1024]; ssize_t bytesRead; while ((bytesRead = recv(clientfd, buffer, sizeof(buffer), 0)) &gt; 0) { std::cout &lt;&lt; &quot;Received message from client: &quot; &lt;&lt; buffer &lt;&lt; std::endl; // 在此处进行需要的处理 // 发送回复给客户端 ssize_t bytesWritten = send(clientfd, buffer, bytesRead, 0); if (bytesWritten == -1) { std::cerr &lt;&lt; &quot;Failed to send response to client&quot; &lt;&lt; std::endl; close(clientfd); break; } } if (bytesRead == -1) { std::cerr &lt;&lt; &quot;Failed to receive data from client&quot; &lt;&lt; std::endl; } std::cout &lt;&lt; &quot;Client disconnected&quot; &lt;&lt; std::endl; close(clientfd); } //7、关闭套接字 close(sockfd); return 0;} 客户端 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596#include &lt;iostream&gt;#include &lt;unistd.h&gt;//1、包含头文件#include &lt;sys/socket.h&gt; // 套接字相关函数和结构#include &lt;sys/un.h&gt; // Unix域套接字相关结构#define SOCKET_PATH &quot;./unix_socket_demo&quot;int main(){ //2、创建套接字 int sockfd = socket(AF_UNIX, SOCK_STREAM, 0); if (sockfd == -1) { std::cerr &lt;&lt; &quot;Failed to create socket&quot; &lt;&lt; std::endl; return 1; } //3、连接到服务器 struct sockaddr_un serverAddr; memset(&amp;serverAddr, 0, sizeof(struct sockaddr_un)); serverAddr.sun_family = AF_UNIX; strncpy(serverAddr.sun_path, SOCKET_PATH, sizeof(serverAddr.sun_path) - 1); while (true) { while (true) { if (connect(sockfd, (struct sockaddr *)&amp;serverAddr, sizeof(struct sockaddr_un)) == -1) { // std::cerr &lt;&lt; &quot;Failed to connect to server&quot; &lt;&lt; std::endl; std::cerr &lt;&lt; &quot;Failed to connect to server, sleep 1s and reconnect...&quot; &lt;&lt; std::endl; sleep(1); continue; // close(sockfd); // return 1; } break; } std::cout &lt;&lt; &quot;Connected to server!&quot; &lt;&lt; std::endl; while (true) { try // 貌似这里try多余了，如果服务端是被强行关闭的，客户端这里是捕获不到的，也会强行结束 { // 输入要发送的消息 // std::cout &lt;&lt; &quot;Enter message to send (or 'q' to quit): &quot;; // std::string message; std::string message = &quot;client auto send a message&quot;; // std::getline(std::cin, message); // if (message == &quot;q&quot;) // { // break; // } // 发送消息给服务器 ssize_t bytesWritten = send(sockfd, message.c_str(), message.length(), 0); if (bytesWritten == -1) { std::cerr &lt;&lt; &quot;Failed to send message to server&quot; &lt;&lt; std::endl; break; // close(sockfd); // return 1; } sleep(1); // 接收服务器的回复 char buffer[1024]; ssize_t bytesRead = recv(sockfd, buffer, sizeof(buffer) - 1, 0); if (bytesRead == -1) { std::cerr &lt;&lt; &quot;Failed to receive response from server&quot; &lt;&lt; std::endl; break; // close(sockfd); // return 1; } buffer[bytesRead] = '\\0'; std::cout &lt;&lt; &quot;Received response from server: &quot; &lt;&lt; buffer &lt;&lt; std::endl; } catch(std::exception&amp; e) { std::cout &lt;&lt; &quot;catch(std::exception&amp; e): &quot; &lt;&lt; e.what() &lt;&lt; std::endl; break; } } // std::cout &lt;&lt; &quot;Disconnecting from server&quot; &lt;&lt; std::endl; // close(sockfd); // return 0; }} UDS性能分析性能上，UDS的流式传输在小包和中包情况下，UDS传输的速度大致是TCP（127.0.0.1）的两倍。 参考于文章： https://zhuanlan.zhihu.com/p/448373622 测试源码： https://github.com/rigtorp/ipc-bench UDS高性能的原因： Unix域套接字在本地通信中不涉及网络协议栈，因此避免了网络协议栈的开销。相比之下，网络套接字需要在网络协议栈中打包拆包、计算校验和、维护序号和应答，因此相对来说更慢。 内存拷贝少，Unix域套接字在进程间传递数据时，可以直接在内存中进行数据传递，而不需要通过内核缓冲区（直接由内核从一个进程的缓冲区拷贝到另一个进程的缓冲区）。而网络套接字的数据传输则需要经过内核的多次拷贝，从用户空间到内核空间再到网络协议栈，因此产生了更多的内存拷贝操作。 此外，unixDomainSocket进行进程间通信，比起基于文件的读写进行进程通信具有更快地速度，USD的数据传输是在内存上完成的，而基于文件读写的通信需要磁盘io操作。 一个容易引起误解的点在于，USD是通过文件路径名来标记的（网络Socket则通过IP、端口标识），但在socket上发生的IO（数据的读写）无需对底层设备进行操作，仅在内存中拷贝。具体来说，当用户来绑定UDS时，bind()会在文件系统中创建一条条目（因此，作为socket的路径名的一部分的目录需要可访问可写）。这个文件会被标记成socket。你可以使用ls-l列出时，UnixDomainSocket会在第一类显示类型s。在该路径名stat()时，他会在stat结构的st_mode字段中文件类型部分返回S_IFSOCK。 参考文章： https://blog.csdn.net/Dontla/article/details/131114439 https://zhuanlan.zhihu.com/p/448373622 https://www.zhihu.com/question/349986127","link":"/2023/11/30/UnixDomainSocket/"},{"title":"c 编译、链接、debug","text":"1、编译链接对于大项目来说，将所有的c的函数代码全放在一个.c文件中不大可能。同时，分开编译链接的好处在于，将一些函数分到其他.c文件中，分开编译使得一部分文件每次修改后不必重新编译。 Main.cpp 12345678910111213141516#include &lt;isostream&gt;#include &quot;mul.hpp&quot;using namespace std;int main(){ int a,b; int result; cout &lt;&lt; &quot;Pick two integers:&quot;; cin &gt;&gt; a; cin &gt;&gt; b; result = mul(a,b); count &lt;&lt; &quot;The result is &quot; &lt;&lt; relut &lt;&lt;endl; return 0;} mul.hpp 123#pragma once int mul(int a, int b); mul.cpp 1234#include &quot;mul.hpp&quot;int mul(int a, int b){ return a *b ;} 分开编译编译图示： ![截屏2023-10-22 19.22.00](c 编译、链接、debug/截屏2023-10-22 19.22.00.png) 一条编译代码可为： 12g++ main.cpp mul.cpp -o mul#-o 表示可执行文件输出 ，若不指定-o 默认a.out 一般错误： 编译错误：语法写错 链接错误：找不到指定函数 运行时错误：除零 2、cmake 不同Make 工具遵循着不同的规范和标准，所执行的 Makefile 格式也千差万别。这样就带来了一个严峻的问题：如果软件想跨平台，必须要保证能够在不同平台编译。而如果使用上面的 Make 工具，就得为每一种标准写一次 Makefile 。 ​ CMake 是一个比上述几种 make 更高级的编译配置工具。在 linux 平台下使用 CMake 生成 Makefile 并编译的流程如下： 写 CMake 配置文件 CMakeLists.txt 。 执行命令 cmake PATH 或者 ccmake PATH 生成 Makefile（ccmake 和 cmake 的区别在于前者提供了一个交互式的界面）。其中， PATH 是 CMakeLists.txt 所在的目录。 使用 make 命令进行编译。 各个示例： 单个源文件 同一目录，多个源文件 多个目录，多个源文件 见原文https://zhuanlan.zhihu.com/p/534439206?utm_id=0 3、gdb3.1 常规https://zhuanlan.zhihu.com/p/74897601 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748#编译 带-g，如下gcc -g -o hello hello.c#gdb启动gdb hello#查看已设置断点info breakpoints#设置程序启动命令行参数set args #根据行号设置断点b 9 #break 可简写为bb test.c:9 #或者b printNum #将断点设置在函数处，程序在调用到printNum函数的时候会断住。break test.c:23 if b==0 #条件断点#所有以printNum开头的函数都设置了断点rbreak printNum* #对所有函数设置断点#用法：rbreak file:regex rbreak . rbreak test.c:. #对test.c中的所有函数设置断点rbreak test.c:^print #对以print开头的函数设置断点#临时断点tbreak test.c:l0 #在第10行设置临时断点#跳过第1个断点30次ignore 1 30#禁用或启动断点disable #禁用所有断点disable bnum #禁用标号为bnum的断点enable #启用所有断点enable bnum #启用标号为bnum的断点enable delete bnum #启动标号为bnum的断点，并且在此之后删除该断点#断点清除#断点清除主要用到clear和delete命令clear #删除当前行所有breakpointsclear function #删除函数名为function处的断点clear filename:function #删除文件filename中函数function处的断点clear lineNum #删除行号为lineNum处的断点clear f:lename：lineNum #删除文件filename中行号为lineNum处的断点delete #删除所有breakpoints,watchpoints和catchpointsdelete bnum #删除断点号为bnum的断点 123#查看表达式值变化watch a 12345678910111213141516171819202122232425262728293031#print（可简写为p）,打印基本类型变量，数组，字符数组(gdb) p a$1 = 10(gdb) p b$2 = {1, 2, 3, 5}(gdb) p c$3 = &quot;hello,shouwang&quot;#打印指针指向内容(gdb) p d$1 = (int *) 0x602010(gdb) p *d$2 = 0(gdb) p *d@10$3 = {0, 1, 2, 3, 4, 5, 6, 7, 8, 9}#打印d指向的所有内容(gdb) p *d@a $2 = {0, 1, 2, 3, 4, 5, 6, 7, 8, 9}#自动显示变量内容(gdb) display e1: e = 8.5#要查看哪些变量被设置了display，可以使用(gdb)into displayAuto-display expressions now in effect:Num Enb Expression1: y b2: y e(gdb) delete display num #num为前面变量前的编号,不带num时清除所有。(gdb) disable display num #num为前面变量前的编号，不带num时去使能所有 12345678910111213141516#查看内存内容#n 表示要显示的内存单元数，默认值为1#f 表示要打印的格式，前面已经提到了格式控制字符#u 要打印的单元长度#addr 内存地址#单元类型常见有如下：#b 字节#h 半字，即双字节#w 字，即四字节#g 八字节(gdb) x/4tb &amp;e0x7fffffffdbd4: 00000000 00000000 00001000 01000001#查看寄存器内容(gdb) info registers 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849#单步执行 next/n$ gdb gdbStep #启动调试(gdb)b 25 #将断点设置在12行(gdb)run #运行程序Breakpoint 1, main () at gdbStep.c:2525 int b = 7;(gdb) n #单步执行26 printf(&quot;it will calc a + b\\n&quot;);(gdb) n 2 #执行两次it will calc a + b28 printf(&quot;%d + %d = %d\\n&quot;,a,b,c);#单步进入-step/s$ gdb gdbStep #启动调试(gdb) b 25 #在12行设置断点(gdb) run #运行程序(gdb) s (gdb) s #单步进入，但是并没有该函数的源文件信息(gdb) finish #继续完成该函数调用(gdb) s #单步进入，现在已经进入到了add函数内部#退出函数finsh#继续执行到下一个断点-continue/c$ gdb gdbStep(gdb)b 18 #在count函数循环内打断点(gdb) c #继续运行，直到下一次断住(gdb) fg #继续运行，直到下一次断住(gdb) c 3 #跳过三次#继续运行到指定位置-until#假如我们在25行停住了，现在想要运行到29行停住，就可以使用until命令（可简写为u）$ gdb gdbStep(gdb)b 25(gdb)run(gdb) u 29#跳过执行--skip$ gdb gdbStep(gdb) b 27(gdb) skip function add #step时跳过add函数(gdb) info skip #查看step情况(gdb) run(gdb) s(gdb) 3.2 多进程调试1234567891011121314#调试子进程set follow-fork-mode chlid#默认情况下是开的，只跟踪一个进程，off之后跟踪两个进程。set detach-on-fork on/off set detach-on-fork off #查看所有进程info inferiors#切换到编号为2的进程inferior 2 3.3 多线程调试12345678910#在使用step或者continue命令调试当前被调试线程的时候#只让被调试程序执行off#off 不锁定任何线程，也就是所有线程都执行，这是默认值。#on 只有当前被调试程序会执行。#step 在单步的时候，除了next过一个函数的情况set scheduler-locking off|on|stepset scheduler-locking oninfo threads #查看当前进程的线程。thread &lt;ID&gt; # 切换调试的线程为指定ID的线程。","link":"/2023/11/02/c%20%E7%BC%96%E8%AF%91%E3%80%81%E9%93%BE%E6%8E%A5%E3%80%81debug/"},{"title":"chatGPT","text":"chatGPT实际上做的事——文字接龙 ​ 例如：问“什么是机器学习？”，则模型中认为下面一个词概率最大的事“机”，在猜“器” ​ 那为什么每次机器学习输出的结果不同呢？原因在于，该模型行在一个分部中对较高部分随机取样。随机性造成了输出结果的不同。 ​ GPT中对P指的是预训练，有时也称自督导式学习、基石模型。 ​ 而chatGPT实际上是通过微调（finetune）GPT做成的都模型，这个微调是需要人类进行介入指导的。 ​ 其中一个很有意思的现象，在多种语言中进行预训练，但只在一种语言上进行微调，机器能对另一种语言的问题给出不错的答案。 ​ 增强式学习，一种不需要给出正确答案的人类指导，只需给出机器生成的答案是否“好”。人类导师进行微调可以更省力。另一个好处在于，对于人类也不知道的什么是好的答，如创作诗，人类能给出评价。 ​ 总结一下chatGPT的炼成： 学习文字接龙（预训练）。利用大量的文字数据，训练文字接龙的能力，每下一个单词的输出都是从一个分部中挑选一个，具有随机性。 微调。找人类老师来思考GPT问题，并人工提供正确的答案，防止chatGPT回答一些无用的答案。人类并不需要给出所有的问题，因为GPT本身就学过知识，只是不知道哪些是好的，为此人类只需提供部分问题，机器便能学习到。 模仿老师的偏好。利用teacher model 来模拟人类对于回答的打分。 用增强式学习像模拟老师学习。类似于强化学习，利用teacher model给chatGPT的输出打分。例如对一个问句，对输出下一个问句的回答给低分，对输出回答给高分。 ​ 几个最近的研究主题： Prompting，催眠，如何提出精准的需求，如“假设你是我的朋友，我工作很累很忙，请试图和我聊天，在过程中请你展现出同理心”。 Neural Editing ， 纠正chatGPT中一些错误的答案，如一些因为时效性而导致的问题（问放生在训练数据以后的最近一次比赛冠军）。 侦测AI生成的物件。 Machine unlearning。GPT会学习到一些个人隐私以及一些不该学习的，我们希望他忘记这些内容。 WEBGPT：使用搜索引擎也是文字接龙 实现原理： ​ 现在互联网中，搜索问题。对这些搜索结果作为chatGPT的部分输入，在进行原始问题上的文字接龙。","link":"/2023/11/16/chatGPT/"},{"title":"conda","text":"conda常用命令 123456789conda info -econda create --name yourEnv python=3.9conda activate yourEnvconda remove --name &lt;env_name&gt; --allpip install -r yourEnv","link":"/2023/11/02/conda/"},{"title":"cmake常用指令","text":"cmakecmake是管理代码构建的工具，跨平台（如windows Bisual Studio,linux g++ make）。 可以简化C/C++的第三方库的引入 linux 安装 12sudo apt install gcc g++ makesudo apt install cmake windows c/c++环境有：MinGW 与 MSVC ​ 建议用mingw环境，常有两个版本mingw-builds 与 w64devkit 。w64devkit 这个版本库较多，且更加与linux g++相符 ​ cmake官网 msi一键安装cmake cmake命令行12345678910111213mkdir buildcd build# 常见默认cmake .. cmake --build . # 或者可以直接 make#一些更通用的# -G 指定生成器，可通过cmake --help查看 cmake -G &quot;Unix Makefiles&quot; /path/to/your/source/code#-D 用于定义Cmake变量的值# -j 指定几个线程编译cmake --build . -DCMAKE_BUILD_TYPE=Release -j 2 CMakeLists.txt基本配置12345678910111213141516171819202122# 设置cmake最低版本要求cmake_minimum_required(VERSION 3.0)# 设置项目名称project(MyProject VERSION 1.0)# 设置语言标准（可选set(CMAKE_CXX_STANDARD 11) # 设置这一项可以替代set(CMAKE_CXX_FLAGS &quot;-std=c++20&quot;)set(CMAKE_CXX_STANDARD_REQUIRED True)# 构建可执行文件add_executable(my_executable main.cpp)# or 构建库# add_library(my_lib main.cpp) # 构建库# 可选：添加链接的库# target_link_libraries(my_executable library_name)# 可选：为特定的目标（例如可执行文件或库）指定头文件搜索路径# target_include_directories(my_executable PUBLIC ${PROJECT_BINARY_DIR})# 可选：添加头文件搜索路径# include_directories(include) Set的使用12345SET(VAR VALUE)#例如#将CmakeLists.txt文件所在的目录下的src文件夹下的hello.c yes.c main.c给到变量SRCSset(SRCS src/hello.c src/main.c src/yes.c) 添加外部库直接找系统中的一些库 123456789101112131415cmake_minimum_required(VERSION 3.0)project(MyProject)# 查找外部库find_package(SomeLibrary REQUIRED)# 添加头文件目录include_directories(${SomeLibrary_INCLUDE_DIRS})# 链接库target_link_libraries(MyExecutable ${SomeLibrary_LIBRARIES})# 定义你的目标（可执行文件或库）add_executable(MyExecutable main.cpp) 手动指定库的路径 如果find_package无法找到库，或者你在使用没有CMake支持的库，你可能需要手动指定库的路径。这可以通过设置include_directories和target_link_libraries来实现。 1234567891011# 设置外部库的路径set(SomeLibrary_INCLUDE_DIR &quot;/path/to/somelibrary/include&quot;)set(SomeLibrary_LIBRARY &quot;/path/to/somelibrary/lib/somelibrary.a&quot;)# 添加头文件目录include_directories(${SomeLibrary_INCLUDE_DIR})# 链接库target_link_libraries(MyExecutable ${SomeLibrary_LIBRARY})# 定义你的目标（可执行文件或库）add_executable(MyExecutable main.cpp) Cmdd","link":"/2024/04/10/cmake/"},{"title":"face_recognition&amp;&amp;opencv","text":"face_recognition结合opencv 三个库：opencv-python, numpy, face_recogniton 两张图像，人脸对比：1234567891011121314151617181920212223242526272829import cv2import numpy as npimport face_recognitionimgElon = face_recognition.load_image_file('images/symbol.jpg') # 加载图片imgElon = cv2.cvtColor(imgElon, cv2.COLOR_BGR2RGB) # 将BGR彩色图像转化为RGB彩色图像imgTest = face_recognition.load_image_file('images/symbol2.jpg')imgTest = cv2.cvtColor(imgTest, cv2.COLOR_BGR2RGB)faceLoc = face_recognition.face_locations(imgElon)[0] # 定位人脸位置encodeElon = face_recognition.face_encodings(imgElon)[0] # 提取人脸的面部特征cv2.rectangle(imgElon, (faceLoc[3], faceLoc[0]), (faceLoc[1], faceLoc[2]), (255, 0, 255), 2) # 框出人脸# print(faceLoc)faceLocTest = face_recognition.face_locations(imgTest)[0]encodeTest = face_recognition.face_encodings(imgTest)[0]cv2.rectangle(imgTest, (faceLocTest[3], faceLocTest[0]), (faceLocTest[1], faceLocTest[2]), (255, 0, 255), 2)result = face_recognition.compare_faces([encodeElon], encodeTest) # 比较人脸编码的相似度faceDis = face_recognition.face_distance([encodeElon], encodeTest) # 计算两个人脸的欧氏距离（欧氏距离用于计算样本之间的相似度或距离）print(result, faceDis)cv2.putText(imgTest, f'{result}{round(faceDis[0], 2)}', (50, 50), cv2.FONT_HERSHEY_COMPLEX, 1, (0, 0, 255), 2) # 显示比对结果cv2.imshow('Elon Musk', imgElon)cv2.imshow('Elon Test', imgTest)key = cv2.waitKey(0)if key == 27: # 按ESC键退出 cv2.destroyAllWindows() 调用摄像头,人脸识别 示例一12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485868788899091import face_recognitionimport cv2import numpy as np# cap = cv2.VideoCapture(0, cv2.CAP_DSHOW)# cap = cv2.VideoCapture(0)cap = cv2.VideoCapture(0)encodings = []names = []font = cv2.FONT_HERSHEY_SIMPLEXdetect_names = []class init(): frame1 = face_recognition.load_image_file(r'images/liudehua.jpg') frame2 = face_recognition.load_image_file(r'images/pengyuyan.jpg') frame3 = face_recognition.load_image_file(r'images/symbol.jpg') frame4 = face_recognition.load_image_file(r'images/lipengpeng.jpg') frame5 = face_recognition.load_image_file(r'images/pansishun.jpg') frame1_encoding = face_recognition.face_encodings(frame1)[0] encodings.append(frame1_encoding) names.append('liudehua') frame2_encoding = face_recognition.face_encodings(frame2)[0] encodings.append(frame2_encoding) names.append('pengyuyan') frame3_encoding = face_recognition.face_encodings(frame3)[0] encodings.append(frame3_encoding) names.append('symbol') frame4_encoding = face_recognition.face_encodings(frame4)[0] encodings.append(frame4_encoding) names.append('lipengpeng') frame5_encoding = face_recognition.face_encodings(frame5)[0] encodings.append(frame5_encoding) names.append('pansishun')class show(): while True: ret, img = cap.read() change_img = cv2.resize(img, (0, 0), fx=0.25, fy=0.25) frame_RGB = cv2.cvtColor(change_img, cv2.COLOR_BGR2RGB) faces_locations = face_recognition.face_locations(frame_RGB) # print(type(frame_RGB)) # print(frame_RGB.shape) # print(type(faces_locations)) faces_encodings = face_recognition.face_encodings(frame_RGB, faces_locations) detect_names.clear() for face_encoding in faces_encodings: matches = face_recognition.compare_faces(encodings, face_encoding,0.9) distances = face_recognition.face_distance(encodings, face_encoding) print(distances) min_distance_index = np.argmin(distances) name = 'unknown' print(min_distance_index) if matches[min_distance_index]: name = names[min_distance_index] detect_names.append(name) print(detect_names) for (top, right, bottom, left), name in zip(faces_locations, detect_names): top *= 4 right *= 4 bottom *= 4 left *= 4 cv2.rectangle(img, (left, top), (right, bottom), (0, 0, 255), 2) cv2.putText(img, name, (left, top - 6), font, 1.0, (255, 255, 255), 1) cv2.imshow('test', img) key = cv2.waitKey(1) if key == ord('q'): breakif __name__ == '__main__': init() show() cap.release() cv2.destroyAllWindows() 调用摄像头，人脸识别2，打卡应用：123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475import cv2import numpy as npimport face_recognitionimport osfrom datetime import datetimepath = 'images' # 人像存储位置images = []className = []myList = os.listdir(path) # 返回指定文件目录下的列表，这里返回的是人像图片print(myList)for cl in myList: # 获取每张人像的名称 curImg = cv2.imread(f'{path}/{cl}') images.append(curImg) className.append(os.path.splitext(cl)[0])print(className)def findEncodings(images): # 获取所有存储的人像编码 encodeList = [] for img in images: img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB) encode = face_recognition.face_encodings(img)[0] encodeList.append(encode) return encodeListdef markAttendance(name): # 打卡，生成记录 with open('Attendance.csv', 'r+') as f: myDatalist = f.readlines() # 读取文件中所有的行 nameList = [] for line in myDatalist: entry = line.split(',') nameList.append(entry[0]) if name not in nameList: now = datetime.now() dtString = now.strftime('%H:%M:%S') # 将日期时间格式化成字符串 f.writelines(f'\\n{name},{dtString}') # 将包含多个字符串的可迭代对象写入文件中，这里是记录人名encodeListKnown = findEncodings(images)print('encoding complete')cap = cv2.VideoCapture(0)while True: success, img = cap.read() imgs = cv2.resize(img, (0, 0), None, 0.25, 0.25) # 调整图片大小 imgs = cv2.cvtColor(imgs, cv2.COLOR_BGR2RGB) faceCurFrame = face_recognition.face_locations(imgs) # 获取人脸位置信息 encodesCurFrame = face_recognition.face_encodings(imgs, faceCurFrame) # 获取人脸编码 for encodeFace, faceLoc in zip(encodesCurFrame, faceCurFrame): # zip函数，连接成字典 matches = face_recognition.compare_faces(encodeListKnown, encodeFace) # 人脸匹配度 faceDis = face_recognition.face_distance(encodeListKnown, encodeFace) # 欧式距离 # print(faceDis) matchIndex = np.argmin(faceDis) # 返回数组中小元素的索引 if matches[matchIndex]: name = className[matchIndex].upper() print(name) y1, x2, y2, x1 = faceLoc # 人脸位置 y1, x2, y2, x1 = y1 * 4, x2 * 4, y2 * 4, x1 * 4 cv2.rectangle(img, (x1, y1), (x2, y2), (0, 255, 0), 1) cv2.rectangle(img, (x1, y2 - 35), (x2, y2), (0, 255, 0), cv2.FILLED) cv2.putText(img, name, (x1 + 6, y2 - 6), cv2.FONT_HERSHEY_COMPLEX, 1, (255, 255, 255), 2) markAttendance(name) # 记录人名 cv2.imshow(str('Face_Detector'), img) if cv2.waitKey(0) &amp; 0xff == 27: breakcap.release()cv2.destroyAllWindows() 补充opencv本地摄像头的使用：12345678910111213141516171819202122232425262728293031323334353637383940414243444546# -*- coding:utf8 -*-import cv2 as cvcap = cv.VideoCapture(0)# while (True):# hx, frame = cap.read()## if hx is False:# print('read video error')# exit(0)## cv.imshow('video', frame)# if cv.waitKey(1) &amp; 0xFF == ord('q'):# break# hx, frame = cap.read()#拍摄一张照片，解决第一张图片比较暗i=10while i&gt;0: i=i-1 hx, frame = cap.read()if hx is False: print('read video error') exit(0)cv.imshow('video', frame)# 维持窗口# 此函数运行后会向后执行程序，如果后面的程序执行完了直接退出，那么程序中需要显示的图像有可能闪一下便消失了，# 因此在需要显示图像的程序中，往往在cv.imshow函数后会有一个cv.waitKey函数，以此将程序暂停一段时间。# 具体暂停时间可以通过参数赋值给函数，单位为毫秒。如果参数默认为默认值或者为0，则表示等待用户按键结束暂停函数## 1.若参数delay≤0：表示一直等待按键；# 2、若delay取正整数：表示等待按键的时间，比如cv2.waitKey(30)，就是等待30（milliseconds）；（视频中一帧数据显示（停留）的时间）# cv2.waitKey(delay)返回值：# 1、等待期间有按键：返回按键的ASCII码（比如：Esc的ASCII码为27，即0001 1011）；(接收值为非空,if代码块执行)# 2、等待期间没有按键：返回 -1；(非0非空,if代码块执行)cv.waitKey(0)cap.release()cv.destroyAllWindows() 参考博客： https://github.com/ageitgey/face_recognition/blob/master/README_Simplified_Chinese.md https://blog.csdn.net/weixin_44686138/article/details/130032130 https://blog.csdn.net/weixin_54627824/article/details/127137534","link":"/2023/11/03/face-recognition-opencv/"},{"title":"Docker","text":"1、docker 的引入一款产品开发和上线实在两套不同的环境上运行的，包括应用环境和应用配置。 环境部署十分麻烦，每一个机器都要部署环境（集群Redis、ES、hadoop…）!麻烦 发布一个项目（jar+（Redis Mysql jdk ES）），项目能不能带上环境打包。 传统：开发jar，运维来做 现在：开发打包部署，一套流程昨晚！ Docker给以上问题，提出了解决方案 java – jar（环境）—打包项目带上环境（镜像）—（Docker仓库：商店）—下载我们发布的镜像–直接运行即可 JRE–多个应用（端口冲突）—原来都是交叉的！ 隔离：Docker核心思想！打包装箱，每一个箱子是互相隔离的。 虚拟机：在windows中装VMwave，通过这个软件我们可以用虚拟机出来一台或者多态电脑！笨重！ 虚拟机属于虚拟化技术，Docker容器技术，也是一种虚拟化技术！ 12vm： linux cents原生镜像（每个镜像就是一台电脑） 隔离，需要开启多个虚拟机！ 几个Gdocker：隔离,镜像（最核心的环境 4m+jdk+msql）十分的小巧，运行镜像就可以了 几M 比较Docker和虚拟机技术： 传统虚拟机，虚拟出一套硬件，运行一个完整的操作系统，然后在系统上安装和运行软件 容器内应用直接运行在宿主机的内容，容器时没有内核的，也没有虚拟我们的硬件，所以轻便 每个容器间是相互隔离的，每个容器内都有一个属于自己的文件系统，互不影响。 Docker是基于Go语言的开源项目； 文档地址：https://docs.docker.com/ 2、docker的安装2.1、Docker的基本组成 镜像（image）： docker镜像就像是一个模板，通过模板来创建容器服务，例如tomcat镜像=&gt;run=&gt;tomcat01容器（最终服务运行或者项目运行就是在容器中的）。 容器（container）： Docker利用容器技术，独立运行或者一组应用，通过镜像来创建的。 启动，停止，删除，基本命令！ 目前就可以把这个容器理解为一个简易 的Linux系统， 仓库（repository）： 仓库就是存放镜像的地方！ 仓库分为公有仓库和私有仓库 Docker Hub 阿里云…都有容器服务（配置镜像加速） 2.2、安装Docker环境准备 1、需要会一点点Linux的基础 2、Cent OS7 3、环境查看 12[admin@iZbp11l07kvf8lhts6k2f9Z /]$ uname -r3.10.0-514.26.2.el7.x86_64 12345678910111213141516[admin@iZbp11l07kvf8lhts6k2f9Z /]$ cat /etc/os-releaseNAME=&quot;CentOS Linux&quot;VERSION=&quot;7 (Core)&quot;ID=&quot;centos&quot;ID_LIKE=&quot;rhel fedora&quot;VERSION_ID=&quot;7&quot;PRETTY_NAME=&quot;CentOS Linux 7 (Core)&quot;ANSI_COLOR=&quot;0;31&quot;CPE_NAME=&quot;cpe:/o:centos:centos:7&quot;HOME_URL=&quot;https://www.centos.org/&quot;BUG_REPORT_URL=&quot;https://bugs.centos.org/&quot;CENTOS_MANTISBT_PROJECT=&quot;CentOS-7&quot;CENTOS_MANTISBT_PROJECT_VERSION=&quot;7&quot;REDHAT_SUPPORT_PRODUCT=&quot;centos&quot;REDHAT_SUPPORT_PRODUCT_VERSION=&quot;7&quot; 安装： 1234567891011121314151617181920212223242526272829303132333435#1、卸载旧版本 sudo yum remove docker \\ docker-client \\ docker-client-latest \\ docker-common \\ docker-latest \\ docker-latest-logrotate \\ docker-logrotate \\ docker-engine #2、需要的安装包yum install -y yum-utils#3、设置的镜像仓库sudo yum-config-manager \\ --add-repo \\ https://download.docker.com/linux/centos/docker-ce.repo #默认是从国外的#4、yum-config-manager \\ --add-repo \\http://mirrors.aliyun.com/docker-ce/linux/centos/docker-ce.repo#5.安装docker相关的内容#更新软件包索引 yum makecache fast#docker-ce社区版sudo yum install docker-ce docker-ce-cli containerd.io#6启动dockersystemctl start dockerdocker run hello-world#docker version 检查是否成功#7、hello-world 12#8、查看一下下载的hello-world镜像 sudo docker images 了解：卸载docker 123sudo yum remove docker-ce docker-ce-cli containerd.iosudo rm -rf /var/lib/dockersudo rm -rf /var/lib/containerd 2.3、配置阿里云镜像加速 登录阿里云，找到容器服务 找到镜像加速地址 配置使用： 12345678sudo mkdir -p /etc/dockersudo tee /etc/docker/daemon.json &lt;&lt;-'EOF'{ &quot;registry-mirrors&quot;: [&quot;https://ng1nkdmw.mirror.aliyuncs.com&quot;]}EOFsudo systemctl daemon-reloadsudo systemctl restart docker 2.4、回顾hello-world 底层原理Docker是怎么工作的? Docker是一个Client-Server结构的系统，Docker的守护进程运行在主机上。通过Socket从客户端访问！ DockerServer接收到Docker-Client的指令，就会执行这个命令！ 自习个问题： 为什么docker比虚拟机快 3、Docker的常用命令3.1、帮助命令123docker version #版本信息docker info #详细信息docker 命令 --help #万能命令 帮助文档地址： 3.2、镜像命令123456789101112131415161718[admin@iZbp11l07kvf8lhts6k2f9Z ~]$ sudo docker imagesREPOSITORY TAG IMAGE ID CREATED SIZEhello-world latest d1165f221234 4 months ago 13.3kB#解释REPOSITORY 镜像的仓库源TAG 镜像的标签IMAGE ID 镜像的idCREATED 镜像创建的时间SIZE 镜像的大小#可选项Options: -a, --all Show all images (default hides intermediate images) -q, --quiet Only show image IDs docker search 搜索镜像： 1sudo docker search mysql docker pull下载镜像 1docker pull mysql [:tag] 1234567891011121314151617181920212223admin@iZbp11l07kvf8lhts6k2f9Z ~]$ sudo docker pull mysqlUsing default tag: latestlatest: Pulling from library/mysql #如果不写，docker image的核心 联合文件系统b4d181a07f80: Pull complete a462b60610f5: Pull complete 578fafb77ab8: Pull complete 524046006037: Pull complete d0cbe54c8855: Pull complete aa18e05cc46d: Pull complete 32ca814c833f: Pull complete 9ecc8abdb7f5: Pull complete ad042b682e0f: Pull complete 71d327c6bb78: Pull complete 165d1d10a3fa: Pull complete 2f40c47d0626: Pull complete Digest: sha256:52b8406e4c32b8cf0557f1b74517e14c5393aff5cf0384eff62d9e81f4985d4b #签名Status: Downloaded newer image for mysql:latestdocker.io/library/mysql:latest#真实地址#等同于它docker pull mysqldocker pull docker.io/library/mysql:lastest 删除镜像 123docker rmi -f 容器id #删除指定容器docker rmi -f 容器id 容器id 容器id #删除多个容器docker rmi -f$(docker images -aq) #删除全部容器 3.3、容器命令说明：我们有了镜像才可以创建容器，linux，下载一个centos镜像来测试学习 1docker pull centos 新建容器并启动 1234567891011121314151617181920212223242526272829303132docker run [可选参数] image#参数说明--name=&quot;Name&quot; 容器名字 tomcat01 tomcat02用来区分容器-d 后台方式运行-i 交互方式运行-p 指定容器端口 -p 8080：8080 -p ip:主机端口：容器端口 -p主机端口：容器端口（常用） -p容器端口 容器端口-p 随机指定端口#测试、启动并进入容器[admin@iZbp11l07kvf8lhts6k2f9Z ~]$ sudo docker run -it centos /bin/bash[root@b270ce2d2c82 /]# ls #查看容器内的centos，基础版本，是不完善的bin etc lib lost+found mnt proc run srv tmp vardev home lib64 media opt root sbin sys usr[root@b270ce2d2c82 /]# #列出运行的docker容器docker ps -a #列出当前正在运行的容器+历史运行过的容器-n=?#显示最近创建的容器-q #显示容器的编号#例如：[admin@iZbp11l07kvf8lhts6k2f9Z ~]$ sudo docker ps -aCONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMESb270ce2d2c82 centos &quot;/bin/bash&quot; 7 minutes ago Exited (127) 4 minutes ago pedantic_saha245a54fb6906 hello-world &quot;/hello&quot; About an hour ago Exited (0) About an hour ago intelligent_golick 123#退出容器,停止exitctrl+P+Q #容器不停止退出 删除容器 12docker rm 容器id #删除指定的容器，不能删除正在运行的容器docker em -f $(docker ps -aq) #强制删除所有容器 启动和停止容器的操作 1234docker start 容器iddocker restart 容器iddocker stop 容器iddocker kill 容器id 常见其他命令后台启动容器： 1234567#命令 docker run -d 镜像名例如：docker run -d centos#问题docker ps 发现centos停止了#常见的坑，docker容器使用后台运行，就必须有一个前台进程，docker发现没有应用，就会自动停止#nginx，容器启动后，发现自己没有提供服务，就会立刻停止，就是没有程序立刻 查看日志信息 123docker logs 进入当前正在运行的容器 123456789101112131415161718#我们通常容器都是使用后台方式运行的，需要进入容器，修改一些配置#方式一：#命令docker exec -it 容器id bashshell#测试#方式二：docker attach 容器id#区别#docker exec #进入容器后开启一个新的终端，可以在里面操作#docker attach #进入容器正在执行的终端，不会启动新的进程 从容器内拷贝文件到主机上面： 12345docker cp 容器id：容器内路径 目的的主机路径#例如：将这个文件拷贝来到主机上docker cp b2156181:/home/test.java /home#拷贝是个主动过程，未来我们使用-v卷的技术，可以实现容器与主机外文件同步 作业1.安装nginx1234#1、搜索镜像 search 建议去docker官网搜索，可以看到版本号#2、下载镜像 pull#3、运行测试#开放端口 思考问题： 我们每次改动nginx配置文件，都需要进入容器内部？十分麻烦，我要是可以在容器外部提供一个映射，达到容器外修改文件，容器内就可以自动修改？ -v数据卷技术 2、安装tomcat1234#官方的使用docker run -it --rm tomcat:9.0#我们启动的都是后台，停止容器之后，容器还是可以查到 --rm 3、安部署ES+Kibana可视化 portainer（先用这个） 12docker run -d -p 8088:9000\\--restart=always -v /var/run/docker.sock --privileged=true portainer/portainer Rancher(CI/CD再用) 什么portainer？ Docker图形化界面管理工具！提供一个后台界面供我们操作 端口访问： 我们平时不会用，测试玩玩就可 4、容器数据卷4.1、什么是容器数据卷如果数据存放在容器里，那么当我们删除容器的时候，数据就会丢失。那么我们就会有一个新的需求：数据持久化 Mysql，容器删了，删库跑路。那么我们那就希望Mysql数据可以储存在本地！ 容器之间可以有一个数据共享的技术！Docker容器中产生的数据同步到本地。 这就是卷技术！目录的挂载，将我们容器内的目录，挂载到linux上面! 总结一句话：容器的持久化和同步操作!容器间也是可以数据共享的！ 4.2、使用数据卷 方式一：直接使用命令挂载 -v 1docker run -it -v 主机目录:容器目录 7、springboot微服务打包docker镜像 架构springboot项目 打包应用 maven-Lifecycle-package 编写dockerfile（确保idea有docker插件） 123456789FROM java:8COPY *.jar /app.jarCMD [&quot;--server.port=8080&quot;]EXPOSE 8080ENTRYPOINT[&quot;jar&quot;,&quot;java&quot;,&quot;/app.jar&quot;] 构建镜像 发布运行！ 以后我们使用了Docker之后给别人交付，就是一个镜像即可","link":"/2021/08/12/docker/"},{"title":"git","text":"linux常用基本命令 基本linux命令学习 cd：改变目录 cd.. 回退到上一个目录，直接cd进入默认目录 pwd：显示当前所在的目录路径 ls（ll）：都是列出当前目录的所有文件。只不过ll更为详细 touch：新建一个文件。如touch index.js rm：删除一个文件。例如，rm index.js mkdir:新建一个目录，就是新建一个文件夹 rm-r：删除一个目录，就是创建一个文件夹 mv移动文件， mv index.html src index.html reset 重新初始化终端/清屏 clear：清屏 history 查看命令历史 help 帮助 exit推出 #标识注释 git配置查看配置 12345678910git config -lgit config --global --list#查看用户、邮箱git config user.name git config user.email#配置名字、邮箱git config --global user.name &quot;symbol&quot;git config --global user.email &quot;symbol23441@163.com&quot; git的基本操作 git项目的创建和克隆本地仓库搭建一种是创建全新仓库，一种是克隆远程仓库 1、创建全新仓库，需要用git管理的项目的根目录执行 1git init 执行后可以看到，在项目目录多出了一个.git目录，关于版本等所有信息都在这个目录里 克隆远程仓库1、克隆远程仓库，将服务器上的仓库完全镜像到本地一份 12#克隆一个项目和它整个历史代码（版本信息）git clone [url] git的文件操作首先，文件有四种状态 1、git status12345#查看指定文件状态git status [filename]#查看所有文件状态git status 2、git add .12#添加所有文件到暂存区git add . 3、commit123456#单个文件提交git commit 文件1 文件2... -m &quot;新增两个文件&quot;#提交暂存区的内容到本地仓库git commit -m#-m &quot;我更新了xxxx&quot; ,提交文件的说明信息 commit合并 git rebase -i &lt;commit的id，可从gitlog中看到，找到所有要合并的前一个&gt; 随后改成s 4、忽略文件​ 有些文件我们不用纳入版本控制，比如数据库文件、临时文件、设计文件。具体如，前端的npm_moudles，idea中的.idea文件 ​ 那么我们就有了，在主目录文件下建立”.gitignore”文件，该文件有以下规则： 忽略文件中的空行，忽略#开头的行 可以使用Linux通配符。例如：星号（*）代表任意多个字符，问号（?）代表一个字符，方括号（[abc]）代表可选字符范围，大括号（{String1，String3,…}）代表可选的字符串 如果名称前有一个感叹号（!）,表示例外规则，将不会被忽视 如果名称的最前面是一个路径分隔符(/),表示要忽略的文件在此目录下，而子目录的文件不忽视 如果名称最后面的一个路径分隔符(/)，表示要忽略的是此目录名称下该名称的子目录，而非文件(默认文件或目录都忽视) 123456#为注释*.txt #忽略所有.txt结尾的文件！lib.txt #但lib.txt除外/temp #仅忽略项目根目录下的TODO文件，不包括其他目录tempbuild/ #忽略build目录下的所有文件doc/*.txt #会忽略doc/notes.txt但不包括doc/server/arch.txt 例如： git log123git loggit log --oneline git分支分支就是科幻电影里的平行宇宙，如果两个宇宙互不干扰，那么对现在的你也没有什么影响。不过在某个时间点，两个平行宇宙合并了，我们就需要处理一个问题了。 git分支中的常用命令: 1234567891011121314151617181920212223242526272829#查看当前分支git branch#列出所有分支（包括远程）git branch -a#仅切换分支git checkout [branch-name]#新建一个分支，但现在依然在原来的分支中git branch [branch-name]#新建一个分支，并切换到该分支git checkout -b [branch]#对分支进行重命名git branch -m &lt;旧名称&gt; &lt;新名称&gt;#和并指定分支到当前分支git merge [branch]#删除分支#-d 用于删除已经合并过的分支#-D 强制删除分支(不管是否合并过)git branch -d [branch-name]#删除远程分支git push origin --delete[branch-name]git branch -dr [remote/branch] 多个代码如果并行执行，就会导致我们代码不冲突，也就是同时存在多个版本！ 但当代码合并的时候，会有文件冲突，那么就需要协商。 master主分支应该非常稳定，用来发布新的版本，一般情况不允许在上面工作，工作一般情况下在新建的dev分支上工作，工作完后，比如要发布，或者说dev分支代码稳定后可以合并到主分支master上来 12345678#合并指定分支到当前分支git merge [branch]#合并指定远程分支到当前分支git merge [origin/branch]#git取消合并git merge --abort git撤销git reset 123- git reset --soft: 将分支回退到指定提交，工作区维持现状不变,暂存区会在现有基础上增加该commit之后的提交。- git reset --mixed: （默认操作）将分支回退到指定提交，暂存区也被同步为该指定提交，工作区保持不变。- git reset --hard: 将分支回退到指定分支，暂存区和工作区都会被同步为该指定的提交。 git reset后的三个参数回退程度是依次递进。soft最轻微，它不会重置当前工作区和暂存区，只会将回退版本后续的提交加到暂存区。 mixed会改变暂存区，使它和回退版本同步。 hard则会重置工作区和暂存区，使它和回退版本一致。 回退 git reset --soft HEAD^：将最近一次提交节点的提交记录回退到暂存区 git reset --mixed HEAD^：将最近一次提交节点的提交记录回退到工作区 git reset --hard HEAD^：将最近一次提交节点的提交记录全部清除 git revert是用一次新的commit来回滚之前的commit，git reset是直接删除指定的commit","link":"/2021/08/14/git/"},{"title":"hexo-prism-plugin 花括号编译问题","text":"solutionnode_modules/hexo-prism-plugin/src/index.js文件中map里未支持大括号，尝试补上”{“与”}“后发现有效，即在map中加上对应字符即可: 123456789const map = { '&amp;#39;': '\\'', '&amp;amp;': '&amp;', '&amp;gt;': '&gt;', '&amp;lt;': '&lt;', '&amp;quot;': '&quot;', '&amp;#123;': '{', '&amp;#125;': '}'};","link":"/2021/08/15/hexo-prism-plugin%20%E8%8A%B1%E6%8B%AC%E5%8F%B7%E7%BC%96%E8%AF%91%E9%97%AE%E9%A2%98/"},{"title":"hexo常用文档","text":"1、front-mater123456789101112131415161718192021222324252627#最简---title: 标题date: 2020-02-29 16:00:00---&lt;!-- more --&gt;updated: 2021-08-12 15:48:05tags: - 未分类categories:- 未分类excerpt: Git 是一个开源的分布式版本控制系统，用于敏捷高效地处理任何或小或大的项目。# 文章摘要cover: /gallery/covers/cover.jpg #封面图thumbnail: /gallery/thumbnails/thumbnail.jpg #缩略图summary: # 文章摘要（matery主题支持）toc: truemathjax: truetop: truecover: trueabbrlink: 213245 # 自己可随意设置img: 'https://img-blog.csdnimg.cn/20200309120551356.png' # 设置文章背景图，设置为外链图片，访问快author: # 设置文章作者password: # 设置密码（yml中开启相应功能）coverImg: # 轮播图片--- 2、hexo命令行12345678910111213#清除缓存文件（db.json）和已生成的静态文件（public）。hexo clean #hexo new命令用于新建文章，可以简写为hexo n &lt;文章名&gt;#hexo generate命令用于生成静态文件hexo g#hexo server命令用于启动本地服务器，默认网址http://localhost:4000/hexo s#hexo deploy部署网站hexo d 不常用 12345#默认在目前的文件夹建立网站hexo init#新建一个标题为 aboutme 的页面，默认链接地址为 主页地址/aboutme/hexo new page aboutme 3、icarus主页readmore的两种方法3.1、front-mater1excerpt: 摘要内容 #文章摘要(装个插件插件) 3.2、在要断处添加&lt;!-- more --&gt;1&lt;!-- more --&gt;","link":"/2021/08/16/hexo%E5%B8%B8%E7%94%A8%E6%96%87%E6%A1%A3/"},{"title":"icarus相关改动","text":"1、调整整体宽度在node_modules\\hexo-theme-icarus\\include\\style目录下，找到responsive.styl，将widescreen样式中： 1234+widescreen() .is-1-column .container, .is-2-column .container max-width: $desktop - 2 * $gap width: $desktop - 2 * $gap 改成： 1234+widescreen() .is-1-column .container, .is-2-column .container max-width: $widescreen - 2 * $gap width: $widescreen - 2 * $gap 2、文章页面两栏布局主题默认是三栏布局，在阅读文章时显得有些拥挤。可以通过配置的方式把所有文章变为两栏布局，在_config.post.yml把需要的widget显示在一边即可，可以参考官方文档。 但两栏整体宽度跟三栏不同，因此强制指定为三栏布局，并且修改相应的宽度，这样所有的页面侧边栏宽度保持一致。 12345 &lt;Head site={site} config={config} helper={helper} page={page} /&gt;- &lt;body class={`is-${columnCount}-column`}&gt;+ &lt;body class={`is-3-column`}&gt; &lt;Navbar config={config} helper={helper} page={page} /&gt; 1234 'is-12': columnCount === 1,- 'is-8-tablet is-8-desktop is-8-widescreen': columnCount === 2,+ 'is-8-tablet is-8-desktop is-9-widescreen': columnCount === 2, 'is-8-tablet is-8-desktop is-6-widescreen': columnCount === 3 12345678 function getColumnSizeClass(columnCount) { switch (columnCount) { case 2:- return 'is-4-tablet is-4-desktop is-4-widescreen';+ return 'is-4-tablet is-4-desktop is-3-widescreen'; case 3: return 'is-4-tablet is-4-desktop is-3-widescreen'; } 并优化在不同屏幕小大下的宽度 1234567891011121314151617+widescreen()+ .is-3-column .container+ max-width: $widescreen - $gap+ width: $widescreen - $gap+ .is-1-column .container, .is-2-column .container max-width: $desktop - 2 * $gap width: $desktop - 2 * $gap +fullhd()+ .is-3-column .container+ max-width: $fullhd - 2 * $gap+ width: $fullhd - 2 * $gap+ .is-2-column .container max-width: $widescreen - 2 * $gap width: $widescreen - 2 * $gap 3、card 增加浮动效果:hover 时增大阴影，并增加动画属性 ease-in-out。 123456.card overflow: visible border-radius: $card-radius+ &amp;:hover+ box-shadow: 0 6px 15px rgba(0,0,0,0.15), 0 0 1px rgba(0,0,0,0.1) 123456 setTimeout(() =&gt; { $('body &gt; .navbar, body &gt; .section, body &gt; .footer').forEach(element =&gt; { element.style.opacity = '1';- element.style.transition = 'opacity 0.3s ease-out, transform 0.3s ease-out';+ element.style.transition = 'opacity 0.3s ease-out, transform 0.3s ease-out, box-shadow 0.3s ease-in-out'; }); 1234 element.style.transform = '';- element.style.transition = 'opacity 0.3s ease-out, transform 0.3s ease-out';+ element.style.transition = 'opacity 0.3s ease-out, transform 0.3s ease-out, box-shadow 0.3s ease-in-out'; }, i * 100); 4、圆角设置笔者能力有限，圆角设置直接在以下代码写死： 12+$card-radius ?= $radius-$card-radius ?= 10px 5、（可选）自动摘要插件2.1、按字数1npm install --save hexo-auto-excerpt https://github.com/ashisherc/hexo-auto-excerpt 2.2、按div1npm install hexo-excerpt --save https://github.com/chekun/hexo-excerpt 6、感谢感谢大佬的博客： https://www.alphalxy.com/2019/03/customize-icarus/#%E6%A0%B7%E5%BC%8F","link":"/2021/08/19/icarus%E7%9B%B8%E5%85%B3%E6%94%B9%E5%8A%A8/"},{"title":"javaDoc文档","text":"javadoc（文档注释）1.可包含的内容：@author 作者名 @version 版本号 @since 指明需要最早使用的jdk版本 @param 参数名 @return 返回值情况 @throws 异常抛出情况 可以在类和方法前插入 文档注释 如： 12345678910111213141516171819package com.Symbol.demo1;/** * @author Symbol * @version 1.0 * @since 1.8 */public class doc { /** * * @param Symbol * @return * @throws Exception */ public String test(String name) throws Exception{ }} 2.javaDoc输出阅读文档（两种方法） 在包下cmd输入： javadoc -encoding UTF-8 -charset UTF-8 Doc.java 在IDEA=&gt;Tools=&gt;Gernate javaDoc","link":"/2020/12/05/javaDoc%E6%96%87%E6%A1%A3/"},{"title":"java接口","text":"java接口1.接口1.1关键词：interface1.2接口中的定义是抽象的​ 无法进行方法的实现 ​ 每个方法前默认：public abstract 1234567public interface UserService { //接口中的定义全都是抽象的 public abstract void add(String name); void delete(String name);} 2.java接口实现2.1关键词：implements2.2“多继承”​ 一个实现类可以实现多个接口 2.3实现java接口的类，就需重写接口中的方法123456789101112131415161718package demo1;public class UserServiceImpl implements UserService,TimeService { @Override public void add(String name) { } @Override public void delete(String name) { } @Override public void timer() { }}","link":"/2020/12/03/java%E6%8E%A5%E5%8F%A3/"},{"title":"json","text":"0、json示例123456789{&quot;name&quot;:&quot;Bill Gates&quot;,&quot;age&quot;:62,&quot;money&quot;:0.01,&quot;cars&quot;:[ &quot;Porsche&quot;, &quot;BMW&quot;, &quot;Volvo&quot; ],&quot;cat&quot;:{&quot;name&quot;:&quot;阿花&quot;，&quot;age&quot;:2},&quot;cats&quot;:[{&quot;name&quot;:&quot;阿花&quot;，&quot;age&quot;:2},{&quot;name&quot;:&quot;阿猫&quot;，&quot;age&quot;:3}],&quot;master&quot;:null} 1、json简介1.1、什么是 JSON ？ JSON 指的是 JavaScript 对象表示法（JavaScript Object Notation） JSON 是轻量级的文本数据交换格式 JSON 独立于语言：JSON 使用 Javascript语法来描述数据对象，但是 JSON 仍然独立于语言和平台。 1.2、json和xml 的区别JSON 与 XML 的相同之处： JSON 和 XML 都用于接收 web 服务端的数据。 JSON 和 XML 数据都是 “自我描述” ，都易于理解。 JSON 和 XML 数据都是有层次的结构 JSON 和 XML 数据可以被大多数编程语言使用 JSON 与 XML 的不同之处： JSON 不需要结束标签 JSON 更加简短 JSON 读写速度更快 JSON 可以使用数组 1.3、json VS map相同点： JSON 和 Map的相同点：都是 key,value的方式存储的, 区别： json是一种数据交换格式（文本格式），不受编程语言和平台的限制；map是一种数据类型，可以使用匿名对象找到一个key对应的value。 JSON精确的说键值只支持String(也可以存数值,但是数值存进去,取出来还是String) Map键值都可以存储对象. 总结：json是一种K/V键值对的数据格式，比xml更加轻便、快捷 2、JSON 语法JSON 语法是 JavaScript 语法的子集。 2.1、JSON 语法规则JSON 语法是 JavaScript 对象表示语法的子集。 数据在名称/值对中 数据由逗号分隔 大括号 {} 保存对象 中括号 [] 保存数组，数组可以包含多个对象 2.2、JSON 名称/值对JSON 数据的书写格式是： 1key : value 名称/值对包括字段名称（在双引号中），后面写一个冒号，然后是值： “name” : “菜鸟教程” 2.3、JSON 值JSON 值可以是： 数字（整数或浮点数） 字符串（在双引号中） 逻辑值（true 或 false） 数组（在中括号中） 对象（在大括号中） null 2.4、JSON 数字JSON 数字可以是整型或者浮点型： { “age”:30 } 2.5、JSON 对象JSON 对象在大括号 {} 中书写： 1{key1 : value1, key2 : value2, ... keyN : valueN } 对象可以包含多个名称/值对： { “name”:”菜鸟教程” , “url”:”www.runoob.com&quot; } 2.6、JSON 数组JSON 数组在中括号 [] 中书写： 数组可包含多个对象： 1234567[ { key1 : value1-1 , key2:value1-2 }, { key1 : value2-1 , key2:value2-2 }, { key1 : value3-1 , key2:value3-2 }, ... { keyN : valueN-1 , keyN:valueN-2 }, ] { “sites”: [ { “name”:”菜鸟教程” , “url”:”www.runoob.com&quot; }, { “name”:”google” , “url”:”www.google.com&quot; }, { “name”:”微博” , “url”:”www.weibo.com&quot; } ] } 在上面的例子中，对象 sites 是包含三个对象的数组。每个对象代表一条关于某个网站（name、url）的记录。 3、JSON 文件 JSON 文件的文件类型是 .json JSON 文本的 MIME 类型是 application/json 4、补充：序列化概念序列化：数据结构或者对象转换成某种格式的过程 反序列化：而将序列化过程的结果反向转换回某种数据结构或对象的过程。","link":"/2021/08/15/json/"},{"title":"linux c组播","text":"一、什么是UDP组播​ UDP组播是指使用用户数据报协议（UDP）实现的组播方式。组播是一种数据传输方式，允许单一数据包同时传输到多个接收者。在UDP组播中，一个数据包可以被多个接收者同时接收，这样可以降低网络传输的负载和提高数据传输效率。 二、使用场景1、多媒体流媒体：UDP组播可以在局域网或广域网上传输音视频流，能够快速地向多个接收者发送相同的视频和音频数据，避免了建立多个点对点的连接。 2、 分布式应用的数据分发：UDP组播可以实现高效的数据分发，例如在大型集群环境下，可以将某些服务的状态信息广播给所有节点，使得所有节点都能够及时了解到最新的信息。 3、网络游戏：UDP组播可以用于多人联机游戏，使得多个玩家能够同时收到相同的游戏状态和动作，提高游戏体验。 4、 网络广播：UDP组播可以用于向多个设备广播事件和消息，例如路由器可以向所有连接的设备发送网络配置信息、DHCP服务器可以向所有设备广播IP地址信息等。 5、实时数据更新：UDP组播可以用于实时的数据更新，例如在金融行业，可以订阅某些财经数据的实时更新，以便及时响应市场变化。 ​ 可以把UDP组播简单理解为群聊。 三、UDP组播通信流程 1发送方 建立套接字。使用socket() 设置端口复用。使用setsockopt()（可选，推荐） 绑定自己的IP地址和端口号。使用bind()（可以省略） 发送数据，接收方IP地址要填写为组播地址。使用sendto() 关闭套接字。使用close() 2接收方 建立套接字。使用socket() 定义并初始化一个组播结构体。使用struct ip_mreq; 给套接字加入组播属性。使用setsockopt() 绑定自己的IP地址和端口号。使用bind()，不可以省略 接收数据。使用recvfrom() 关闭套接字。使用close() 四、相关函数API1、建立套接字123456789101112131415// 建立套接字 int socket(int domain, int type, int protocol); // 接口说明 返回值：成功返回一个套接字文件描述符，失败返回-1 参数domain：用来指定使用何种地址类型，有很多，具体看别的资源 （1）PF_INET 或者 AF_INET 使用IPV4网络协议 （2）其他很多的，看别的资源 参数type：通信状态类型选择，有很多，具体看别的资源 （1）SOCK_STREAM 提供双向连续且可信赖的数据流，即TCP （2）SOCK_DGRAM 使用不连续不可信赖的数据包连接，即UDP 参数protocol：用来指定socket所使用的传输协议编号，通常不用管，一般设为0 2、设置端口状态12345678910111213141516171819202122232425262728293031// 设置端口的状态int setsockopt(int sockfd, int level, int optname, const void *optval, socklen_t optlen); // 接口说明 返回值：成功返回0，失败返回-1 参数sockfd：待设置的套接字 参数level： 待设置的网络层，一般设成为SOL_SOCKET以存取socket层 参数optname：待设置的选项，有很多种，具体看别的资源，这里讲常用的 （1）、SO_REUSEADDR 允许在bind()过程中本地地址可复用，即端口复用 （2）、SO_BROADCAST 使用广播的方式发送，通常用于UDP广播 （3）、SO_SNDBUF 设置发送的暂存区大小 （4）、SO_RCVBUF 设置接收的暂存区大小 （5）、IP_ADD_MEMBERSHIP 设置为组播 参数optval：待设置的值 参数optlen：参数optval的大小，即sizeof(optval) // 组播结构体struct ip_mreq{ struct in_addr imr_multiaddr; // 多播组的IP地址，就是组播的IP地址 struct in_addr imr_interface; // 需要加入到组的IP地址，就是自己的IP地址}; 3、绑定IP地址和端口号12345678910111213141516171819202122232425// 绑定自己的IP地址和端口号 int bind(int sockfd, const struct sockaddr *addr, socklen_t addrlen); // 接口说明 返回值： 参数sockfd：待绑定的套接字 参数addrlen：参数addr的大小，即sizeof(addr) 参数addr：IP地址和端口的结构体，通用的结构体，根据sockfd的类型有不同的定义 当sockfd的domain参数指定为IPV4时，结构体定义为 struct sockaddr_in { unsigned short int sin_family; // 需与sockfd的domain参数一致 uint16_t sin_port; // 端口号 struct in_addr sin_addr; // IP地址 unsigned char sin_zero[8]; // 保留的，未使用 }; struct in_addr { uin32_t s_addr; }// 注意：网络通信时，采用大端字节序，所以端口号和IP地址需要调用专门的函数转换成网络字节序 4、字节序转换接口123456789101112131415161718192021222324252627282930313233// 第一组接口// 主机转网络IP地址，输入主机IP地址uint32_t htonl(uint32_t hostlong); // 主机转网络端口，输入主机端口号uint16_t htons(uint16_t hostshort); // 常用 // 网络转主机IP，输入网络IP地址uint32_t ntohl(uint32_t netlong); // 网络转主机端口，输入网络端口uint16_t ntohs(uint16_t netshort); // 第二组接口，只能用于IPV4转换，IP地址// 主机转网络int inet_aton(const char *cp, struct in_addr *inp); // 主机转网络in_addr_t inet_addr(const char *cp); // 常用 // 网络转主机int_addr_t inet_network(const char *cp); // 网络转主机char *inet_ntoa(struct in_addr in); // 常用 // 将本地IP地址转为网络IP地址int inet_pton(int af, const char *src, void *dst);// 参数说明： 参数af：选择是哪一种协议族，IPV4还是IPV6 参数src：本地IP地址 参数dst：将本地IP地址转为网络IP地址存储到这里 5、发数据12345678910111213141516// UDP协议发送数据ssize_t sendto(int sockfd, const void *buf, size_t len, int flags, const struct sockaddr *dest_addr, socklen_t addrlen); // 接口说明 返回值：成功返回成功发送的字节数，失败返回-1 参数sockfd：发送者的套接字 参数buf：发送的数据缓冲区 参数len：发送的长度 参数flags：一般设置为0，还有其他数值，具体查询别的资源 参数dest_addr：接收者的网络地址 参数addrlen：接收者的网络地址大小，即sizeof(dest_addr) 6、接收数据12345678910111213141516// UDP协议接收数据ssize_t recvfrom(int sockfd, void *buf, size_t len, int flags, struct sockaddr *src_addr, socklen_t *addrlen); // 接口说明： 返回值：成功返回成功接收的字节数，失败返回-1 参数sockfd：接收者的套接字 参数buf：接收数据缓的冲区 参数len：接收的最大长度 参数flags：一般设置为0，还有其他数值，具体查询别的资源 参数src_addr：发送者的网络地址，可以设置为NULL 参数addrlen： 发送者的网络地址大小，即sizeof(src_addr) 7、关闭套接字123456// 关闭套接字int close(int fd); // 接口说明 返回值：成功返回0，失败返回-1 参数fd：套接字文件描述符 五、UDP组播示例发送端GroupSend.c：123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384// UDP组播发送方的案例 #include &lt;stdio.h&gt;#include &lt;unistd.h&gt;#include &lt;string.h&gt;#include &lt;sys/types.h&gt; #include &lt;sys/socket.h&gt;#include &lt;netinet/in.h&gt;#include &lt;netinet/ip.h&gt;#include &lt;arpa/inet.h&gt; #define SEND_IP &quot;192.168.64.128&quot; // 记得改为自己IP#define SEND_PORT 10000 // 不能超过65535，也不要低于1000，防止端口误用 int main(int argc, char *argv[]){ // 1、建立套接字，使用IPV4网络地址，UDP协议 int sockfd = socket(AF_INET, SOCK_DGRAM, 0); if(sockfd == -1) { perror(&quot;socket fail&quot;); return -1; } // 2、设置端口复用（推荐） int optval = 1; // 这里设置为端口复用，所以随便写一个值 int ret = setsockopt(sockfd, SOL_SOCKET, SO_REUSEADDR, &amp;optval, sizeof(optval)); if(ret == -1) { perror(&quot;setsockopt fail&quot;); close(sockfd); return -1; } // 3、绑定自己的IP地址和端口号（可以省略） struct sockaddr_in send_addr = {0}; socklen_t addr_len = sizeof(struct sockaddr); send_addr.sin_family = AF_INET; // 指定协议为IPV4地址协议 send_addr.sin_port = htons(SEND_PORT); // 端口号 send_addr.sin_addr.s_addr = inet_addr(SEND_IP); // IP地址 ret = bind(sockfd, (struct sockaddr*)&amp;send_addr, addr_len); if(ret == -1) { perror(&quot;bind fail&quot;); close(sockfd); return -1; } // 4、发送数据，往组播地址 uint16_t port = 0; // 端口号 char ip[20] = {0}; // IP地址 struct sockaddr_in recv_addr = {0}; char msg[128] = {0}; // 数据缓冲区 // 注意输入组播地址，范围是D类网络地址，224.0.0.1~239.255.255.254 printf(&quot;please input receiver IP and port\\n&quot;); scanf(&quot;%s %hd&quot;, ip, &amp;port); printf(&quot;IP = %s, port = %hd\\n&quot;, ip, port); recv_addr.sin_family = AF_INET; // 指定用IPV4地址 recv_addr.sin_port = htons(port); // 接收者的端口号 recv_addr.sin_addr.s_addr = inet_addr(ip); // 接收者的IP地址 while(getchar() != '\\n'); // 清空多余的换行符 while(1) { printf(&quot;please input data:\\n&quot;); fgets(msg, sizeof(msg)/sizeof(msg[0]), stdin); // 发送数据，注意要填写接收者的地址 ret = sendto(sockfd, msg, strlen(msg), 0, (struct sockaddr*)&amp;recv_addr, addr_len); if(ret &gt; 0) { printf(&quot;success: send %d bytes\\n&quot;, ret); } } // 5、关闭套接字 close(sockfd); return 0;} 接收端GroupRecv.c：123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384// UDP组播接收方的案例 #include &lt;stdio.h&gt;#include &lt;unistd.h&gt;#include &lt;string.h&gt;#include &lt;sys/types.h&gt; #include &lt;sys/socket.h&gt;#include &lt;netinet/in.h&gt;#include &lt;netinet/ip.h&gt;#include &lt;arpa/inet.h&gt; #define RECV_IP &quot;192.168.64.128&quot; // 记得改为自己的地址 #define GROUP_IP &quot;224.0.0.10&quot; // 组播地址#define GROUP_PORT 20000 // 不能超过65535，也不要低于1000，防止端口误用 int main(int argc, char *argv[]){ // 1、建立套接字，使用IPV4网络地址，UDP协议 int sockfd = socket(AF_INET, SOCK_DGRAM, 0); if(sockfd == -1) { perror(&quot;socket fail&quot;); return -1; } // 2、定义并初始化一个组播结构体，设置组播IP struct ip_mreq vmreq; inet_pton(AF_INET, GROUP_IP, &amp;vmreq.imr_multiaddr); // 初始化组播地址 inet_pton(AF_INET, RECV_IP, &amp;vmreq.imr_interface); // 把自己的地址加入到组中 // 3、给套接字加入组播属性 int ret = setsockopt(sockfd, IPPROTO_IP, IP_ADD_MEMBERSHIP, &amp;vmreq, sizeof(vmreq)); if(ret == -1) { perror(&quot;setsockopt fail&quot;); close(sockfd); return -1; } // 4、绑定自己的IP地址和端口号（不可以省略） struct sockaddr_in recv_addr = {0}; socklen_t addr_len = sizeof(struct sockaddr); recv_addr.sin_family = AF_INET; // 指定协议为IPV4地址协议 recv_addr.sin_port = htons(GROUP_PORT); // 端口号，注意绑定为组播的端口号 // recv_addr.sin_addr.s_addr = inet_addr(RECV_IP); // IP地址. 写下面的更好 recv_addr.sin_addr.s_addr = htonl(INADDR_ANY); // 本机内所有的IP地址 ret = bind(sockfd, (struct sockaddr*)&amp;recv_addr, addr_len); if(ret == -1) { perror(&quot;bind fail&quot;); close(sockfd); return -1; } // 4、接收数据 uint16_t port = 0; // 端口号 char ip[20] = {0}; // IP地址 struct sockaddr_in send_addr = {0}; char msg[128] = {0}; // 数据缓冲区 while(1) { // 接收数据，注意使用发送者的地址来接收 ret = recvfrom(sockfd, msg, sizeof(msg)/sizeof(msg[0]), 0, (struct sockaddr*)&amp;send_addr, &amp;addr_len); if(ret &gt; 0) { memset(ip, 0, sizeof(ip)); // 先清空IP strcpy(ip, inet_ntoa(send_addr.sin_addr)); // 网络IP转主机IP port = ntohs(send_addr.sin_port); // 网络端口号转主机端口号 printf(&quot;[%s:%d] send data: %s\\n&quot;, ip, port, msg); memset(msg, 0, sizeof(msg)); // 清空数据区 } } // 5、关闭套接字 close(sockfd); return 0;} 参考博客：https://blog.csdn.net/AABond/article/details/133589579","link":"/2023/12/02/linux-c%E7%BB%84%E6%92%AD/"},{"title":"MD5","text":"MD5信息摘要算法MD5为计算机安全领域广泛使用的一种散列函数，用以提供消息的完整性保护。用于确保信息传输完整一致。是计算机广泛使用的杂凑算法之一（又译摘要算法、哈希算法），主流编程语言普遍已有MD5实现。将数据（如汉字）运算为另一固定长度值，是杂凑算法的基础原理，MD5的前身有MD2、MD3和MD4。 1.MD5算法具有以下特点：123451、压缩性：任意长度的数据，算出的MD5值长度都是固定的。2、容易计算：从原数据计算出MD5值很容易。3、抗修改性：对原数据进行任何改动，哪怕只修改1个字节，所得到的MD5值都有很大区别。4、弱抗碰撞：已知原数据和其MD5值，想找到一个具有相同MD5值的数据（即伪造数据）是非常困难的。5、强抗碰撞：想找到两个不同的数据，使它们具有相同的MD5值，是非常困难的。 根据以上的特定我们能总结出几个根据以上特点衍生出来可以供我们使用的特性: 12341.方便存储:MD5加密出来都是32位的字符串,能够给定固定大小的空间存储,传输,验证2.文件加密:MD5运用在文件加密上很有优势,应为只需要32为字符串就能对一个巨大的文件进行验证完整性3.不 可 逆:MD5加密出来只会截取末尾32位,具有良好的安全性,如果是对于参数加密很难伪造MD54.加密损耗低:MD5加密对于性能的消耗微乎其微(我获得的结果是:0.001毫秒) 2.实际应用2.1.密码管理利用md5加密，我们可以做到即使数据库被窃取，攻击者也无法知道用户的密码。我们利用md5的不可逆性。在用户注册的时候，系统把用户输入的密码计算成 MD5 值，然后再去和系统中保存的 MD5 值进行比较，如果密文相同，就可以认定密码是正确的，否则密码错误。通过这样的步骤，系统在并不知道用户密码明码的情况下就可以确定用户登录系统的合法性。 建议： MD5(MD5(用户名+用户密码)+MD5(KEY+项目名+公司名)) 这样可以避免和别人碰库不排除别人用MD5来攻击你的服务器来匹配. 2.2.请求参数校验都与服务器来言排除系统问题最大的问题就是害怕请求被拦截,拦截修改之后就有很多漏洞的可能性了 为了避免被拦截,参数被修改这种文件的常用方法就是对请求参数进行校验,就算拦截了请求参数修改了只要模拟不出MD5加密出来的值,在服务器过滤器直接就会进行拦截. 我这边推荐的请求校验方法在传递参数的时候带上 MD5值 随机数 时间戳 当然这几个都是由客户端生成 MD5=MD5(随机数+时间戳+MD5(KEY+公司名+项目名)) 当然这个规则也是可以定制的 请求参数在服务器拦截器就用客户端传递过来的 随机数 时间戳 来做校验如果不通过就不让继续访问(在这里的随机数 时间戳在后面的请求安全请求唯一性验证中会起到很大的作用所以建议保留) 2.3文件校验当然对于一些图片已经一些很小很小的文件来说可以不用MD5校验应为基本上都是一次请求就完成了上传,而且显示的时候也不需要验证图片完不整. 但是如果是遇到了大文件上传MD5 就起到作用了,当然不是吧一个几个G 的文件一次性上传使用MD5校验,这边100%会失败 就算传递到服务端了 这个时间是不能被接受的 ,而且服务器最好是对请求做好限制(以后会开一篇来单独探讨文件上传的问题) 我们对于大文件上传的处理方式是进行分片上传,也就是所谓的断点续传,里面的实现机制 如果有一个5MB的文件 客户端把它分割成5份 1MB的文件 在上传的时候 上传两个MD5值 一个是当前上传的片1MB文件流的MD5 还有一个就是拼接之后的MD5(如果现在上传的是第二片 这个MD5就应该是第一片加上第二片的MD5)通过这样的方式能保证文件的完整性 当如果文件传到一半断了,用户换了台机器传 通过验证文件MD5 值就可以得知用户已经传到了第几片 就可以告诉用户从第几片开始传递 就解决了这个问题 2.4垃圾邮件筛选在电子邮件使用越来越普遍的情况下，可以利用 MD5 算法在邮件接收服务器上进行垃圾邮件的筛选，以减少此类邮件的干扰，具体思路如下： 建立一个邮件 MD5 值资料库，分别储存邮件的 MD5 值、允许出现的次数（假定为 3）和出现次数（初值为零）。 对每一封收到的邮件，将它的正文部分进行MD5 计算，得到 MD5 值，将这个值在资料库中进行搜索。 如未发现相同的 MD5 值，说明此邮件是第一次收到，将此 MD5 值存入资料库，并将出现次数置为1，转到第五步。 如发现相同的 MD5 值，说明收到过同样内容的邮件，将出现次数加 1，并与允许出现次数相比较，如小于允许出现次数，就转到第五步。否则中止接收该邮件。结束。 接收该邮件 。 参考文献： https://www.cnblogs.com/chenlong-50954265/p/5647056.html https://baike.baidu.com/item/MD5/212708?fr=aladdin 视频推荐： https://www.bilibili.com/video/BV1u44y1z7t1?from=search&amp;seid=1410709506571007734","link":"/2021/08/18/md5/"},{"title":"redis缓存雪崩、击穿、穿透","text":"1. 缓存雪崩（Cache Avalanche）原理大量缓存数据在同一时间失效，导致大量请求直接打到数据库，数据库压力暴增甚至造成连锁反应导致系统宕机。 流程图12复制编辑用户请求 → 查缓存 ❌（缓存大量过期）→ 查数据库（大量请求）→ 数据库压力爆炸 导致原因 缓存设置了相同的过期时间 某次异常（比如宕机或重启）导致缓存全失效 解决方法 随机打散缓存失效时间（比如 基础时间 + 随机秒数） 设置缓存不过期: 由后台服务更新缓存数据 2. 缓存击穿（Cache Breakdown）原理某个热点数据突然失效，导致大量请求在同一瞬间查询数据库，。 流程图12复制编辑用户请求 → 查缓存 ❌（热点数据失效）→ 查数据库（高并发）→ 数据库压力大 解决方法 加互斥锁（一个线程去数据库查，其它等待）：Redis 中使用 setNX 方法设置一个状态位，表示这是一种锁定状态，保证同一时间只有一个业务线程请求缓存。 设置永不过期+异步更新缓存 3. 缓存穿透（Cache Penetration）简介请求根本不存在的数据，缓存中没有，数据库中也没有，导致每次都打到数据库。 原理 请求无效数据，比如id=-1、超大id。或误删了业务数据。 恶意攻击或异常请求导致大量空查 流程图12复制编辑用户请求 → 查缓存 ❌（缓存无记录）→ 查数据库 ❌（数据库也无记录）→ 每次都查，数据库持续高负载 解决方法 参数校验拦截非法请求 缓存空对象（比如查不到也存入空值，设置较短过期时间）。使的不至于频繁查库 使用布隆过滤器（提前拦截非法请求）：在写入数据库数据时，使用布隆过滤器做个标记，然后在用户请求到来时，业务线程确认缓存失效后，可以通过查询布隆过滤器快速判断数据是否存在，如果不存在，就不用通过查询数据库来判断数据是否存在，即使发生了缓存穿透，如果不存在，就不用通过查询数据库来判断数据是否存在，即使发生了缓存穿透。 4. 三者对比一张表总结 名称 特点 原因 解决方法 雪崩 大量缓存同一时刻失效 批量过期，缓存宕机 随机过期、不过期 击穿 单个热点key失效 热点数据过期 加锁、不过期 穿透 请求不存在的数据，缓存/数据库都无 恶意攻击或异常请求 非法参数检验，缓存空值，布隆过滤器 缓存击穿，成功读取一次加载缓存后便能恢复。而缓存穿透，则次次打到数据库。","link":"/2025/04/17/redis%E7%BC%93%E5%AD%98%E9%9B%AA%E5%B4%A9%E3%80%81%E5%87%BB%E7%A9%BF%E3%80%81%E7%A9%BF%E9%80%8F/"},{"title":"java数组","text":"1.数组的声明和创建正规的如： 1int[] array = new array[10]; 不正规，也可用： 1int array1[] =new array1[10]; 2.数组的三种初始化2.1静态初始化 创建+赋值 静态初始化后不能对其值进行更改 123int[] a={1,2,3,4};//a[1]=8; 报错System.out.println(a[1]); 2.2动态初始化12345//动态初始化：包含默认初始化int[] b = new int[10];b[0]=10;System.out.println(b[0] );System.out.println(b[1]); 2.3默认初始化包含在动态初始化中，new过程中将所有数组初始化 一般设为0，bool值为false 3.数组的内存分析​ Java数组是一种引用数据类型。数组变量并不是数组本身，而是指向堆内存中存放的数组对象。因此，可以改变一个数组变量所引用的数组。 4.二维数组4.1创建1int[][] array ={{1,2},{2,3},{3,4},{4,5}}; 4.2其内存分析 5. Arrays类使用5.1 返回数组代码：Arrays.toString(a) 5.2 给数组赋值fill代码： 5.3 对数组排序sort代码: Arrays.sort(a); 5.4比较数组equals1234567891011121314// Arrays 类 equals()方法// 使用 Arrays.equals()方法比较两个数组元素是否相等package ch22;import java.util.*;public class ArraysEqual { public static void main(String[] args) { int[] arr1 = { 93,5,3,55,57 }; int[] arr2 = { 93,5,3,55,57 }; // ==比较 System.out.println(&quot;arr1==arr2: &quot;+(arr1==arr2)); // equals System.out.println(&quot;Arrays.equals(arr1,arr2): &quot;+Arrays.equals(arr1,arr2)); }}","link":"/2020/12/05/java%E6%95%B0%E7%BB%84/"},{"title":"self- attention&amp;&amp;transformer","text":"Self-attention： Transformer： 1、Seq2Seq介绍1.1 输入：一堆向量文字输入表示有：One-hot-Encoding、Word Embedding 语音输入：语音中提取出一堆向量 1.2 输出：n2n、n21、n2m（sequence-to-sequence）有几个输入就有几个向量。 多个输入一个输出标签： 多个输入多个输出（不确定长度，sequence-to-sequence）： 2、self- attention2.1 self- attention引入对于“I saw a saw”这句话，输出对应词的词性。 然而第一个saw和saw的意思和词性都不一样，那么如何让机器分辨呢？需要上下文的相关内容来推理。如给一个合理的窗口，将前后部分内容也作为输入进行预测。 那么如何确定一个window的大小呢？ 如果需要考虑整个input sequence 才能解决，那么我们将window调为整个数据中最大的长度，进行全覆盖输入吗？这会导致你的网络模型需要很大的参数。 2.2 self- attentionself- attention给出了一种方法考虑了整个sequence的咨询再来推理。 self- attention如何考虑真个sequence呢？ 我们如下定义Alpha相关性： 这里用softmax暂时没有任何道理，你也可以用reLU，只是softmax更常见。 以上讲述了self- attention 如何从一整个sequence得到b1 2.3 矩阵乘法的角度，再次表示self-attetion。 我们对后续计算在进行整合，整合成矩阵乘法。 大体上，总结如上： 2.4 多头自注意机制（multi-head Self-attention）： 2.5 Postitional Encoding上述方法中，并没有位置的标注，就像最后一个单词和第一个单词，与其相邻的重要性比重相似。 然而，位置的信息有可能也是重要的。为此，提出了一种Postitional Encoding。 一些基于学习的位置编码方法： 一些应用： 在语音识别领域：向量长度可能会很大，这就会导致矩阵会非常大。所以一般语音识别中，只对一定范围内的向量进行自注意。这个范围是人设定的。 在图像方面， 把图像三通道看做一个向量，那么也可以用self- attention进行处理。 self-attentio v.s. CNN 简单来说，CNN是简化版的self-attention。self-attetion考虑的范围不再是人工划定，且比CNN考虑范围的更大。 另一个方面，一个比较灵活flexible的model会更容易过拟合，因此也需要更大的数据来进行训练。 self-attention v.s. RNN 如今很多方面的问题，self- attention都可以代替RNN工作，且效果更好。 主要有以下差异： RNN通常指考虑以前序列的影响，而不考虑后面序列。如果一定要考虑，也可以改造RNN使得其成为一个双向的。而self-attention可以轻易的考虑前后的关系。 RNN若要考虑第一个的向量，那么必须用一个memory存下来直到当前步。而self-attetion则不必记录 另一个最大不同，RNN只能串行计算，必须计算出前一个才能计算下一个。然而，self- attention可以直接并行计算一层的输出。 self-attention 在图结构上的应用： graph需要考虑点和边。并且在注意力矩阵中，我们只需考虑有边相连的点。 self- attention有各种变形： 由于self- attention有很大的计算量，为此有了许多变形，来优化速度。 3、transformsequence-to-sequence，最后输出的长度由model决定。 一般的Seq2Seq组成：Encoder、Decoder。 3.1 EncoderEncoder中注意三个重点：self-attention、Residual、Layer norm 一些关于layer normlization的研究： transformer中的设计不一定更好，如更该Layer Norm的位置；为什么Layer Norm比batch norm更好。 3.2 Decoder3.2.1 Autoregressive前一个输出作为后一个的输入，进行串行推理。 如下是Encoder和Decoder一个比较，我们可以看出除去中间部分，剩余部分十分相似。 3.2.2 Masked self-attentionMasked的原因：Decoder后面部分的输入是前一个的输出，因此在输出前几个的结果的时候，Decoder无法得知后面的输入。因此这里是一个Masked的self-attention 3.3 cross-attention连接Encoder和Decoder 3.4 Transformer总体框架： 4、一些补充：4.1 训练seq2seq的一些tips： Copy Mechanism在chat-bot的时候可以对听不懂的东西，或者某个名词进行复制。在summary的时候可以进行抄写一些名词 Guided Attention例如在语音识别中，你希望有一定的注意力顺序，由左向右，而不是乱关注。 Beam Search事实上，bean search找出最优的路线，会使得model一直在重复一些话。然而，如果你需要model具有一些创造力，那么一些随机性对于model来说是更好的。 4.2 一个问题：训练Decoder，他永远看到正确的输入。训练Decoder，他永远看到正确的输入。但是真实预测时候，会有输入的错误，导致一步错步步错。为此在训练时加入一些错误，效果会更好。 4.3 两种“硬train一发”4.3.1 Seq2Seq 硬train一发QA能用sequence-to-sequence解决。 多标签分类能用sequence-to-sequence解决。 目标识别能用sequence-to-sequence解决。 4.3.2 RL硬train一发Optimizing Evaluation Metrics 对于无法直接优化的Loss 如BLEU score ，可以试试RL（reinforcement Learning）硬train一发。 4.4 AT 和 NAT","link":"/2023/11/16/self-attention-transformer/"},{"title":"spring的循环依赖解决方案","text":"在日常开发中，我们有时会遇到 Spring 中的 循环依赖 问题。今天我们来深入理解一下： 什么是循环依赖？ Spring是如何优雅地解决循环依赖的？ 为什么有些情况下不能解决？ 1. 什么是循环依赖？循环依赖，指的是两个或多个Bean相互引用，在创建它们的时候形成了死循环。 比如下面的例子： 1234567891011@Componentpublic class A { @Autowired private B b;}@Componentpublic class B { @Autowired private A a;} 在 Spring 容器初始化时，会去实例化每个 Bean，如果发现依赖其他 Bean，就会递归地先去创建被依赖的 Bean。 如果 A 正在创建，发现依赖 B，于是转去创建 B。 创建 B 时，又发现依赖 A。 这时候如果没有特殊处理，就会无限递归，最终栈溢出或抛出错误。 2. Spring是如何优雅地解决循环依赖的？Spring 为了解决 单例（Singleton）+ setter注入 的循环依赖问题，设计了一个非常巧妙的机制：三级缓存机制。 2.1 三级缓存分别是什么？ singletonObjects：一级缓存（真正成品的单例Bean） earlySingletonObjects：二级缓存（暴露出早期的单例对象，解决循环依赖） singletonFactories：三级缓存（产生早期对象的工厂，用来生成 earlySingletonObjects） 2.2 具体流程（核心过程）： 先实例化Bean(new出来“空壳”，但还没给属性赋值) 将实例化的开始填充属性（populateBean） - 遇到依赖另一个 Bean（比如 A 依赖 B），需要去容器中获取 B。 - Spring发现 B 正在被创建，就去 singletonFactories 或 earlySingletonObjects 中找是否有早期暴露的 B。”三级缓存（singletonFactories）， 提供一个 ObjectFactory供按需生成早期引用。 开始填充属性（populateBean） 遇到依赖另一个 Bean（比如 A 依赖 B），需要去容器中获取 B。 - Spring发现 B 正在被创建，就去 singletonFactories 或 earlySingletonObjects 中找是否有早期暴露的 B。 最后，等所有属性都注入完毕，将完全创建好的 Bean 移入 singletonObjects（一级缓存）。 2.3 流程图12345创建A └── 需要B，去创建B └── 需要A，从earlySingletonObjects拿半成品A └── B创建完成 └── A创建完成 3. Spring 解决不了的部分循环依赖⚡ Spring 只支持： 单例作用域（@Scope(&quot;singleton&quot;)） setter注入或字段注入 ⚡ 不能处理： 构造器注入的循环依赖 原型作用域（@Scope(&quot;prototype&quot;)） 的循环依赖 为什么构造器注入不行？因为构造器注入时，必须在new对象时就完整传入依赖对象，连半成品都没有，没法提前暴露对象，所以 Spring 没办法打破死循环。 1234567891011121314151617@Componentpublic class ServiceA { private final ServiceB serviceB; public ServiceA(ServiceB serviceB) { this.serviceB = serviceB; }}@Componentpublic class ServiceB { private final ServiceA serviceA; public ServiceB(ServiceA serviceA) { this.serviceA = serviceA; }} 如果有构造器循环依赖，会直接抛出： 1org.springframework.beans.factory.BeanCurrentlyInCreationException","link":"/2025/04/20/spring%E7%9A%84%E5%BE%AA%E7%8E%AF%E4%BE%9D%E8%B5%96%E8%A7%A3%E5%86%B3%E6%96%B9%E6%A1%88/"},{"title":"sprintf&amp;snprintf&amp;memcpy&amp;fprintf","text":"1、sprintfint sprintf(char *str, const char *format, ...); 其中，str参数是指向存储输出结果的缓存区的指针，必须具有足够的容量来存储输出结果；format参数是格式控制字符串，定义了输出的格式等；其余的…参数是输出结果 sprintf函数的返回值为输出到缓存区中的字符数量，这个值不包括字符串结尾的’\\0’。 12345char str[100];char *str1 = &quot;Hello&quot;;char *str2 = &quot;World&quot;;sprintf(str, &quot;%s %s!&quot;, str1, str2);printf(&quot;%s\\n&quot;, str); // 输出：Hello World! 2、snprintf在 C 语言中，snprintf 是一个用于格式化字符串并将其写入字符数组的函数。它与 sprintf 函数类似，但 snprintf 允许你指定要写入的最大字符数，避免了缓冲区溢出的风险。 int snprintf(char *str, size_t size, const char *format, ...); str：要写入的目标字符数组的指针。 size：目标字符数组的最大容量。 format：格式化字符串，包含了要写入到字符数组的文本内容，可以包含格式说明符。 12char buffer[50];int length = snprintf(buffer, sizeof(buffer), &quot;The value of x is: %d&quot;, x); 3、fprintfint fprintf(FILE *stream, const char *format, ...); stream 是文件指针，指向要写入的文件。 format 是一个格式字符串，指定了输出的格式，类似于 printf 中使用的格式。 ... 是要输出的变量列表，根据 format 字符串中的格式控制符指定输出的变量。 123456789101112#include &lt;stdio.h&gt;int main() { FILE *fp; int num = 10; fp = fopen(&quot;output.txt&quot;, &quot;w&quot;); // 打开文件用于写入 if (fp != NULL) { fprintf(fp, &quot;The number is: %d\\n&quot;, num); // 将数据写入文件 fclose(fp); // 关闭文件 } return 0;} 也有操作： fprintf( stdout, &quot;The number is: %d\\n&quot;, num); 标准输出 4、memcpymemcpy 是 C 标准库中的一个函数，用于在内存块之间复制数据 void *memcpy(void *destination, const void *source, size_t num); destination：目标内存块的起始地址。 source：源内存块的起始地址。 num：要复制的字节数。 1234char src[] = &quot;Hello, World!&quot;;char dest[20];memcpy(dest, src, sizeof(src));","link":"/2023/11/24/sprintf-snprintf-memcpy-fprintf/"},{"title":"synchronized 底层实现方式","text":"1、synchronized 是什么？锁了什么？synchronized 是 Java 的内置关键字，用来控制线程同步，是JVM 层面原生支持的锁机制，使用简单、可靠、安全。 它可以修饰： 普通方法（锁当前对象） 静态方法（锁类的 Class 对象） 任意代码块（锁任意对象） 本质上是给对象上“监视器锁”（Monitor），锁的核心数据保存在每个对象的对象头（Object Header）中，特别是 Mark Word 字段。 Mark Word 记录了锁的状态信息，比如： 是否加锁 偏向于哪个线程 是轻量级、重量级锁 哈希码、GC 信息等 2.底层原理：字节码 + Monitor + 对象头synchronized 被编译后，在字节码中表现为两个指令： 操作 字节码 说明 加锁 monitorenter 尝试进入对象的 Monitor（加锁） 解锁 monitorexit 离开 Monitor（释放锁） 每个对象背后有个 Monitor（监视器锁） 当线程执行 monitorenter，会尝试抢占这个对象的 Monitor，如果被占用，则阻塞等待。 Monitor 的实现原理： 使用 Mark Word + Monitor 对象 JVM 会根据锁的竞争情况，选择不同锁状态（下面讲） 3.锁的升级机制（从快到慢）为了优化性能，JVM 在 JDK1.6 后加入了锁的升级机制，总共有 4 种锁状态，从轻到重依次是： 锁状态 特点 🟢 无锁 默认状态，没有竞争 🟩 偏向锁 偏向第一个访问线程，下次直接重入，性能最好 🟨 轻量级锁 多线程尝试 CAS 抢锁，失败会自旋 🟥 重量级锁 多线程竞争激烈，自旋n次失败后 → 线程挂起 锁的升级过程是： 1无锁 → 偏向锁 → 轻量级锁 → 重量级锁 ⚠️ 一旦升级，不会降级！ 加锁 &amp; 解锁的完整流程： 以 synchronized(obj) 为例： 初始状态下，对象是“无锁”状态； 第一个线程进来，Mark Word 被设置为“偏向该线程”，进入偏向锁； 如果后续仍是这个线程加锁，直接进入，无需加锁操作； 如果另一个线程也来抢锁： 偏向锁被撤销； 尝试升级为轻量级锁，用 CAS 争锁（可能多次自旋）； 若 CAS 多次失败，JVM 判断竞争激烈，升级为重量级锁，后续线程进入阻塞等待。 锁升级会通过修改对象头中的 Mark Word 完成，JVM 会利用操作系统底层的互斥量（mutex）来实现线程挂起/唤醒。 synchronized 是 JVM 层通过对象头 + monitor 实现的原生锁机制，具有锁升级策略，安全可靠，适合通用并发控制场景。","link":"/2025/04/24/synchronized-%E5%BA%95%E5%B1%82%E5%AE%9E%E7%8E%B0%E6%96%B9%E5%BC%8F/"},{"title":"typora的日常使用","text":"1.标题格式：## ​ 注：几级标题就几个# 快捷键： ctrl+1~6 2.代码标注格式：`` 快捷键：ctrl+shift+~ 3.插入图片快捷键：ctrl+shift+i 3.1同一文件夹下格式：![提示文字](1.jpg) 3.2网络图片格式：![typora.jpg](https://网址) 4.插入超链接格式：！[提示文字](http://www.XXX) 快捷键：ctrl+k 5.目录在需要插入目录的地方打入：[TOC] 6.字体普通格式加粗:ctrl+b 倾斜: ctrl+i 下划线：ctrl+u 删除线：alt+shift+5 7.表格、列表7.1插入表格快捷键：ctrl+t 7.2插入有序列表格式：序号.空格 快捷键：ctrl+shift+[ 7.3插入无序列表格式：*空格或+空格 快捷键：ctrl+shift+] 7.4插入任务列表格式：-空格[空/x]空格","link":"/2020/12/03/typora%E7%9A%84%E5%BF%AB%E6%8D%B7%E9%94%AE%E4%BB%A5%E5%8F%8A%E6%A0%BC%E5%BC%8F/"},{"title":"wireshark&amp;&amp;tshark","text":"暂时常用： 12tshark -f 'port 67 or port 68'tshark -f 'port 67 or port 68'-F pcapng -w 1.pcapng 抓流量： 1234567891011121314151617# 查看可以抓包的网卡信息/usr/local/bin/tshark -D# 抓包 同时支持多个网卡抓包 /usr/local/bin/tshark -i em1 -i lo#设置缓存大小，丢包场景可以设置下，单位为MB/usr/local/bin/tshark -i em1 -B 2 #只抓前面512个字节，抓包小，大流量情况下有用/usr/local/bin/tshark -i em1 -s 512 # 禁止域名解析 只想看ip/usr/local/bin/tshark -i em1 -n #设置包保存文件格式/usr/local/bin/tshark -i em1 -F pcapng -w 1.pcapng 抓包过滤： 1234567891011tshark -f 'port 8080 or port 54' # 常用过滤语法# 抓tcp端口为22 ，且含有fin标识的数据包tshark -f &quot;tcp port 22 and (tcp[tcpflags] &amp; tcp-fin != 0)&quot; #主机过滤not host vs and ace #网络过滤ip and not net localnet 参考博客： https://blog.csdn.net/mseaspring/article/details/128271152","link":"/2023/11/25/wireshark-tshark/"},{"title":"unix xv6 系统实现","text":"1、重定向 c语言一般习惯上默认，文件描述描述符0,1分别表示标准输入、标准输出，这两个文件都连接于shell终端显示。 例如： 一个简单的echo程序： 12345678910111213141516171819#include &quot;kernel/types.h&quot;#include &quot;kernel/stat.h&quot;#include &quot;user/user.h&quot;intmain(int argc, char *argv[]){ int i; for(i = 1; i &lt; argc; i++){ write(1, argv[i], strlen(argv[i])); if(i + 1 &lt; argc){ write(1, &quot; &quot;, 1); } else { write(1, &quot;\\n&quot;, 1); } } exit();} 如果不想使得0,1连接shell，可以进行重定向。关闭0,1，在使用open即可（open使用的文件描述符取为可用的最小). fork &amp;&amp; exec fork 创建一个新进程，其内存内容完全复制原进程（除去一些特定内容，如锁等）。其中，parent进程fork()返回值为子进程号，child进程fork()返回为0。 exec 加载一个文件，并将进程空间全部更替为该文件代码的内容，直行exce()后进程完全替换执行。 以下是一些例子： fork() 12345678910111213141516171819#include &quot;kernel/type.h&quot;#include &quot;user/user.h&quot;intmain(){ int pid; pid = fork(); printf(&quot;fork() returned %d\\n&quot;, pid); if(pid ==0) { printf(&quot;child\\n&quot;); }else{ printf(&quot;parent\\n&quot;); } exit();} exec.c 1234567891011#include &quot;kernel/types.h&quot;#include &quot;user/user.h&quot;intmain(){ char *argv[] = {&quot;echo&quot;, &quot;this&quot;,&quot;is&quot;,&quot;echo&quot;,0}; exec(&quot;echo&quot;, argv); printf(&quot;exec failed!\\n&quot;); exit();} Fork and exec 123456789101112131415161718192021#include &quot;kernel/types.h&quot;#include &quot;user/user.h&quot;int main(int argc, char const *argv[]){ int pid,status; pid = fork(); if(pid == 0) { char *argv[] = {&quot;echo&quot;,&quot;This&quot;,&quot;is&quot;,&quot;Echo&quot;,0}; exec(&quot;echo&quot;,argv); printf(&quot;echo failed!\\n&quot;); exit(); }else{ printf(&quot;parent waiting!\\n&quot;); wait(); printf(&quot;the child exited with status %d\\n&quot;,status); } exit();} 2、用户态和内核态的隔离isolate kernel/user mode systemcall shell echo find -————————— ​ OS -—————————- HW (Such as cpu) 如果没有操作系统进行调度，我们有一种原始的模式：协作模式。协作模式要求每个进程隔一段时间放弃cpu的使用，进行切换。 非强制隔离 3、page内部的隔离 进程cpu资源的切换 内核应该被保护 内核和应用进程的隔离 两种方式隔离，用户内核态、虚拟内存 用户内核态 特权指令：设置页表、设置时钟中断 非特权指令：加减，trap 用户系统调用来请求内核的特权服务 页表：把虚拟地址映射成物理地址 内核进程有自己的页表，只能访问页表中映射的页。页的映射由操作系统完成分配与回收。 内核：可信计算基础 两种设计模式。 为减少内核bug,提高安全性，提出了微内核的架构。只有少量必须由内核完成的包含在内核内。然而，大量进程在用户态，他们之间相互通信需要通过内核态的转换，与内核的通信IPC。因此效率较低。 而unix,windows，macOS这些宏内核，可以大部分处于内核态，可以直接进行通信，但随着规模的增大，容易出bug。 实验： Util实验，并发 QEMU gdb启动 0x8000开始 kernel.asm main.c proc.c initcode.S init.c 系统调用systemcall cpu mmu 内存 页表 mmu通过satp找到映射关系完成映射 虚拟地址到物理地址的映射（内存） 页表完成映射 多级页表的原因：不必一次性载入所有页表 64位计算机，为什么多级页表一级为9位？ 8B一条目，4KB一物理内存，可存512条目，因此9位表示 多级页表，导致了多次访存，为此取一条指令时间成本大大增加（访存时间远大于一次计算时间）。 解决方案，快表TLB translation lockside buufer 记录VA：PA。 虚拟地址到最终页表结果得到的实际物理地址 进程切换时，TLB全部失效，重新访问页表获得。这也是进程切换，所提到的开销大的原因。因为在进程切入之初，所有的指令地址，数据地址，都需要进行多次访存（多级页表）。 普通缓存，有些由虚拟地址索引，有些由物理地址索引。虚拟地址索引在mmu前，物理地址索引在mmu后。 4.syscall 系统调用用户态： user/user.h 用户态函数调用的声明 user/usys.pl 普通进程进行系统调用的具体操作（pl文件编译为user/usys.S） 内核态： kernel/syscall.h 系统调用编号 kernel/syscall.c 系统调用，调用号，在函数数组中去执行具体函数 进程相关的代码： kernel/proc.h Kernel/proc.c trap 进入内核后，将会保存用户态的寄存器（包括通用寄存器，satp，pc等等） 操作系统要认为所有的用户进程都是恶意的，为此进行隔离，保护内核的安全 ecall所做的三件事： 1、从用户态变到内核态 2、保存用户进程pc到sepc、以及保存其他寄存器的值，如到trapframe 3、跳转到stvec指令（放入pc） 其中，stvec中执行了trampoline的内容 stvec 是 RISC-V 架构中的一个 CSR（Control and Status Register，控制和状态寄存器）的名称，用于设置异常向量基址（Exception Vector Base Address）。 在 RISC-V 架构中，异常（例如中断、陷阱或其他处理器异常）的处理是通过异常处理向量表来实现的。stvec 指令可以用于设置异常处理向量表的基址。异常处理向量表存储了异常发生时相应的处理程序的地址。 trapframe这一页保存了进程的一些内容，其中包括了32个插槽，用于保存32个寄存器。 pc存储于sepc寄存器。 trapframe 在xv6中的地址始终是0x3fffffff000地址，代码定义于kernel/proc.h. risc-v提供了sscratch寄存器，在用户态转为内核态的过程中，sscratch存储了指向trapframe的地址。 当系统调用正在trampoline的代码上执行时，cpu会将satp更新为内核（将页面更新为内核页面），问：pc依旧指向原来的下一条，然而此时我们更换了内核页面，也就说pc可能指向一个不知道是什么的地方，为什么整个操作系统没有崩溃？ 因为所有进程的trampoline页面都映射在0x3fffffff000中，这使得更换页面之后依旧可以正常运行。 进程内核栈的守护页 linux将内核和用户空间处于同一套页表中，这使得内核态的切换不必切换整套页表。事实上直至今日，linux也是这么做的。不过这么做容易受到熔断攻击，侧通道攻击。 kpti mode 利用页错误的技巧 lazy alocation sbrk() umunmap panic修改 zero-fill on demand 所有BBS段都映射到同一个只读的全0页 一但需要写入，就会有page fault。 解决：copy+undate pte、restart instruction copy on write fork 所有子进程的页表都从父进程的页表复制，并且父进程和子进程将权限都设置为只读。如此做，意义在于父进程和子进程的页表都映射到同一物理内存，节省了物理内存。当父进程和子进程其中一方写入页面是，会发生页错误，此时内核为子进程复制一份物理页表，父进程仍然指向原来的物理页，权限设置为刻度科协，子进程pte指向新的物理页面，可读可写。然后返回原来的执行，重新执行userret()。 x86有复制内存范围的硬件指令 指令，而risc-v没有。 demand paging 按需分配时对于加载执行文件来说的。若一个二进制文件非常大，那么打开（将程序从磁盘加载到内存）该程序将花费许多时间，为此我们可以延迟加载该部分内容。 当程序运行到一个未加载的虚拟内存的时候（访问程序段或者数据段），会出现页错误。此时我们再加载该页的实际内容，并且va和pa映射，之后再重新执行原来的指令。 demand paging2 如果某个进程的二进制文件很大，或者运行了许多进程，会耗尽物理内存的资源，即out-of-memory。 那么就应该： 淘汰一个页面 在载入所需要的页面 重新执行原来的指令 那么如何淘汰就会涉及一些算法（替换策略），如FIFO，LRU等等。 以及一些脏页和非脏页的概念。有些换出非脏页。若换出脏页则需要进行写入磁盘。 内存映射文件memory-mapped-files 汇编ld，sd，加载内存和存储内存 os实现mmap，mmap（va，len，protected，flags，fd，off） 文件描述符fd 会指向一点内存的虚拟地址，通过off偏移来指定相对位置，并且prot会有一些保护标识，如只读只写等等。 unmap(va,len) 在这里需要把脏页（pte D标志位为1）的数据写回到磁盘。 在内存实现中，unmap不是立即完成的，只需要在某个地方保存副本，比如一个pte属于一个特定的文件描述符，在旁边会有一些控制信息，例如结构体VMA=virtual memory area。 VMA（Virtual Memory Area，虚拟内存区域）是操作系统中用于管理进程虚拟地址空间的抽象概念。它代表了进程地址空间中的一块连续的虚拟内存区域，包含了相似属性的内存页。 如果多个进程对文件进行写入，那么他可能是任意进程写入的一个。如果不进行同步控制，会出现覆盖的情况。这就需要引入文件锁了。 中断interruptshw wants attention now Sw save its work process interrupt resume its work 和系统调用类似 涉及了 异步asynachornous 并发 concyrency 设备编程 课题： shell如何打印$ 以及如何读入数据 PLIC PLIC（Platform-Level Interrupt Controller）和 CLINT（Core Local Interruptor）是 RISC-V 处理器架构中常见的两种中断控制器。 PLIC：PLIC 是 RISC-V 处理器中用于管理外部中断的控制器。它负责管理来自外部设备（如外部 I/O 设备）的中断，并向处理器内核传递这些中断请求。PLIC 通常是多核处理器系统中的共享组件，可以连接多个处理器核心，为每个核心提供中断信息。 CLINT：CLINT 是 RISC-V 处理器中的本地中断控制器。它主要负责处理与特定核心相关的中断。每个核心都有一个本地定时器和本地中断控制器。CLINT 用于处理定时器中断，还包含一个用于处理全局中断的计时器。 driver manages device uart.c 是uart芯片的驱动程序 一个驱动程序大致有如下结构： ​ 中断处理：接收一些设备或者cpu的一些中断信号，进行处理。 ​ 上层：如系统调用等等，进行一些数据与信号的传输。 ​ 队列buffer:缓冲队列进行暂存数据，这使得cpu和设备进行解耦。不必等待彼此。 编程设备 ​ memory mapped i/o ​ 例如在risc-v中对一些特定的物理地址进行映射。 ​ 程序通过ld、st进行read、write 设备的控制寄存器（control register device） $：设备把$放到uart中，然后uart在此之后产生一个中断 ls： 键盘连接到接收line，并且产生中断 RISC-V支持的中断 SIE one bit for E，S，T SSTATUS onr bit 开启禁用中断 SIP 展示时什么中断 SCAUSE 用于存储导致异常或中断的原因代码（cause code） STVEC 用于指定异常处理程序的基址 设备和cpu并行运行，通过生产者消费者方式进行解耦运行 中断的启停，uart、plic、cpu 以上为一些慢速设备的终端，倘若有快速设备的中断，例如网卡，每秒需要处理的速度大于cpu的中断处理能力。操作系统对于这种快速的设备，操作系统进行轮询接收，其处理速率会远高于中断处理，节省了entry和exit的花费。 锁简单的循环判断获取，变量并不能解决竞态问题。 123456while(1){ if(l-&gt;locked==0){ l-&gt;locker=1; return; }} 倘若两个核心分别都同时读入l-》locked，那么它们都将成功进入临界区。锁的设计失败了。 当然也有算法可以实现纯代码的锁，如皮特森算法，面包店算法。 而在操作系统中更常见的是由硬件实现的锁。（原子操作） 硬件实现： 在内存某个位置使用swap的原子操作，进行交换获取锁。 另一个问题是，编译器会在不同架构下对代码进行优化。 那就有可能将要求保护的变量读写的指令，移除了锁的请求和锁的释放之间。这使得实际上锁并没有保护上变量。 进程切换与调度yield 是进程让出cpu的第一步 shed 进行了一些检查 保存了中断的intena 调用switch 从switch返回 Switch 又汇编编写，保存并切换了了一些寄存器。 重要的是ra寄存器，保存了返回执行的地址。（调用者调用switch是以函数调用的方式，这也意味着无需保存pc，而是函数返回时自动设置了pc） 其中switch更换的上下文为，cpu的一段程序，这段程序可以认为是cpu自己的一个进程，代码中自己设置进程号为0（不是一般的进程）； 进程切换的整体流程如下： ​ 使得进程放弃cpu资源进行切换的原因有三：时间中断（时间片用完）、睡眠（等待IO）、进程退出。 ​ 进程不会主动放弃cpu使用权，大多数情况下进程切换是因时间中断。倘若时间中断发生，无论在用户态和内核态，都会进行切换。usertrapret或kerneltrap进行处理时间中断，调用yield函数（上锁、修改当前进程的状态为就绪runable、然后进行sched切换），sched()（进行了安全检查，switch切换到cpu的进程上下文，即调度）。switch中保存了一些寄存器，其中重要的有ra(return address)寄存器，保存了switch程序返回的执行地址。 ​ 切换到另一端是在proc.c中的scheduler()函数switch()后的函数中，在这个scheduler函数中进行了调度的操作。 ​ 一个值得注意点是，普通进程和cpu调度进程之间的p-&gt;locked锁是交错上锁解锁的。具体来说，调度进程找到一个可执行的进程，上p-&gt;locked锁，修改为running状态，然后通过switch切换到进程中，进行执行，进程中的switch后便是解锁p-&gt;locked。当进程时间中断的时候,再scheduler中先上p-&gt;locked锁，改为就绪态，switch切换到scheduler上，然后解锁，进行调度下一个进程。 ​ schedluer在每个cpu执行初始化main.c的最后便进入scheduler的循环调度。 ​ 对于后续创建的进程来说，在进程创建的时候对该进程的上下文进行fake初始化，ra的返回执行地址为forkret()函数地址（后续对第一个进程执行的过程中，进行文件系统的初始化，后续进程不进行；随后usertrapret返回到用户态执行进程指令）。 COW的实现 协作 pipe读写，disk读写 wait() 方案： busy wait ​ while（xxxx）； 文件系统系统open write read link unlink Inode Link count Open fd count（fd必须维护一个偏移量offset） 两个都为0，才可删除文件 names fds icache (目的同步) logging bufcache disk cpu-mem —–PCIe—– SSD HDD Max file size : (256+12)*1024 这是磁盘中目录文件的布局。 在inode中type也会支持这是个目录文件 大的文件系统可以用B-tree实现 写磁盘 Inode create ialloc Bio.c bread ​ bget 在高速缓冲区获取一个插槽（查看相关锁） ​ brealse 自旋锁有许多限制条件： 中断必须关闭 所需时间必须足够小 sleep睡眠锁 所需等待时间较长，为此让出cpu处理资源 为什么fs.c文件中只调用了bread，而没有bwrite呢？ 那对一个文件的修改是如何保存的呢？ 提示：文件系统的日志 文件系统的崩溃安全\\日志系统logcrash safety 文件系统的操作是多步的，当我们正在执行一个多步操作的时候如若内核崩溃、设备掉电等等问题，可能会使得文件磁盘数据损坏。 为此提出了文件日志的解决方案 文件操作是多步的，例如，读取inode、分配inode等等 $echo “hi” &gt; x Write 33 allocate indoe for x Write 33 init inode s Write 46 record x in/directory’s data block Write 32 update root inode Write 33 update inode x Write：45 set alloc bit in bitmap block write 595 write h to allocated data block write 595 write i to allocated data lblock write 33 (sizeupdate,bn0) …. ​ 例如在第二条后崩溃了。在这种情况下，我们已经分配了x的inode，但是我们没有将x记入目录，这使得lose inode，我们甚至没有办法删除该inode ​ 在Write：45 set alloc bit in bitmap block后崩溃呢？lose disk block logging fs的调用都是原子的 fast recovery high performance ​ 在磁盘区域中，我们划出一部分作为日志区域。我们将写入操作，按块写入log区域，当我们commit op时候，我们将log中的block写入文件区域（install），当写入完成后我们清楚该条log。 ​ 当设备在commit前崩溃时，就如同未执行写调用一样。当设备在commit op后发生崩溃，系统便可以在重启的时候将log重新写入文件区域。当设备在install后崩溃时，且log块还没有被清楚，此时系统也重新install，由于重复写同一份数据并不会出错，因此正确执行。 ​ 一个值得说明的是，追加操作并不在这里体现，因为，追加的这些操作一般在内存中实现，内存中的一个块对应入磁盘一个块，这里做的事情是将内存中修改的脏块安全的载入磁盘。 xv6中文件log系统的实现，详见代码。 事实上，上次的write print过程只是卸载log_write中，这次我们将其卸载bwrite中。 $echo “hi” &gt; x Write 33 allocate indoe for x Write 33 init inode s Write 46 record x in/directory’s data block Write 32 update root inode Write 33 update inode x bwrite 3 allocate indoe for x/init inode s/update inode x 事务原子操作的总结果 bwrite 4 record x in/directory’s data block 事务原子操作的总结果 bwrite 5 update root inode 事务原子操作的总结果 bwrite 2 write log head（end_op&quot;commit的结果”） bwrite 33 install change 33 bwrite 46 install change 46 bwrite 32 install change 32 bwrite 2 bwrite 3 bwrite 4 bwrite 5 bwrite 2 bwrite：45 bwrite 595 bwrite 33 bwrite 2 ​ challenges ： bache evication ​ 缓存不应该驱逐日志中的任何块。因此，在log_write一个block后，调用者将block–，此时log_write 中使用bpin使得b.ref++,防止一个事务还未完成的时候，内存将该块内容驱逐出去。 fs op must be fit in log max log size is 30 因为观察得知，一次磁盘的op操作，写入的块基本小于30块。 同时，bcache&gt;=logsize 问：当写入一个大文件的时候，是否会超过30block？ 事实上在sys_write函数中，我们将一个大的文件写入拆成小的文件进行写入。 concernt fs calls，all concurrent ops must fit 当并发执行文件调用的时候，所有的操作都应该写入log。 xv6为了解决这个问题，限制了进行fs调用的数量，当超过可调用的数量，程序便进入睡眠，等待可调用。可在log.c中的begin_op中实现。 这些并发的数据log同时写入，也称为组提交。 文件系统的性能 file system performancelog = “jourual” “ext3” = ext2 + jourual Xv6 log review 元数据：indoe、dir（树桩）、bitmap。保存文件的块我们称为文件块。 log区域 head、记录块。 install 真实的文件区域 带有log的文件系统写入的过程。 每一次的写入操作，从事务开始到事务结束，这一系列的操作都在内存中（cache中）完成，直到运行到commit位置。将数据写入log区域，先写入log的block区域，然后覆写log的head（记录新写入的每个块区域中对应的block number）。（预写规则） ​ 每次必须等log区域内的block都install后才能再次调用log。 在xv6中，cache 通常指的是内存中的软件缓存，用于存储磁盘数据的副本，以提高访问速度。 ​ 由于xv6在将log区的数据写入文件区域的时候，文件系统不能做任何其他的事情(这里需要许多系统调用、磁盘的操作（磁盘需要写入两次，一次写入log，一次写入文件区域）)。也就是说这个文件系统是同步的(synchchrouous)。因此，该文件系统是低效的。 xv6给出的log系统并不高效，学习LINUX ext3文件日志系统 ​ ext3 MEM ​ cache 【】【】【】 ​ traction wfo ​ 1、SEQ、BLOCK num、 HANDELS disk ​ LOG ​ SUPER BLOCK 日志超级块：包含有效书屋偏移量和序列号 ​ OFF、SEQ ​ DESC 描述块（类似于xv6的log head） ​ 内容块 ​ commit块（一个单独的块） 为区分文件块、和提交块描述块：提交块和描述块的的开头为魔数开头。 ASYNC FILES CALLS I/O CONCURRENCY + BATCHING fsysuc（fd） 类似于flush BATCHING ​ one “open” traction。总有一个打开着的事务traction。ex3文件系统中，大概一个大的事务打开5秒，一次将5秒内的一次提交。 ​ write absorbtion。比如，位图，相邻inode节点，倘若有多个事务的话，这些块会多次写入，现在我们将许多块的更新都在内存中进行，多次操作吸收后，大事务提交后的io磁盘的次数会有效减少。 ​ disk scheduler：基于一个事实，顺序文件，相近文件的读写会比随机位置的读写快很多（尤其是机械硬盘）。 CONCURRENCY 1、sys call in parallel。在ext3决定关闭并提交事务之前，系统调用不必相互等待。在ex3中，许多系统调用都可以更改当前事务。 2、many older xaction ​ 1、one open ​ 2、commiting to log ​ 3、writing to home ​ 4、freed 无论是不同块的事务，还是同一块的不同阶段的系统调用都可以并发的运行。 问：ex3是如何做到在内存cache中写入该块的同时，也在讲该块从内存中写入到磁盘？ 事实上，在同一个内存上这两个是不允许的同时进行的。在事务写入log区的时候，应该进包括由该是五中的系统调用进行的更新，不应包括有后续事务的其他的更新。我们不允许在事务关闭后发生的任何更新。它们可并发的原因、解决方案在于，当事务关闭后复制一个该事物的所有副本，直到操作结束为止。而新的系统调用更新，在另一副本中。同时为了更加高效，系统运用了写入时复制的操作。 ext3 ​ sys_unlink() ​ h=start() ​ get(h,block#) ​ modify block in cache ​ stop(h) start返回一个句柄，stop(h)时候并不会直接提交事务。每次start、stop都可以计算出事务中正在执行的系统调用所进行的数量。当正在该事务中执行的系统调用为0时候，提交事务。系统会在合适的时候打开一个新的事务。 commit 1、block new system calls 2、wait for 未完成的syscall 3、open new xaction，（允许新的syscall写入新的事物） 4、write desc block w/ block #s 5、write blocks to log 6、wait for 4、5 7、write commit block 8、wait for commit write “commit point” 9、write to home locations 10、re-use LOG 事务2的系统调用必须在事务1之后是因为，如果交错运行，T2的一些操作是实实在在写入cache中的，然而当T1提交后崩溃，T2的修改会部分执行，这使得T2丢失了原子性。 大内核和微内核 L4操作系统 7个系统调用、13000 行代码 由于微内核中只包含少量的系统调用，磁盘管理、进程管理等等都需要在用户态完成，因此这些模块间的通信IPC便会大大增加，并且用户态和内核态的切换也会更加频繁 IPC 速度 RCU 一个慢的设计 通信的过程：P1向P2发送数据，P1利用系统调用send将数据写入操作系统的缓冲区buffer，写入后便返回，P2系统调用recv从buffer中读出数据。 这样的通信过程我们称之为异步调用。 缓冲系统。 P2向P1发送，则类似。因此两个进程通信需要进行4次系统调用。 L4 fast IPC 它是同步的 非缓冲的 对于小数据来说，零拷贝，将数据放入寄存器后直接切换进程。 对于大的数据来说，进行页表映射。 RPC ​ call—–send+recv 服务端：sendrecv() 20倍更快的速度","link":"/2023/12/18/unix-xv6/"},{"title":"unix xv6 环境","text":"环境配置参考： https://pdos.csail.mit.edu/6.828/2019/labs/util.html https://blog.csdn.net/m0_53157173/article/details/130944057 s081课程地址： https://pdos.csail.mit.edu/6.828/2019/schedule.html","link":"/2023/12/18/unix-xv6-%E7%8E%AF%E5%A2%83/"},{"title":"主要成分分析(PCA)","text":"理论：待完成 Python代码——PCA1234567891011121314151617181920212223242526272829303132import numpy as npx=np.array([[2.5,0.5,2.2,1.9,3.1,2.3,2,1,1.5,1.1], [2.4,0.7,2.9,2.2,3.0,2.7,1.6,1.1,1.6,0.9]])x=x.T #输入数据，样本数为10，特征数为2；行数为样本数，列数是特征数print(x)#-----按列中心化-----#raw=len(x) #行数col=len(x[0]) #列数x_new=np.zeros((raw, col))#创建全为0的数组x_new=x-np.mean(x,axis=0) #-----求协方差矩阵-----#x_cov=np.cov(x_new.T) #Python里cov()函数是按照行向量来计算协方差的 #-----求协方差矩阵的特征值和特征向量feature_value,feature_vector=np.linalg.eig(x_cov) #由特征值、特征向量组成的元组，第一个元素是特征值，第二个是特征量 #-----特征值由大到小排序-----#index=np.argsort(feature_value)[::-1] #获取特征值从大到小排序前的索引feature_value_sort=feature_value[index] #特征值由大到小排序feature_vector_sort=feature_vector[:,index] #特征向量按照特征值的顺序排列 #-----选取主成分，可以根据累积贡献率来选取-----#for i in range(len(feature_value_sort)): if sum(feature_value_sort[0:i+1])/np.sum(feature_value_sort)&gt;0.9: #累积贡献率大于90%的主成分 k=i+1 #主成分个数 breakmain_component = feature_vector_sort[:,0:k] #k维向量 #-----将样本点映射到k维向量上-----#final_data=np.dot(x_new,main_component) #n维数据变成k维数据print(final_data) 参考博客： https://blog.csdn.net/dongke1991/article/details/126774638","link":"/2023/11/03/%E4%B8%BB%E8%A6%81%E6%88%90%E5%88%86%E5%88%86%E6%9E%90-PCA/"},{"title":"从C语言函数指针到回调函数","text":"​ 函数指针允许程序将函数作为参数传给另一个程序B。 ​ 程序B中某个事件发生或完成后，调用通过程序A传入的函数指针，调用函数。这个函数便成为回调函数。 ​ 回调函数优势在于：更灵活（动态调用函数）、控制和处理逻辑分离、异步与事件驱动。 1、函数指针函数定义函数返回值类型 函数名(函数参数列表); 例： 12345#定义int fun(int x,int y);#使用fun(1,2); 函数指针是指向函数的指针变量。 函数指针定义： 函数返回值类型 (* 指针变量名) (函数参数列表); 例： 12345#定义int （*fun）(int x,int y);#使用（*fun）(1,2); typedef简化函数指针定义一般为了方便，我们也会选择typedef简化定义 typedef 函数返回值类型 (* 指针变量名) (函数参数列表); 例： 123456#类型定义typedef int (*func_p)(int x,int y);#定义func_p p;#使用(*p)(1,2); 代码实例：1234567891011121314#include&lt;stdio.h&gt;/* 函数指针的定义、使用 */int printINT(int n){ printf(&quot;num:%d\\n&quot;,n); return 0;}int main(){ int (*p)(int); p=printINT; (*p)(21); return 0;} 12345678910111213141516#include&lt;stdio.h&gt;/* typedef简化函数指针定义，函数指针的定义、使用 */typedef int (*func_p)(int);int printINT(int n){ printf(&quot;num:%d\\n&quot;,n); return 0;}int main(){ func_p p; p = printINT; (*p)(22); return 0;} 2、回调函数​ 回调函数是将函数作为参数传递给另一个函数的函数。在这种情况下，函数的执行在某些条件下会调用传递进来的回调函数。 ​ 通常，回调函数的目的是在某个特定事件发生时执行某些操作。例如，异步操作、事件驱动等。 事件处理： 操作系统中的图形用户界面(GUI)经常使用回调函数来处理事件，比如按钮点击、键盘输入、鼠标移动等。当用户执行某些操作时，系统会调用相应的回调函数来响应这些事件。 异步操作： 操作系统中的I/O操作通常是异步进行的，当一个I/O操作完成时，操作系统会通过回调函数来通知应用程序，以便应用程序可以继续处理已完成的数据。 回调函数的优势： 灵活性和可重用性： 允许开发者编写通用的代码，以便在不同的上下文中重复使用。通过将函数指针传递给其他函数，可以在运行时动态指定要执行的代码，从而实现不同的行为。 事件驱动和异步操作： 在事件驱动的系统中，回调函数常用于处理异步操作和事件处理。当某个事件发生时，可以调用相应的回调函数来处理，这使得编写异步代码更为简单和直观。 分离逻辑和控制流： 回调函数允许将程序的控制流和特定的逻辑分离开来。例如，在图形用户界面 (GUI) 中，可以使用回调函数来处理按钮点击、鼠标移动等事件，使得界面逻辑和事件处理逻辑分离，易于维护和管理。 示例： 12345678910111213141516171819202122232425262728293031323334353637#include&lt;stdio.h&gt;int Callback_1(int a) ///&lt; 回调函数1{ printf(&quot;Hello, this is Callback_1: a = %d &quot;, a); return 0;}int Callback_2(int b) ///&lt; 回调函数2{ printf(&quot;Hello, this is Callback_2: b = %d &quot;, b); return 0;}int Callback_3(int c) ///&lt; 回调函数3{ printf(&quot;Hello, this is Callback_3: c = %d &quot;, c); return 0;}int Handle(int x, int (*Callback)(int)) ///&lt; 注意这里用到的函数指针定义{ (*Callback)(x);}/* 事实上，main应该是另一个程序B，程序A提供回调函数以及回调函数的指针。 B在某个事件完成或发生后，在进行回调函数进行相关处理 */int main(){ Handle(4, Callback_1); Handle(5, Callback_2); Handle(6, Callback_3); return 0;} 四则运算的简单回调函数例子： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273#include &lt;stdio.h&gt;#include &lt;stdlib.h&gt;/**************************************** * 函数指针结构体 ***************************************/typedef struct _OP { float (*p_add)(float, float); float (*p_sub)(float, float); float (*p_mul)(float, float); float (*p_div)(float, float); } OP; /**************************************** * 加减乘除函数 ***************************************/float ADD(float a, float b) { return a + b;}float SUB(float a, float b) { return a - b;}float MUL(float a, float b) { return a * b;}float DIV(float a, float b) { return a / b;}/**************************************** * 初始化函数指针 ***************************************/void init_op(OP *op){ op-&gt;p_add = ADD; op-&gt;p_sub = SUB; op-&gt;p_mul = &amp;MUL; op-&gt;p_div = &amp;DIV;}/**************************************** * 库函数 ***************************************/float add_sub_mul_div(float a, float b, float (*op_func)(float, float)){ return (*op_func)(a, b);}int main(int argc, char *argv[]) { OP *op = (OP *)malloc(sizeof(OP)); init_op(op); /* 直接使用函数指针调用函数 */ printf(&quot;ADD = %f, SUB = %f, MUL = %f, DIV = %f\\n&quot;, (op-&gt;p_add)(1.3, 2.2), (*op-&gt;p_sub)(1.3, 2.2), (op-&gt;p_mul)(1.3, 2.2), (*op-&gt;p_div)(1.3, 2.2)); /* 调用回调函数 */ printf(&quot;ADD = %f, SUB = %f, MUL = %f, DIV = %f\\n&quot;, add_sub_mul_div(1.3, 2.2, ADD), add_sub_mul_div(1.3, 2.2, SUB), add_sub_mul_div(1.3, 2.2, MUL), add_sub_mul_div(1.3, 2.2, DIV)); return 0; } 回调函数实例（很有用）一个GPRS模块联网的小项目，使用过的同学大概知道2G、4G、NB等模块要想实现无线联网功能都需要经历模块上电初始化、注册网络、查询网络信息质量、连接服务器等步骤，这里的的例子就是，利用一个状态机函数（根据不同状态依次调用不同实现方法的函数），通过回调函数的方式依次调用不同的函数，实现模块联网功能，如下： 123456789101112131415161718192021222324252627282930313233343536373839404142/********* 工作状态处理 *********/typedef struct{ uint8_t mStatus; uint8_t (* Funtion)(void); //函数指针的形式} M26_WorkStatus_TypeDef; //M26的工作状态集合调用函数/************************************************ &gt;M26工作状态集合函数***********************************************/M26_WorkStatus_TypeDef M26_WorkStatus_Tab[] ={ {GPRS_NETWORK_CLOSE, M26_PWRKEY_Off }, //模块关机 {GPRS_NETWORK_OPEN, M26_PWRKEY_On }, //模块开机 {GPRS_NETWORK_Start, M26_Work_Init }, //管脚初始化 {GPRS_NETWORK_CONF, M26_NET_Config }, /AT指令配置 {GPRS_NETWORK_LINK_CTC, M26_LINK_CTC }, //连接调度中心 {GPRS_NETWORK_WAIT_CTC, M26_WAIT_CTC }, //等待调度中心回复 {GPRS_NETWORK_LINK_FEM, M26_LINK_FEM }, //连接前置机 {GPRS_NETWORK_WAIT_FEM, M26_WAIT_FEM }, //等待前置机回复 {GPRS_NETWORK_COMM, M26_COMM }, //正常工作 {GPRS_NETWORK_WAIT_Sig, M26_WAIT_Sig }, //等待信号回复 {GPRS_NETWORK_GetSignal, M26_GetSignal }, //获取信号值 {GPRS_NETWORK_RESTART, M26_RESET }, //模块重启}/************************************************ &gt;M26模块工作状态机，依次调用里面的12个函数 ***********************************************/uint8_t M26_WorkStatus_Call(uint8_t Start){ uint8_t i = 0; for(i = 0; i &lt; 12; i++) { if(Start == M26_WorkStatus_Tab[i].mStatus) { return M26_WorkStatus_Tab[i].Funtion(); } } return 0;} 所以，如果有人想做个NB模块联网项目，可以copy上面的框架，只需要修改回调函数内部的具体实现，或者增加、减少回调函数，就可以很简洁快速的实现模块联网。 参考博客：https://blog.csdn.net/qq_41854911/article/details/121058935","link":"/2023/12/02/%E4%BB%8EC%E8%AF%AD%E8%A8%80%E5%87%BD%E6%95%B0%E6%8C%87%E9%92%88%E5%88%B0%E5%9B%9E%E8%B0%83%E5%87%BD%E6%95%B0/"},{"title":"yaml语法","text":"1、简介​ 在创建springboot的文件中有一个application.properties的配置文件，这就是一个自带的springboot的配置文件。 ​ springboot的很多的自动配置，详细见官网：https://docs.spring.io/spring-boot/docs/2.6.0-SNAPSHOT/reference/htmlsingle/#legal ​ 据我了解，在springboot的中配置的方法有以下几种： java的controller类配置 application.properties application.yaml (yml) 我们也可以从源码中看出springboot支持yaml文件配置： 1、语法结构 application.properties 语法结构：key=value application.yml 语法结构：key=空格value 配置文件的作用：修改springboot自动配置的默认值，因为Springboot在底层给我们配置好了 2、yml对比xml yml: 12server: port: 8080 xml: 123&lt;server&gt; &lt;port&gt;8080&lt;/port&gt;&lt;/server&gt; 3、yml对比properties yml对空格有严格的要求，行前空格标识层级关系 123456789101112131415161718#k=v#普通的key-valuename: symbol#对象student: name: symbol age: 3#行内写法student= {name: symbol,age: 3}#数组perts: - cat - dog - pigperts: [cat,dog,pig] properties： 123456#properties 只能保存键值对name=张三student.name=张三student.age=3 2、yaml注入实体类yaml可以直接给实体类赋值 2.1、原先用注解赋值原先我们也可以用注解给实体类赋值 12345678910111213141516171819202122232425262728293031323334353637383940414243public class Dog { @Value(&quot;旺财&quot;) private String name; @Value(&quot;3&quot;) private String age; public Dog() { } public Dog(String name) { this.name = name; } public Dog(String name, String age) { this.name = name; this.age = age; } public String getName() { return name; } public void setName(String name) { this.name = name; } public String getAge() { return age; } public void setAge(String age) { this.age = age; } @Override public String toString() { return &quot;Dog{&quot; + &quot;name='&quot; + name + '\\'' + &quot;, age='&quot; + age + '\\'' + '}'; }} 在SpringbootTest测试类中测试 1234567891011@SpringBootTestclass Springboot02ConfigApplicationTests { @Autowired private Dog dog; @Test void contextLoads() { System.out.println(dog); }} 可以得到以下结果 2.2、yaml注入1234567891011121314151617181920212223242526272829303132333435363738394041424344454647package com.symbol.pojo;import org.springframework.boot.context.properties.ConfigurationProperties;import org.springframework.stereotype.Component;@Component@ConfigurationProperties( prefix = &quot;dog&quot;)public class Dog { private String name; private String age; public Dog() { } public Dog(String name) { this.name = name; } public Dog(String name, String age) { this.name = name; this.age = age; } public String getName() { return name; } public void setName(String name) { this.name = name; } public String getAge() { return age; } public void setAge(String age) { this.age = age; } @Override public String toString() { return &quot;Dog{&quot; + &quot;name='&quot; + name + '\\'' + &quot;, age='&quot; + age + '\\'' + '}'; }} 1234dog: name: &quot;旺财&quot; age: 9 12345678910@SpringBootTestclass Springboot02ConfigApplicationTests { @Autowired private Dog dog; @Test void contextLoads() { System.out.println(dog); }} 2.3、*指定配置文件注入12345678910111213141516171819202122232425262728293031323334353637383940414243@Component//javaConfig绑定我们配置的值，可以采取这些方式！//加载指定的配置文件@PropertySource(&quot;classpath:food.properties&quot;)public class Food { //EL表达式 @Value(&quot;${name}&quot;) private String name; @Value(&quot;${type}&quot;) private String type; public Food() { } public Food(String name, String type) { this.name = name; this.type = type; } public String getName() { return name; } public void setName(String name) { this.name = name; } public String getType() { return type; } public void setType(String type) { this.type = type; } @Override public String toString() { return &quot;Food{&quot; + &quot;name='&quot; + name + '\\'' + &quot;, type='&quot; + type + '\\'' + '}'; }} 12name=1234type=123 12345678910@SpringBootTestclass Springboot02ConfigApplicationTests { @Autowired private Food food; @Test public void m1(){ System.out.println(food); }} 3、优缺点对比 3、一些用法如： 2表达式：如果person.hello不存在，用hello代替 完整实例： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103package com.symbol.pojo;import org.springframework.boot.context.properties.ConfigurationProperties;import org.springframework.stereotype.Component;import java.util.Date;import java.util.List;import java.util.Map;@Component@ConfigurationProperties( prefix = &quot;person&quot;)public class Person { private String name; private Integer age; private boolean happy; private Date birth; private Map&lt;String,Object&gt; maps; private List&lt;Object&gt; lists; private Dog dog; public Person() { } public String getName() { return name; } public void setName(String name) { this.name = name; } public Integer getAge() { return age; } public void setAge(Integer age) { this.age = age; } public boolean isHappy() { return happy; } public void setHappy(boolean happy) { this.happy = happy; } public Date getBirth() { return birth; } public void setBirth(Date birth) { this.birth = birth; } public Map&lt;String, Object&gt; getMaps() { return maps; } public void setMaps(Map&lt;String, Object&gt; maps) { this.maps = maps; } public List&lt;Object&gt; getLists() { return lists; } public void setLists(List&lt;Object&gt; lists) { this.lists = lists; } public Dog getDog() { return dog; } public void setDog(Dog dog) { this.dog = dog; } public Person(String name, Integer age, boolean happy, Date birth, Map&lt;String, Object&gt; maps, List&lt;Object&gt; lists, Dog dog) { this.name = name; this.age = age; this.happy = happy; this.birth = birth; this.maps = maps; this.lists = lists; this.dog = dog; } @Override public String toString() { return &quot;Person{&quot; + &quot;name='&quot; + name + '\\'' + &quot;, age=&quot; + age + &quot;, happy=&quot; + happy + &quot;, birth=&quot; + birth + &quot;, maps=&quot; + maps + &quot;, lists=&quot; + lists + &quot;, dog=&quot; + dog + '}'; }} 12345678910111213141516dog: name: &quot;旺财&quot; age: 9person: name: symbol${random.int} age: 3 happy: &quot;true&quot; maps: { k1: v1 ,k2: v2} lists: - code - music - girl dog: name: ${person.hello:hello}_旺财 age: 6 birth: 2021/07/17 1234567891011121314151617181920212223@SpringBootTestclass Springboot02ConfigApplicationTests { @Autowired private Dog dog; @Test void contextLoads() { System.out.println(dog); } @Autowired private Person person; @Test void m0(){ System.out.println(person); } @Autowired private Food food; @Test public void m1(){ System.out.println(food); }}","link":"/2021/09/07/yaml%E8%AF%AD%E6%B3%95/"},{"title":"共享内存","text":"1、共享内存简介共享内存是最快的进程间通信方式，没有之一。 共享内存的原理是让不同的进程看到同一份内存区域。操作系统OS，申请一块物理内存空间，并将其映射在不同进程的进程空间（逻辑空间）中。 2、优缺点​ 优点：我们可以看到使用共享内存进行进程间的通信真的是非常方便，而且函数的接口也简单，数据的共享还使进程间的数据不用传送，而是直接访问内存，也加快了程序的效率。同时，它也不像匿名管道那样要求通信的进程有一定的父子关系。 ​ 缺点：共享内存没有提供同步的机制，这使得我们在使用共享内存进行进程间通信时，往往要借助其他的手段来进行进程间的同步工作。 3、相关函数1、ftok传入shmget函数(shmget函数用于创建共享内存)的第一个参数key，需要我们使用ftok函数进行获取 key_t ftok(const char *pathname, int proj_id); ftok函数的作用：通过数学运算将一个已存在的路径名pathname和一个整数标识符proj_id转换成一个key值，称为IPC键值，在使用shmget函数获取共享内存时，这个key值会被填充进维护共享内存的数据结构当中。需要注意的是，pathname所指定的文件必须存在且可存取。 ftok运算出来的key值可能会产生冲突，不过概率很小。如果产生冲突，就对ftok的参数进行修改即可。 2、shmget创建共享内存 int shmget(key_t key, size_t size, int shmflg); 参数： key:共享内存段的名字（就是上面我们通过ftok函数获取的key值） size：共享内存的大小 shmflg：创建共享内存的方式 返回值：成功返回一个非负整数。即该共享内存段的标识码；失败返回-1。 第三个参数的组合方式： IPC_CREAT 如果内核中对应key值的共享内存不存在，则新建一个共享内存并返回该共享内存的句柄；如果已存在，则直接返回该共享内存的句柄 IPC_CREAT|IPC_EXCL 如果不存在对应key值的共享内存则新建一个共享内存并返回该共享内存的句柄；如果已存在，则出错返回 关于共享内存，一定是一个进程创建，另一个进程获取，并且最好是创建新的共享内存。共享内存的大小是以PAGE页（4kb）为单位的，用户需要多大，OS给予多大，不过如果超过特定的页，OS直接向上对齐到4kb的整数倍。 3、shmat共享内存的关联（将该内存映射到进程虚拟空间） void *shmat(int shmid, const void *shmaddr, int shmflg); 参数： shmid：是由shmget（创建共享内存函数）返回的共享内存标识码-句柄。 shmaddr：按我们的指定将共享内存映射到进程地址空间的某一地址处，通常设置为NULL，让OS自助决定一个合理的位置。 shmflg：表示关联共享内存设置的属性。设置为0，默认具有读写权限；SHM_RDONLY表示只读操作 返回值： 调用成功，返回共享内存映射到虚拟地址进程空间的起始地址。 调用失败，返回-1 4、shmdt取消共享内存与进程地址空间之间的关联我们需要用shmdt函数 int shmdt(const void *shmaddr); 解读： shmaddr：进程所关联的共享内存的起始地址，即调用shmat函数时得到的返回值 返回值： shmdt调用成功，返回0。 shmdt调用失败，返回-1。 5、shmctl控制共享内存。最需要的便是删除回收这块共享内存 int shmctl(int shmid, int cmd, struct shmid_ds *buf); 函数参数： shmid:是由shmget（创建共享内存函数）返回的共享内存标识码-句柄 cmd：表示控制动作 buf：指向一个保存着（共享内存的模式状态和访问权限-即属性）的数据结构 返回值：成功返回0，失败返回-1 第2个参数的有关选项如下： 命令 说明 IPC_STAT 把shmid_ds结构中的数据设置为共享内存的当前关联值 IPC_SET 在进程有足够权限的前提下，把共享内存的当前关联值设置为shmid_ds数据结构中给出的值 IPC_RMID 删除共享内存段 4、示例这里我们直接指定了key值 1.Header.h12345678910111213#include&lt;sys/ipc.h&gt;#include&lt;sys/shm.h&gt;#include&lt;stdio.h&gt;#include&lt;string.h&gt;typedef struct data_t{ int writing; int len; char buff[1&lt;&lt;10];}data_t;#define SHARED_MEM_ID 0x1122 2.write_process.c1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556#include &quot;header.h&quot;int main(){ int shmid; void *maddr; char buff[1&lt;&lt;10]; data_t *data; int len; shmid = shmget(SHARED_MEM_ID, 0, 0 ); if ( shmid != -1 ) { shmctl( shmid, IPC_RMID, NULL ); shmid = -1; } //1、创建共享空间 shmid = shmget(SHARED_MEM_ID,sizeof(data_t),IPC_CREAT | IPC_EXCL | 0644); if(shmid == -1) { printf(&quot;shared memory creating failed!&quot;); return -1; } printf(&quot;shmid = %d\\n&quot;,shmid); //2、将共享内存与当前进程进行关联 maddr=shmat(shmid,NULL,0); data =(data_t *)maddr; memset(maddr,0,sizeof(data_t)); //3、写入数据 /* 这是一个共享锁 ，当然他有一定缺陷，改进可用文件锁*/ while(data-&gt;writing ==1 ); data-&gt;writing = 1; len = snprintf(data-&gt;buff,sizeof(data-&gt;buff),&quot;Hello,world！&quot;); data-&gt;len = len; data-&gt;writing=0; //稍微暂停 printf(&quot;按任意键结束：\\n&quot;); getchar(); //4.解除关联 shmdt(maddr); //5.删除共享内存 shmctl(shmid,IPC_RMID,NULL); return 0;} 3.read_process.c12345678910111213141516171819202122232425262728293031323334353637383940414243#include &quot;header.h&quot;int main(){ int shmid; void *maddr; char buff[1&lt;&lt;10]; data_t *data; int len; //1、查询获得已创建的共享空间 shmid = shmget(SHARED_MEM_ID,0,0); if(shmid == -1) { printf(&quot;shared memory creating failed!&quot;); return -1; } printf(&quot;shmid = %d\\n&quot;,shmid); //2、将共享内存与当前进程进行关联 maddr=shmat(shmid,NULL,0); data =(data_t *)maddr; //读 /* 这是一个共享锁 ，当然他有一定缺陷，改进可用文件锁*/ while(data-&gt;writing ==1 ); data-&gt;writing = 1; printf(&quot;data:%s/n&quot;,data-&gt;buff); data-&gt;writing=0; //4.解除关联 shmdt(maddr); return 0;} 参考文献： https://blog.csdn.net/weixin_63449996/article/details/131289593 https://blog.csdn.net/qq_43213240/article/details/129976836","link":"/2023/12/03/%E5%85%B1%E4%BA%AB%E5%86%85%E5%AD%98/"},{"title":"关于blog网站搭建的经验分享","text":"&emsp;&emsp;我开始搭建Mr.Symbolのblog要从租用阿里服务器开始说起，出于好奇吧，不过也因为学生买阿里云的轻量服务器价格相当优惠，9.5元/月！比一杯奶茶还便宜，毫不犹豫就下单了。拥有了服务器之后呢，我就想拿它来干点啥了，于是就开始了我的blog网站搭建之旅了。&emsp;&emsp;诶，等一等，等一等，等一等，兄弟们先别冲。阿里云轻量服务器虽香，但还有更香的，那就是Github啦，零成本（G站威武啊）。 下面分享零基础用Github做一个可访问的网页吧1. 注册一个Github账号，邮箱验证，登录。 国内可以访问Github，但速度特别慢。可以自己去探索下某种上网方式。 我还想在外面多待几年，所以我不知道怎么加速，别问我别问我~~ 2.创建一个代码托管仓库 点标识1即可 标识2为以后你查看库的一种方式 3. 然后如下填写： 注意：标识1处填入格式为：用户名.github.io(我演示的这个Github用户名为trytryGithub。所以我填入trytryGithub.github.io) 标识2处为你对这个库的描述，不填也没事。 4. 点击add file, 点击create new file 5. 如下输入: a) index.html 为默认主页 b) 框中是一串html代码。（如果你不会，随便输入一串123456就可，待会你的页面上应该还是能显示123456的） 6. 然后拉到网页最下面，点击commit new file 7. 然后就完成了 在浏览器地址输入：用户名.github.io（例如我输入trytryGithub.github.io回车，就可以访问了） 我们的网站如下： 8. 有些时候网页出错了，那就把库中的READme.md文件删掉。 &emsp;&emsp;好了，那这个网站我们就算建造好了。如果你想让你的网站更美，那就去学点html、css等前端代码，加进这个库就好啦&emsp;&emsp;有一说一，Github这个功能实在太强大了，既不用买服务器域名，也不用自己去调配服务器环境，就能有自己的网站。给Github点赞！","link":"/2020/11/17/%E5%85%B3%E4%BA%8Eblog%E7%BD%91%E7%AB%99%E6%90%AD%E5%BB%BA%E7%9A%84%E7%BB%8F%E9%AA%8C%E5%88%86%E4%BA%AB/"},{"title":"关于c语言的官方文档","text":"ISO/IEC 9899:TC3 （C语言标准） https://port70.net/~nsz/c/c99/n1256.html The GNU C Library (glibc) manual https://sourceware.org/glibc/manual/","link":"/2023/12/02/%E5%85%B3%E4%BA%8Ec%E8%AF%AD%E8%A8%80%E7%9A%84%E5%AE%98%E6%96%B9%E6%96%87%E6%A1%A3/"},{"title":"分布式事务--TCC","text":"一、背景：为什么需要 TCC？在微服务或多库分布式系统中，一个完整的业务通常涉及多个系统，例如： 订单创建 ➝ 扣减账户余额 ➝ 扣减库存 ➝ 添加积分 如何保证多个步骤要么全部成功、要么全部失败？ 传统 2PC/3PC 虽能解决一致性，但存在阻塞、单点、性能差等问题，不适合高并发互联网场景。 因此，TCC（Try-Confirm-Cancel） 模式作为一种柔性事务解决方案应运而生。 二、什么是 TCC 模式？TCC 是 Try - Confirm - Cancel 的缩写，是将分布式事务拆成三个明确的业务动作： 第一阶段。Try-预留资源，冻结数据。 第二阶段。Confirm-确认资源，使用冻结数据完成业务处理。Cancel-取消预留的资源，把之前预留的资源解冻/恢复回去 每个服务都实现这三个操作，协调者驱动执行，保证全局一致性。 三、TCC 示例：账户金额冻结🧾 场景设定用户在下单时需支付 100 元，系统需要： 扣除用户余额 但在订单未完成前不能真正扣款，只能冻结这 100 元 后续根据订单状态选择确认支付 or 回滚释放 ✅ TCC 三步操作详解1️⃣ Try 阶段：冻结金额 检查用户余额是否足够（如剩余 ≥ 100 元） 如果足够，将 100 元从“可用余额”移至“冻结余额” 不做实际扣减，仅冻结 1234UPDATE accountSET available_balance = available_balance - 100, frozen_balance = frozen_balance + 100WHERE user_id = 123 AND available_balance &gt;= 100; 2️⃣ Confirm 阶段：正式扣款 订单创建成功，执行确认操作 将冻结金额正式扣除（从 frozen 中减掉） 123UPDATE accountSET frozen_balance = frozen_balance - 100WHERE user_id = 123; 3️⃣ Cancel 阶段：释放金额 如果订单失败/超时/回滚 将冻结金额恢复为可用余额 1234UPDATE accountSET available_balance = available_balance + 100, frozen_balance = frozen_balance - 100WHERE user_id = 123; 12345678910客户端 ——&gt; TCC 协调者 ——&gt; 账户服务：Try（冻结金额） ——&gt; 库存服务：Try（预扣库存） ——&gt; 商品服务：Try（锁定商品）全部 Try 成功： ——&gt; Confirm 阶段并行提交任一 Try 失败 或 中断： ——&gt; Cancel 阶段回滚所有资源 四、与2PC、3PC对比 特性 2PC/3PC TCC 模型 协议型 业务型(侵入业务代码) 通用性 强，屏蔽业务逻辑 弱，需要定制业务接口 性能 较差 高效 并发性 差，易阻塞 高，非阻塞设计 实现难度 简单，靠中间件 较复杂，每服务需实现三操作 一致性 非极端情况强一致性 最终一致性 五、TCC 的优势与注意事项✅ 优势 特性 描述 非阻塞 各参与服务在本地控制资源，无需锁全局资源 高性能 不依赖协调器长连接，适合高并发环境 可恢复性 每个阶段业务明确，具备幂等与空补偿能力 ⚠️ 实践中需要注意： 幂等性保障：三次操作都要是幂等的（避免重复执行出错） 空回滚处理：Cancel 阶段可能在 Try 未执行时调用，要能识别并跳过 资源隔离设计：如账户余额需区分 available 和 frozen 字段 状态一致性：中间状态需持久化，如记录事务状态表","link":"/2025/05/06/%E5%88%86%E5%B8%83%E5%BC%8F%E4%BA%8B%E5%8A%A1-TCC/"},{"title":"分布式事务--2PC、3PC","text":"一、什么是分布式事务？分布式事务是指涉及多个数据库或多个服务节点的事务处理。它将单库事务的概念扩展到多个库，目的是保证分布式系统中的数据一致性。分布式事务的核心挑战在于，必须确保所有子事务最终达到统一的提交或回滚决策，否则就可能出现数据不一致问题。 在分布式系统中，各个节点物理上独立，通过网络协调。每个节点的本地事务可以满足 ACID 特性，但节点之间无法直接知晓彼此的执行状态。因此，需要引入一个协调者（Coordinator）来统一调度事务操作。 为了解决分布式事务一致性问题，二阶段提交（2PC）和三阶段提交（3PC）协议应运而生。 二、2PC（二阶段提交协议）2PC（Two-Phase Commit）是一种用于保证分布式系统事务一致性的经典协议。其核心思想是： 由协调者统一收集所有参与者的执行结果，再决定是否提交整个事务。 ✅ 两个阶段详解1️⃣ 准备阶段（Prepare / 投票阶段） 协调者发送 Prepare 请求给所有参与者； 参与者执行事务操作（但不提交），写入日志并返回“是否可以提交”； 状态：每个参与者处于“准备提交”状态，锁定资源。 2️⃣ 提交阶段（Commit / 执行阶段） 如果所有参与者返回 Yes： 协调者发送 Commit 请求，所有参与者正式提交； 如果任一参与者返回 No 或超时未响应： 协调者发送 Rollback 请求，所有参与者回滚事务。 流程图: ❌ 存在的问题 同步阻塞： 所有参与者都要等待协调者决策，资源锁定时间长； 协调者单点故障： 若协调者在提交前宕机，参与者不知事务是否成功，无法继续； 数据不一致： 在提交阶段发生部分网络丢包或故障时，可能导致部分参与者提交，部分未提交； 不可恢复状态： 协调者崩溃后无事务状态持久化，无法恢复决策。 三、3PC（三阶段提交协议）🎯 改进目的3PC（Three-Phase Commit）是对 2PC 的增强，引入中间阶段 + 超时机制，降低阻塞风险，让参与者在协调者宕机时也能自行决策。 对2PC的准备阶段进行拆分，引入CanCommit阶段，仅做验证检查。 🔁 三个阶段详解1️⃣ CanCommit 阶段（询问提交） 协调者向参与者发送 CanCommit? 请求； 参与者仅检查是否可以提交，不执行实际事务、不锁资源； 返回 Yes / No； ✅ 优势：不占资源，可过滤无法提交的参与者。 2️⃣ PreCommit 阶段（预提交） 如果所有参与者返回 Yes，协调者发送 PreCommit 请求； 参与者正式执行事务操作、写入日志（但尚未提交），返回 ACK； 进入“准备提交状态”。 3️⃣ DoCommit 阶段（提交执行） 协调者发送 DoCommit 指令，参与者提交事务； 若协调者未发 DoCommit，参与者超时后可自主提交或回滚； ⚠️ 此阶段支持参与者的超时判断与自主处理。 超时相关：协调者#CanCommit、PreCommit 如果收不到参与者的反馈，则向参与者发送中断 参与者#PreCommit，参与者自行执行中断；do commit ，参与者提交事务。（原因：概率因素） 2PC与3PC区别 2PC 3PC 阶段数 两阶段 三阶段（CanCommit + PreCommit + DoCommit） 超时机制 仅协调者有 协调者与参与者都具备 宕机容错 差，容易阻塞 好，参与者可恢复并决策 提交前资源占用 有，提前锁资源 减少，第一阶段不占资源 参与者自主性 无 有，预提交后有判断依据 虽然 3PC 相较于 2PC 更具容错性与弹性，但它仍然存在问题： 引入了更多通信步骤，性能开销大； 复杂的状态控制与超时判断，实现成本高； 如果参与者的状态不可靠或日志丢失，仍可能造成数据不一致。","link":"/2025/04/29/%E5%88%86%E5%B8%83%E5%BC%8F%E4%BA%8B%E5%8A%A1--2PC%E3%80%813PC/"},{"title":"分布式事务--消息队列(rabbitmq\\rocketmq)","text":"一、为什么使用消息队列解决分布式事务？在微服务架构中，一个完整的业务流程往往需要多个服务协作完成，例如： 用户下单 ➝ 扣减库存 ➝ 扣减余额 ➝ 派单 ➝ 发送通知 可通过异步解耦 + 最终一致性的方式，借助 消息队列（MQ） 实现分布式事务。具有重试、消息持久化机制。 二、基于 RabbitMQ 实现分布式事务🧱 原理概述RabbitMQ 本身不具备分布式事务的内置机制，但我们可以借助 确认机制 + 手动 ACK + 补单队列 实现一个可靠的事务解决方案。 实现流程详解1. 消息生产者端：确保消息发送成功 使用 Confirm 确认机制 确保消息成功投递到 Exchange： 成功：进入正常消费流程； 失败：记录日志 + 人工补偿； 注意：生产者发送的是一个包含业务数据的消息（如订单信息 + 派单标识）。 2. 消息消费者端：确保业务消费成功 使用 手动 ACK 确认机制； 如果业务处理失败，NACK，由 RabbitMQ 自动重试； 超过重试次数 ➝ 进入死信队列 ➝ 后期人工补偿。 12channel.basicAck(deliveryTag, false); // 成功确认channel.basicNack(deliveryTag, false, true); // 失败，重新入队 3. 补单机制：解决“事务回滚但消息已发”问题 订单服务事务回滚，但派单消息已成功发出，导致下游派单失败 解决方式：派单消息中带上订单号/核心数据，并设置一个“补单队列”： 派单消费者在消费时，先查订单表是否存在该订单 不存在 → 是异常消息，触发补单逻辑（调用接口重建订单或记录待补单日志） 存在 → 正常执行派单逻辑 优点： 确保下游服务对“幻影消息”有自我恢复能力 异步补偿，而不是依赖 2PC 三、基于 RocketMQ 实现分布式事务🚀 RocketMQ 支持原生的“事务消息”RocketMQ 是阿里巴巴开发的高性能消息中间件，原生支持分布式事务消息（事务型消息）机制，是目前较为成熟的 MQ 事务解决方案。 实现流程详解1️⃣ 步骤一：发送半消息（Prepare Message） 生产者向 RocketMQ Broker 发送一个“事务预消息”； 此消息处于暂时不可消费状态，Broker 持久化存储该消息； 2️⃣ 步骤二：执行本地事务逻辑 比如写入订单、扣库存等数据库操作； 成功或失败后返回执行结果给 RocketMQ（COMMIT / ROLLBACK）； 3️⃣ 步骤三：RocketMQ Broker 处理事务结果 若收到 COMMIT ➝ 允许消费者正式消费该消息； 若收到 ROLLBACK ➝ 删除该半消息，消费者永不感知； 4️⃣ 异常补偿机制 若 RocketMQ 未收到事务执行结果（如网络中断）： Broker 每 1 分钟回查一次生产者事务状态； 最多重试 15 次（默认配置）； 确保消息最终状态可靠。 流程总结： 12341. 订单服务发送“预发货消息” ➝ RocketMQ 半消息2. 订单服务执行本地事务：插入订单表、锁库存3. 本地事务成功，返回 COMMIT ➝ RocketMQ 允许发货服务消费消息4. 发货服务收到消息，执行发货操作 优点 原生支持分布式事务； 自动回查补偿机制，开发简单； 高性能、高并发，分区机制强大； 消息持久化、高可用设计； 四、RabbitMQ vs RocketMQ：事务能力对比 特性 RabbitMQ RocketMQ 原生事务支持 ❌ 无 ✅ 有 消息确认 需要开发者自行实现（Confirm + 手动 ACK） 内置事务消息机制 补偿机制 补单消费者、死信队列 自动回查事务状态 实现复杂度 相对较高 相对简单 适合场景 通用异步消息、轻量任务 分布式事务、强一致性 MQ 模式 特点 场景推荐 RabbitMQ + 补单队列 灵活可控，但需要人工兜底 轻量场景、团队已有 RabbitMQ 基础 RocketMQ 事务消息 原生支持、自动补偿、强一致性 金融、电商等强事务需求系统","link":"/2025/05/06/%E5%88%86%E5%B8%83%E5%BC%8F%E4%BA%8B%E5%8A%A1-%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97-rabbitmq-rocketmq/"},{"title":"双亲委派机制","text":"我们来讲讲 Java 中非常经典的一个机制：双亲委派机制（Parent Delegation Model）。 这个机制是 Java 类加载器体系的基石，它决定了 类加载器是如何查找并加载类的。 一、什么是双亲委派机制？双亲委派机制是一种类加载器的工作模式，它规定： 当某个类加载器需要加载一个类时，它首先不会尝试自己加载，而是把这个请求委托给它的“父类加载器”去完成，只有当父加载器无法加载这个类时，它才尝试自己加载。 这个“委托”的过程是层层向上递归，直到最顶层（Bootstrap ClassLoader），然后再层层向下尝试加载。 双亲委派机制的目标是确保系统核心类的安全、类的加载一致性，以及模块之间的隔离和稳定运行。 二、类加载器的体系结构Java 有以下几个主要的类加载器（从底层到高层，父到子）： 类加载器 负责加载 说明 Bootstrap ClassLoader（引导类加载器） java.* 包（rt.jar） 用 C++ 写的，JVM 自带的，不是 Java 类 Extension ClassLoader（扩展类加载器） ext 目录下的类，如 javax.* 加载 lib/ext 下的 jar 包 App ClassLoader（应用类加载器） 应用程序的类路径 classpath 下的类 是我们最常用的，默认使用它加载用户代码 （用户自定义类加载器） 特殊需求下自定义逻辑 一般用于框架（如 Tomcat、Spring）中实现类隔离、热部署等 📌 每个类加载器都有一个“父加载器”，除了最顶层的 Bootstrap ClassLoader。 三、双亲委派机制的执行流程以应用类加载器 AppClassLoader 加载一个类为例： 1Class.forName(&quot;java.lang.String&quot;); 加载过程如下： AppClassLoader 收到请求加载 &quot;java.lang.String&quot;。 它先将请求委托给 父加载器 ExtensionClassLoader。 ExtensionClassLoader 再将请求委托给 BootstrapClassLoader。 BootstrapClassLoader 尝试加载 java.lang.String，发现它在 rt.jar 中，加载成功。 加载器链路停止，返回 Class 对象，下层加载器不再重复加载。 四、双亲委派机制的优点 防止类重复加载（类的唯一性） 同一个类只能由一个类加载器加载一次，保证类的全局唯一性。 保护核心类库不被篡改 比如你不能自定义一个 java.lang.String 类，即使路径一样，父加载器已经加载了真正的 String，你的不会被加载。 模块隔离、可插拔 Tomcat、WebLogic、Spring Boot 中，不同模块可能使用不同的类加载器 五、打破双亲委派：为什么要“破坏”它？JVM 会认为“同一个类的字节码文件”，如果是由不同的类加载器（ClassLoader）加载的，那它们就是两个完全不同的类 虽然双亲委派很安全，但某些场景下我们需要打破它： Tomcat、Spring Boot、OSGi、JDBC 驱动等框架 它们需要 不同类加载器加载不同模块或插件，实现类隔离、热部署。 破坏方式： 自定义类加载器重写 loadClass() 方法时，不调用 super.loadClass()。 或者先尝试自己加载，失败再委托父加载器（即 “先自己后父亲” 模式）。 JDBC 驱动加载常常与 类加载器和双亲委派机制 发生冲突，尤其在如下场景中： 1.JDBC 驱动无法被加载 当你调用 Class.forName(&quot;com.mysql.cj.jdbc.Driver&quot;) 时，如果该类不在 系统类加载器或其父加载器 的路径中，加载就会失败。 2.多个 ClassLoader 导致 DriverManager 无法识别驱动 DriverManager 是由 系统类加载器 加载的。如果你用 自定义类加载器 加载 JDBC 驱动类，它就不会被注册到 DriverManager 的驱动列表中，因为 DriverManager 看不到它。 解决方式有两种： 显式调用 DriverManager.registerDriver(new com.mysql.cj.jdbc.Driver()); 使用 JDBC 4.0 的 SPI（服务提供者机制），自动注册驱动。 六、简易源码123456789101112131415161718192021222324protected Class&lt;?&gt; loadClass(String name, boolean resolve) throws ClassNotFoundException { // 检查是否已被加载 Class&lt;?&gt; c = findLoadedClass(name); // 1. 委托父加载器 if (c == null) { try { c = getParent().loadClass(name); } catch (ClassNotFoundException e) { // 忽略，由当前类加载器继续尝试 } } // 2. 自己尝试加载 if (c == null) { c = findClass(name); } // 链接 if (resolve) { resolveClass(c); } return c;}","link":"/2025/04/24/%E5%8F%8C%E4%BA%B2%E5%A7%94%E6%B4%BE%E6%9C%BA%E5%88%B6/"},{"title":"图像卷积&amp;&amp;卷积神经网络","text":"摘要：信号系统中的卷积，实际上是计算累加会衰退的值。图像处理中的卷积，实际上是对局部区域的一个加权累加计算，可以进行边缘检测（提取特征）与滤波等功能。卷积神经网络（CNN）中的卷积核，形式上犹如图像处理，但是卷积核的参数是有网络自学习所得到的。事实上CNN的卷积实现了全连接的权值共享，减少了参数、计算量，也保留了大量的特征。 1、信号系统——卷积信号系统中的卷积要解决的问题：计算累加会衰退的权值。 例子：往湖面丢一个石头，湖面上会有涟漪，而涟漪会随时间逐渐变淡。如果你在扔一颗石头，又会有一个新的涟漪。而湖面会有上次淡化的水波，也会有这次新产生的水波，水波是会叠加的，那么如何表示这个总的状态呢？ 另一个例子是：人一日三餐，你早上8：00吃了早饭，并且在肚子里消化，问9点你肚子里还有多少食物。当你12点吃了午饭，问肚子里肚子里还有对食物？ 事实上，卷积所做的事情正是计算如上胃中还剩下多少食物。 其实呢卷积的本质就是翻转，相乘，相加的这么一个过程 2、图像处理——卷积 ​ 如上图中所示，3x3的卷积核原图上进行相乘后累加的出一个值，然后依次移动计算各各值。 ​ 图像简单边缘检测：由于图像一些某些部分的颜色和强度差不多，为此只会在边缘进行变化，那么两遍做差便能找出大致的边界。 ​ 图像的高斯滤波也是用卷积核进行计算。 3、卷积神经网络（CNN）——卷积​ CNN中卷积核事实上核图像处理中的卷积核，只不过卷积核的参数是有神经网络学习而得。不像图像处理中的一些边缘检测卷积核、高斯滤波卷积核是固定的参数。 ​ CNN的一个好处是，用网络自学习的方式去自己选择适合的卷积核。这种End2End的操作，减少了手工题特征的工作量，并且结果上也可以更适合于总体结果。 ​ CNN的卷积核，可以看成是全连接网络的权值共享。减少了权重，降低了计算量，较大程度的保留了原始图像中的信息。","link":"/2023/11/17/%E5%9B%BE%E5%83%8F%E5%8D%B7%E7%A7%AF-%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/"},{"title":"处理Http请求的完整过程(Tomcat + SpringMVC)","text":"简单流程： 1浏览器 --&gt; HTTP 请求 --&gt; Tomcat（Servlet 容器）--&gt; DispatcherServlet（SpringMVC的核心） 1、Tomcat 接收并处理网络层请求 步骤 描述 1.1 监听端口（默认 8080），接收 TCP 连接 1.2 从线程池中取出工作线程，解析 TCP 数据，识别为 HTTP 请求 1.3 将 HTTP 请求封装为 HttpServletRequest 对象，创建空的 HttpServletResponse 对象 1.4 调用SpringMVC 的 DispatcherServlet，从 URL 匹配对应的 Servlet 2、SpringMVC 接管：DispatcherServlet 登场 步骤 描述 2.1 DispatcherServlet 接收到 HttpServletRequest/Response 对象 2.2 查找 HandlerMapping，根据 URL 找到对应的 Controller 方法 2.3 调用 HandlerAdapter 执行这个方法 2.4 Controller 执行业务逻辑，返回 ModelAndView 或响应体（如 JSON） 2.5 如果是视图，使用 ViewResolver 渲染成 HTML 页面 2.6 返回响应数据，写入 HttpServletResponse 3.Tomcat 回传响应给客户端 步骤 描述 4.1 SpringMVC 方法执行完成，Tomcat 拿到填充好的 HttpServletResponse 4.2 将响应数据写入底层 Socket，转为 TCP 数据发回客户端 4.3 请求处理线程释放，回到线程池等待下一个请求 4.总结12345678910111213[浏览器请求] ↓[Tomcat 接收 TCP → HTTP] ↓[封装成 HttpServletRequest/Response] ↓[调用 DispatcherServlet.service()] ↓[SpringMVC 分发：HandlerMapping → Controller → ViewResolver] ↓[返回响应数据] ↓[Tomcat 发送响应 → 客户端] 层级 谁负责 关键工作 TCP/HTTP Tomcat 监听端口，解析请求，封装 Servlet 请求对象 请求分发 DispatcherServlet（SpringMVC） Controller 分发、视图解析 响应 Tomcat 写入响应数据并发送回客户端 线程管理 Tomcat 请求线程池，控制并发数量","link":"/2025/04/23/%E5%A4%84%E7%90%86Http%E8%AF%B7%E6%B1%82%E7%9A%84%E5%AE%8C%E6%95%B4%E8%BF%87%E7%A8%8B-Tomcat-SpringMVC/"},{"title":"如何用布隆过滤器和空值缓存抵御黑产刷接口攻击","text":"随着业务规模扩大，各类黑产攻击（如接口刷取、暴力破解、资源盗刷）越来越频繁。为了有效防御黑产刷接口，同时减少后端数据库的压力，我们可以结合 布隆过滤器 和 空值缓存，搭建一套高效、可扩展的防御体系。 本文将从 Key设计维度、布隆过滤器应用、空值缓存机制、误判率控制 以及 整体架构设计 五个方面展开详细分享。 1. 确定Key的维度要防御黑产攻击，首先要明确：什么特征能代表一次恶意请求？这些特征就是我们需要拦截和缓存的“Key”。 常见的维度包括： 用户标识：如用户ID、手机号、设备ID、设备指纹。 请求特征：如IP地址 + 接口路径的组合。 行为特征：如不存在的订单号、商品ID、券码等非法查询。 举例： 若遭遇大量随机订单ID查询，可以选择 用户IP+订单ID 作为Key；如果是单个IP频繁刷接口，可以选择 IP地址 作为Key。 2. 布隆过滤器的应用布隆过滤器（Bloom Filter）是一种空间效率极高的数据结构，适合用于判断某个元素是否存在于集合中。它有一定的误判率（即有小概率误认为存在），但在抵御黑产场景下是可以接受的。 应用步骤如下： a. 初始化阶段 将已有的恶意Key（如黑名单IP、无效订单号）预加载到布隆过滤器中。 b. 动态更新 当检测到新的恶意行为时，实时将对应Key添加进布隆过滤器中。 c. 优化误判率 合理设置布隆过滤器参数： 增大位数组容量。 选择合适数量的哈希函数。 引入白名单机制： 白名单用户、白名单IP不走布隆过滤器校验，避免误伤。 3. 空值缓存的应用对于无效查询（如不存在的订单号、商品ID），即使通过布隆过滤器，也可能查询到数据库，增加压力。此时，可以使用空值缓存机制。 核心逻辑： 将查询结果为空的Key，缓存到Redis等缓存层。 设置合理的TTL（过期时间），比如5-10分钟，防止缓存长期污染。 下次同样请求到来时，直接在缓存层返回“无数据”，不再穿透数据库。 4. 控制误判率虽然布隆过滤器存在误判率，但我们可以通过多种策略，将误判影响控制在可接受范围内： a. 动态调整布隆过滤器 监控日志，观察误判情况。 动态扩容位数组或调整哈希函数数量。 使用支持扩容或删除元素的布隆变种，如Counting Bloom Filter。 b. 兜底校验机制 对被布隆过滤器拦截的请求，允许用户通过二次验证（如短信验证码、滑动验证）解除封禁。 或结合数据库进行最终一致性校验，确保不会误杀正常用户。 c. 多层防御 限流保护：根据IP、用户ID设置访问速率上限。 行为分析：引入机器学习模型，识别异常访问模式。 验证码策略：针对高频异常请求自动弹出验证码，人机分离。 d. 精确数据结构 在数据量不大或关键场景中，采用哈希表、字典等精确数据结构，做到绝无误判。 5. 总体防御架构设计结合以上方案，我们可以设计如下防御流程： 123456789请求进入 ↓布隆过滤器拦截恶意Key ↓空值缓存拦截无效查询 ↓限流/验证码二次验证 ↓最终穿透至数据库查询 注意： Key维度要贴合业务特点，重点拦截高频攻击特征。 误判率通过参数优化、白名单机制、动态扩容等手段控制。 空值缓存要合理设置TTL，避免正常业务受损。 小结应对黑产刷接口攻击，不仅要靠限流、验证码等传统手段，更要合理运用数据结构和缓存机制，做到既拦截恶意流量，又保障正常用户体验。 布隆过滤器+空值缓存的组合，轻量、高效、实用，非常适合在微服务、接口型系统中推广应用。 未来，我们还可以在此基础上，结合 动态黑白名单、机器学习模型识别，打造更智能的防护体系。","link":"/2025/04/28/%E5%A6%82%E4%BD%95%E7%94%A8%E5%B8%83%E9%9A%86%E8%BF%87%E6%BB%A4%E5%99%A8%E5%92%8C%E7%A9%BA%E5%80%BC%E7%BC%93%E5%AD%98%E6%8A%B5%E5%BE%A1%E9%BB%91%E4%BA%A7%E5%88%B7%E6%8E%A5%E5%8F%A3%E6%94%BB%E5%87%BB/"},{"title":"如何确定线程数","text":"在高并发环境下，合理设置线程池的线程数，能有效控制资源开销，提升系统响应速度和稳定性。线程数设置过少或过多，都会影响系统性能，因此需要结合实际情况精心确定。 1. 为什么要合理设置线程数 线程太少：任务堆积，吞吐量低，响应慢。 线程太多：频繁上下文切换，增加CPU调度开销，甚至导致内存耗尽、性能下降。 2. 了解任务类型线程数量的设定要根据任务性质分类处理： CPU密集型任务 特点：主要消耗CPU计算资源。 线程数建议：CPU核心数 + 1。 理由：避免线程过多导致无谓的切换开销。 IO密集型任务 特点：经常等待外部资源（磁盘、网络等）。 线程数建议：CPU核心数 × 2+1（或更高）。 理由：等待期间CPU空闲，可以用更多线程提高并发度。 混合型任务 特点：既有计算又有IO。 建议：将计算和IO拆分，分别使用不同配置的线程池。 3. 理论指导 + 实际调整 理论计算只能作为初步参考。 必须通过性能监控和压力测试，动态调整线程池参数。 重点监控指标： CPU利用率 吞吐量 响应时间 内存使用情况 4. 小结确定线程池线程数，需要根据任务类型，结合系统硬件情况，理论估算 + 压测验证，最终找到最适合自身业务的最佳值，而不是盲目套用公式。","link":"/2024/05/06/%E5%A6%82%E4%BD%95%E7%A1%AE%E5%AE%9A%E7%BA%BF%E7%A8%8B%E6%95%B0/"},{"title":"定时任务","text":"转载自：https://www.jianshu.com/p/ac3daf7a248f 一、ScheduledThreadPoolScheduledThreadPool是JDK自带的类，可以用来替代Timer类实现定时任务。一个Timer只能执行一个任务，而一个ScheduledThreadPool却可以同时执行多个定时任务。用法很简单，直接看例子： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849public class ScheduledThreadPoolService { private Logger logger = LoggerFactory.getLogger(getClass().getSimpleName()); // 参数代表可以同时执行的定时任务个数 private ScheduledExecutorService service = Executors.newScheduledThreadPool(3); /** * schedule：延时2秒执行一次任务 */ public void task0() { service.schedule(() -&gt; { logger.info(&quot;task0-start&quot;); sleep(2); logger.info(&quot;task0-end&quot;); }, 2, TimeUnit.SECONDS); } /** * scheduleAtFixedRate：2秒后，每间隔4秒执行一次任务 * 注意，如果任务的执行时间（例如6秒）大于间隔时间，则会等待任务执行结束后直接开始下次任务 */ public void task1() { service.scheduleAtFixedRate(() -&gt; { logger.info(&quot;task1-start&quot;); sleep(2); logger.info(&quot;task1-end&quot;); }, 2, 4, TimeUnit.SECONDS); } /** * scheduleWithFixedDelay：2秒后，每次延时4秒执行一次任务 * 注意，这里是等待上次任务执行结束后，再延时固定时间后开始下次任务 */ public void task2() { service.scheduleWithFixedDelay(() -&gt; { logger.info(&quot;task2-start&quot;); sleep(2); logger.info(&quot;task2-end&quot;); }, 2, 4, TimeUnit.SECONDS); } private void sleep(long time) { try { TimeUnit.SECONDS.sleep(time); } catch (InterruptedException e) { e.printStackTrace(); } }} 和线程池的使用类似，也是通过Executors类来创建ScheduledThreadPool，常用的方法例子中都有说明，简单的定时任务使用ScheduledThreadPool实现就可以了，也不用引入其它依赖，还是挺方便的。 二、 @Scheduled@Scheduled是Spring框架的定时任务实现，相比JDK的ScheduledThreadPool功能更加强大。可以先创建一个Spring Boot项目，在启动类上添加@EnableScheduling注解，使@Scheduled生效，开启定时任务： 1234567@SpringBootApplication@EnableSchedulingpublic class LearnSpringbootApplication { public static void main(String[] args) { SpringApplication.run(LearnSpringbootApplication.class, args); }} 然后就是定义任务类，用@Scheduled配置具体的定时规则： 12345678910111213141516171819202122232425262728293031323334353637383940414243@Servicepublic class ScheduleService { private Logger logger = LoggerFactory.getLogger(getClass().getSimpleName()); /** * fixedRate：每间隔2秒执行一次任务 * 注意，默认情况下定时任务是在同一线程同步执行的，如果任务的执行时间（例如6秒）大于间隔时间，则会等待任务执行结束后直接开始下次任务 */ @Scheduled(fixedRate = 2000) public void task0() { logger.info(&quot;task0-start&quot;); sleep(6); logger.info(&quot;task0-end&quot;); } /** * fixedDelay：每次延时2秒执行一次任务 * 注意，这里是等待上次任务执行结束后，再延时固定时间后开始下次任务 */ @Scheduled(fixedDelay = 2000) public void task1() { logger.info(&quot;task1-start&quot;); sleep(6); logger.info(&quot;task1-end&quot;); } /** * initialDelay：首次任务启动的延时时间 */ @Scheduled(initialDelay = 2000, fixedDelay = 3000) public void task2() { logger.info(&quot;task2-start&quot;); sleep(6); logger.info(&quot;task2-end&quot;); } private void sleep(long time) { try { TimeUnit.SECONDS.sleep(time); } catch (InterruptedException e) { e.printStackTrace(); } } fixedRate、fixedDelay、initialDelay属性的时间单位是毫秒，用法也比较简单，可参考代码的注释。 这里我们重点看使用@Scheduled的cron属性定义定时任务的时间表达式，它的功能更加丰富。先看一个简单的例子： 1234567891011121314@Servicepublic class ScheduleService { ................... /** * 每天晚上23:59执行一次 */ @Scheduled(cron = &quot;0 59 23 * * ?&quot;) public void task3() { logger.info(&quot;task3-start&quot;); sleep(6); logger.info(&quot;task3-end&quot;); } ...................} 接下来具体看cron属性对应时间表达式的定义规则： 1、按顺序依次是：秒、分、时、日、月、周，中间用空格间隔 2、月、周可以用数字或英文单词的前三个字母表示 3、日和周可能会冲突，因此两个可以有一个配置为? 4、常用通配符的含义： *表示任意值，例如在秒字段上设置*，表示每秒都触发 ?表示不指定值，只能出现在日或者周的位置，用于处理日和周可能存在的冲突，例如2020年8月15是周六，如果又在周的位置上指定为周一，那就会产生冲突到导致定时任务失效。如果我们不关心日或者周的时候，也可以将其设置为? -表示时间区间，例如在秒上设置1-3，表示第1、2、3秒都会触发 /表示时间间隔，例如在秒上设置2/4，表示从第2秒开始每间隔4秒触发一次 ,表示列举多个值，例如MON,WED,FRI表示周一、周三、周五触发 5、几个表达式的例子： 0 0 9 * * ?：每天早上9点触发 0 0/30 * * * ?：每30分钟触发一次 0 30 18 ？ * MON-FRI：每周一到周五的18:30分触发 0 10 12 1,15 * ?：每月1号、15号的12:10触发 0 0/10 7-8 1,15 * ?：每月1号、15号早上7点到8点每10分钟触发一次 6、注意，不同版本的Spring对cron属性的支持有所差异，例如较新的版本中cron属性只支持6个字段，不包含年份；同时#、L、W通配符也不支持。 7、注意，@Scheduled默认会使用同一线程同步的去执行所有定时任务，要打破这一点，可以在Spring Boot启动类上配置@EnableAsync注解来开启异步线程可用，然后在定时任务方法上配置@Async注解，则会使用异步线程去执行定时任务。 三、Quartz除了上边的方式之外，我们还有更好的选择，那就是Quartz，在Spring Boot中集成Quartz需要先添加如下Maven依赖： 12345&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-quartz&lt;/artifactId&gt; &lt;version&gt;2.3.2.RELEASE&lt;/version&gt;&lt;/dependency&gt; 和@Scheduled一样，也需要在启动类添加@EnableScheduling注解来开启定时任务： 1234567@SpringBootApplication@EnableSchedulingpublic class LearnSpringbootApplication { public static void main(String[] args) { SpringApplication.run(LearnSpringbootApplication.class, args); }} 这样准备工作就完成了。接下来先了解几个重要的概念： Job：定义具体要执行的任务 JobDetail：配置要执行任务的描述信息，即如何去定位要执行的Job，每次执行任务时，都会根据JobDetail创建一个Job对象，避免任务并发执行时访问同一个Job对象产生问题 Trigger：触发器，配置任务执行的时间规则，需要和一个JobDetail关联起来 Scheduler：调度器，它维护了一个JobDetail和Trigger的注册表，当任务关联的触发器到达预定的时间，调度器会去执行任务 接下来通过Quartz实现定时任务，可以按照上边几个重要概念的顺序来完成。 1、定义Job定义Job有两种方式， 第一种是直接定义任务类，并注册到Spring IoC容器中： 12345678910@Servicepublic class QuartzJob { private Logger logger = LoggerFactory.getLogger(getClass().getSimpleName()); public void hello(){ logger.info(&quot;job0-start&quot;); Utils.sleep(TimeUnit.SECONDS, 4); logger.info(&quot;job0-end&quot;); }} 第二种是继承QuartzJobBean，重写executeInternal方法，这种方式可以接受JobDetail传递的参数： 1234567891011121314public class QuartzJob2 extends QuartzJobBean { private Logger logger = LoggerFactory.getLogger(getClass().getSimpleName()); @Override protected void executeInternal(JobExecutionContext jobExecutionContext) throws JobExecutionException { logger.info(&quot;job1-start&quot;); Utils.sleep(TimeUnit.SECONDS, 4); // 获取参数 JobDataMap jobDataMap = jobExecutionContext.getMergedJobDataMap(); String date = jobDataMap.getString(&quot;date&quot;); logger.info(&quot;参数：&quot; + date); logger.info(&quot;job1-end&quot;); }} 这样就把JobDetail和我们之前定义的QuartzJob关联起来了。 2、配置JobDetailJobDetail可以使用MethodInvokingJobDetailFactoryBean或者JobDetailFactoryBean配置，配置工作需要在一个Spring配置类中完成，可以定义一个QuartzConfig配置类，首先看MethodInvokingJobDetailFactoryBean的使用： 123456789101112@Configurationpublic class QuartzConfig { @Bean public MethodInvokingJobDetailFactoryBean methodInvokingJobDetailFactoryBean() { MethodInvokingJobDetailFactoryBean bean = new MethodInvokingJobDetailFactoryBean(); // 指定任务类在IoC容器中的Bean名称 bean.setTargetBeanName(&quot;quartzJob&quot;); // 指定要执行的方法名称 bean.setTargetMethod(&quot;hello&quot;); return bean; }} 这样就把JobDetail和之前QuartzJob所定义的任务关联起来了，接下来看JobDetailFactoryBean： 123456789101112131415@Configurationpublic class QuartzConfig { @Bean public JobDetailFactoryBean jobDetailFactoryBean() { JobDetailFactoryBean bean = new JobDetailFactoryBean(); // 指定任务类名称 bean.setJobClass(QuartzJob2.class); // 准备参数 JobDataMap jobDataMap = new JobDataMap(); jobDataMap.put(&quot;date&quot;, &quot;2020-8-16&quot;); // 传递参数 bean.setJobDataMap(jobDataMap); return bean; }} 这样就把JobDetail和之前定义的QuartzJob2关联起来了，同时传递了参数。 3、配置TriggerTrigger同样定义在QuartzConfig配置类里，常用的Trigger有SimpleTrigger、CronTrigger等，它们分别可以通过SimpleTriggerFactoryBean、CronTriggerFactoryBean来完成配置，我们先用SimpleTriggerFactoryBean配置的触发器关联MethodInvokingJobDetailFactoryBean配置的JobDetail： 123456789101112@Configurationpublic class QuartzConfig { @Bean public SimpleTriggerFactoryBean simpleTriggerFactoryBean() { SimpleTriggerFactoryBean bean = new SimpleTriggerFactoryBean(); bean.setRepeatCount(10); bean.setRepeatInterval(2000); // 关联JobDetailbean.setJobDetail(methodInvokingJobDetailFactoryBean().getObject()); return bean; }} SimpleTriggerFactoryBean的用法比较简单 再用CronTriggerFactoryBean配置的触发器关联JobDetailFactoryBean配置的JobDetail： 1234567891011@Configurationpublic class QuartzConfig { @Bean public CronTriggerFactoryBean cronTriggerFactoryBean() { CronTriggerFactoryBean bean = new CronTriggerFactoryBean(); bean.setCronExpression(&quot;0/2 * * * * ? 2020&quot;); // 关联JobDetail bean.setJobDetail(jobDetailFactoryBean().getObject()); return bean; }} CronTriggerFactoryBean可以实现类似Spring中@Scheduled的cron表达式的功能，同时支持了年份的配置。 4、配置Scheduler最后一步就是通过SchedulerFactoryBean来配置Scheduler，来注册Trigger 12345678910@Configurationpublic class QuartzConfig { @Bean public SchedulerFactoryBean schedulerFactoryBean() { SchedulerFactoryBean bean = new SchedulerFactoryBean(); // 注册两个Trigger bean.setTriggers(simpleTriggerFactoryBean().getObject(), cronTriggerFactoryBean().getObject()); return bean; }} Quartz会使用异步线程去执行定时任务，不会出现像@Scheduled中定时任务在同一线程同步执行的情况。 到这里Spring Boot集成Quartz整个流程就完成了，运行项目就可以看到定时任务按照预期的效果执行。","link":"/2021/08/17/%E5%AE%9A%E6%97%B6%E4%BB%BB%E5%8A%A1/"},{"title":"数据流图","text":"数据流图帮助我们在开发的时候理思路 它是结构化开发方法的重要工具 0、快捷面板： 1、什么是数据流图 数据流图也称数据流程图（Data Flow Diagram，DFD)，它是一种便于用户理解、分析系统数据流程的图形工具。 摆脱了系统的物理内容，精确地在逻辑上描述系统的功能、输入、输出和数据存储等，是系统逻辑模型的重要组成部分。 数据流图是结构化开发的重要工具 2、基本图形元素 3、数据流图的分层 顶层图：将整个系统浓缩为一个节点，清晰的展现了系统与外界的交互，但看不出来这个系统的模块以及模块之间的数据交换 子图：细分了模块之间、节点之间的数据流转 数据流图平衡原则： 父图与子图之间的平衡：父图与外部的数据交换，在子图中有且必须有 子图内平衡：加工元素既有输入也有输出 4、例子：我们直接来看看软件设计师的题目吧（2019年下） 某公司欲开发一款二手车物流系统，以有效提升物流成交效率。该系统的主要功能是:(1)订单管理:系统抓取线索，将车辆交易系统的交易信息抓取为线索。帮买顾问看到有买车线索后，会打电话询问买家是否需要物流，若需要，帮买顾问就将这个线索发起为订单并在系统中存储，然后系统帮助买家寻找物流商进行承运。⑵路线管理:帮买顾问对物流商的路线进行管理，存储的路线信息包括路线类型、物流商、起止地点。路线分为三种，即固定路线、包车路线、竞拍体系，其中固定路线和包车路线是合约制。包车路线的发车时间由公司自行管理，是订单的首选途径。(3)合约管理:帮买顾问根据公司与物流商确定的合约，对合约内容进行设置，合约信息包括物流商信息、路线起止城市、价格、有效期等。(4)寻找物流商:系统根据订单的类型(保卖车、全国购和普通二手车)、起止城市，需要的服务模式(买家接、送到买家等)进行自动派发或以竞拍体系方式选择合适的物流商。即:有新订单时，若为保卖车或全国购，则直接分配到竞拍体系中:否则，若符合固定路线和/或包车路线，系统自动分配给合约物流商，若不符合固定路线和包车路线，系统将订单信息分配到竞拍体系中。竞拍体系接收到订单后，将订单信息推送给有相关路线的物流商，物流商对订单进行竞拍出价，最优报价的物流商中标。最后，给承运的物流商发送物流消息，更新订单的物流信息，给车辆交易系统发送物流信息。 (5)物流商注册:物流商账号的注册开通。现采用结构化方法对二手车物流系统进行分析与设计，获得如图1-1所示的上下文数据流图和图1-2所示的0层数据流图。 问题:1.1(3分)使用说明中的词语，给出图1-1中的实体E1~E3的名称。 问题:1.2(5分)使用说明中的词语，给出图1-2中的数据存储D1~D5的名称。 问题:1.3(4分)根据说明和图中术语，补充图1-2中缺失的数据流及其起点和终点。 答案： 123456789E1:帮买顾可;E2:车辆交易系统;E3:物流商。本题属于常规题型，补充数据流图中的实体名，实体一般为人员、组织机构、第三方系统等。根据题干描述，“帮买顾问看到有买车线索后，...&quot;可知接收交易线索的E1对应实体应该是帮买顾问;根据题干描述“将车辆交易系统的交易信息抓取为线索”&quot;可知提供车辆交易信息的E2对应实体应该是车辆交易信息;根据题干描述“物流商注册:物流商账号的注册开通。&quot;可知提供物流商注册信息的E3对应实体应该是物流商。D1:线索信息表/线索信息存储;D2:订单信息表/订单信息存储;D3:路线信息表/路线信息存储;D4:合约信息表/合约信息存储;D5:物流商信息表。本题属于常规题型，补充数据流图中的数据存储名，一般对应**库、**表、**档案等。根据题干描述和图示P1抓取线索后交易线索数据流入并且有线索数据流出的数据存储，应该是线索存储，即D1为线索信息表（线索信息存储等)。根据题干描述“帮买顾问将这个线索发起为订单并在系统中存储&quot;和图示P2发起订单，新订单数据流入的数据存储D2，应该是订单信息表。根据题干描述和图示P3路线管理，有路线数据流入的数据存储D3应该是路线信息表。根据题干描述和图示P4合约管理，有合约数据流入的数据存储D4应该是合约信息表。根据题干描述和图示P5、P6，有新物流商数据流入、物流商信息数据流出的数据存储D5，应该是物流商信息表。 123本题属于常规题型，补充缺失的数据流及其起点和终点。1、根据父图-子图平衡原则，父图存在E2-&gt;二手车物流系统的物流信息数据流，子图不存在，又根据题干描述:寻找物流商: ...，给车辆交易系统发送物流信息，所以图1-2缺失数据流p5-&gt;E2，物流信息。2、根据题干描述“系统根据订单的类型(保卖车、全国购和普通二手车)、起止城市、...选择合适的物流商”，P5寻找物流商缺失订单信息流入。3、根据题干描述“若符合固定路线和/或包车路线，系统自动分配给合约物流商，若不符合...&quot;，P5寻找物流商需要依据固定路线和/或包车路线，还需要根据合约的有效期等信息判断是否可以分配，所以需要补充数据流路线信息:D3-&gt;P5，合约信息:D4-&gt;P5。","link":"/2021/08/18/%E6%95%B0%E6%8D%AE%E6%B5%81%E5%9B%BE/"},{"title":"欢迎来到Mr.Symbolのblog!","text":"欢迎来到Mr.Symbolのblog!&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;这是Mr.Symbol的第一篇博客，欢迎你成为我的读者！&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;先做个自我介绍吧，现在Mr.Symbol还仅仅是一位处于颓废大学生活的大二学生，技术还只处于入门阶段，如果你希望在这里看到一些技术上的干货呢，可能还要等上好一阵子，所以在这里要说上声抱歉。但是，如果你也一位刚入门或者还未入门的IT技术爱好者，我希望我的捣鼓经历与好资料分享会对你有所帮助。以上。","link":"/2020/11/15/%E6%AC%A2%E8%BF%8E%E6%9D%A5%E5%88%B0Mr-Symbol%E3%81%AEblog/"},{"title":"深度学习","text":"神经网络各种参数的设置随机梯度下降SGD对一个batch或minibatch求出平均值后调整参数。 激活函数Sigmod，tanh，Relu，leakyRelu 上述函数求导都简单，到数值与原函数数值上相关。 做均值和方差归一化newx=（X - mean（X））/std(X) 做均值和方差归一化的好处在于使得输出的值在每一个维度上对后面的贡献都相同 （W，b）的初始化batch normalization为避免梯度消失现象，我们直接把每一层的值基于均值和方差做归一化 每一层FC层接一个BN层 注意： batch normalization是对一批样本的同一纬度特征做归一化。 layer normalization是对单个样本的所有维度特征做归一化。 目标函数的选择如果是分类问题可以采用softmax和交叉熵 softmax softmax（qi）=exp(zi)/求和1到n exp(zj) $softmax(q_i)=\\frac{exp(z_i)}{\\sum_{j=1}^{n}exp(z_j)}$ 输出的求和一定等于1 mean score error （MSE）： ​ $E=\\frac{1}{2}||q-p||^2$ 交叉熵: ​ $E=-\\sum_{i=1}^{N}p_ilog(q_i)$ 信息论中可证明如如果所得的p加起来为1，所有的q加起来为1，则E一定是一个大于0的值 p和q如果越相近，则E会更大 参数更新的策略SGD的问题： （w,b）的每一个分量获得的梯度绝对值有大小，会使得优化路径成为z字形 SGD求梯度的策略过于随机由于上次和下一次使用完全不同的batch数据，将会出现优化的方向随机的情况 解决的方法： AdaGrad RMSproop Momentum（角动量）：解决梯度随机性的问题 Adam：综合了上述三个方法。 自动编码器该算法被认为是开启深度学习的论文。 基本思想如下： 首先训练一层&lt;X,X&gt;的网络层，采用BP算法。而后，便固定住第一层的W对后面层进行训练旨在，使得第一层的W能够很好的获得原来X的信息，起到一个好的压缩效果。 训练第二层。固定前面的层，&lt;X_layer2,X_layer2&gt;进行如下训练。一直到训练完所有的层。 最后解冻所有层，对输入和目标之间进行BP微调。 卷积神经网络卷积神经网络，一句话概括： 由手工设计卷积核编程自动学习卷积核。 手工变换，如：傅里叶变换，小波变换，离散余弦变换…. Gabor Transform常见的卷积核，属于小波变换。 神经网络卷积： 特征图多大？ 图像大小：(M,N) 卷积核大小: (m,n） Stride : (u,v) 特征图大小：(K,L) 答： 宽上：m+(K-1)u&lt;=M，所以K&lt;=(M-m)/u+1 高上同理 32*32图像用5*5卷积，stride=1 ，特征图为28 补零Padding 卷积神经网络共享权重的特点： AlexNet的几个改进： ReLU激活函数 max pooling（vs avg pooling） dropout（随机丢弃） 增加训练样本，数据增强（水平翻转、随机截取部分、引入一定噪声） GPU加速训练过程 Transfer Learning（迁移学习） 把一个domain的经验迁移到另一个Domain中去","link":"/2023/11/02/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"},{"title":"理解数据库事务","text":"理解数据库事务：ACID、隔离级别、数据库并发问题、并发问题的解决（锁）、MVCC 一、ACID：事务的四大特性 数据库事务的设计目标是：让一组操作，要么全部成功，要么全部失败，保证数据的一致性与可靠性。 1. 原子性（Atomicity） 事务中的所有操作应该被看作不可分割的一组指令，任何一个指令不能独立存在，要么全部成功执行，要么全部不发生（也就是回滚） 原子性并不意味着中间操作无法失败，而是：失败后必须整体回滚，不留下脏数据。程序员也可以主动调用 rollback() 实现业务层回滚。 举例：用户下单后扣库存失败，整个下单过程需要撤销。 2. 一致性（Consistency） 一致性是指事务是否产生非预期中间状态或结果。如脏读、不可重复度等，出现了非预期的中间状态。 一致性实际上是由后面的隔离性去进一步保证的，隔离性达到要求，则可以满足一致性。也就是说，隔离不足会导致事务不满足一致性要求，所以务必理解各个隔离级别，才能少写Bug。 3. 隔离性（Isolation） 隔离性就是多个事务互不影响，感觉不到对方存在，这个特性就是为了做并发控制。 不同隔离级别对应不同的并发场景，隔离性越高，性能越低。最理想的效果是可串行化，目前采用两阶段加锁的方式，但是效率非常低。 有时候为了效率，原则是可以妥协的，于是隔离性并不严格，它被分为了多种级别，从高到低分别为： ⬇️可串行化（Serializable） ⬇️可重复读（Read Repeatable） ⬇️已提交读（Read Committed） ⬇️未提交读（Read Uncommitted） 举例：两个用户同时抢购商品，不应互相看到对方的中间状态。 4. 持久性（Durability） ✅ 一旦事务提交，修改就会永久保存，即使宕机也不会丢失。 ⚙️ 依赖数据库的日志机制（如 redo log）。 举例：下单成功后即使断电，订单数据仍然保留。 二、事务隔离级别详解 隔离级别 脏读 不可重复读 幻读 未提交读（Read Uncommitted，RU） ✅ ✅ ✅ 已提交读（Read Committed，RC） ❌ ✅ ✅ 可重复读（Read Repeatable，RR） ❌ ❌ ✅（用间隙锁防） 可串行化（Serializable） ❌ ❌ ❌ 三、并发问题1. 脏读（Dirty Read） 一个事务读到了另一个未提交事务的数据。 123456789101112-- 事务 BBEGIN;UPDATE account SET balance = balance - 100 WHERE id = 1;-- 事务 A（此时读取了事务 B 尚未提交的数据）BEGIN;SELECT balance FROM account WHERE id = 1; -- 读取到了 -100 的余额-- 事务 B 回滚ROLLBACK;-- 事务 A 的读取结果是脏的，不存在的数据 2. 脏写（Dirty Write） 两个未提交的事务修改了同一行数据，后提交的会覆盖前者。 12345678910111213-- 事务 ABEGIN;UPDATE account SET balance = 200 WHERE id = 1;-- 事务 B（在 A 未提交时也修改同一数据）BEGIN;UPDATE account SET balance = 300 WHERE id = 1;-- 事务 A 提交（balance = 200）COMMIT;-- 事务 B 提交（balance = 300，A 的修改被“擦除”）COMMIT; 💡 数据库通常通过加 排他锁 防止这种情况发生。 3. 不可重复读（Non-Repeatable Read） 同一事务两次读同一条数据，结果不同。 123456789101112-- 事务 ABEGIN;SELECT price FROM product WHERE id = 1; -- 结果：100-- 事务 BBEGIN;UPDATE product SET price = 200 WHERE id = 1;COMMIT;-- 事务 A 再次读取SELECT price FROM product WHERE id = 1; -- 结果：200（变了！）COMMIT; 4. 幻读（Phantom Read） 两次相同条件的范围查询，结果条数不同。 相比不可重复读来说，不是具体某条记录的内容，而是范围性的，如记录个数等。 123456789101112-- 事务 ABEGIN;SELECT * FROM user WHERE age &gt; 20; -- 返回：3 条记录-- 事务 B 插入符合条件的数据BEGIN;INSERT INTO user(name, age) VALUES('Tom', 25);COMMIT;-- 事务 A 再次查询SELECT * FROM user WHERE age &gt; 20; -- 返回：4 条记录（幻读）COMMIT; 💡 RR 隔离级别通过间隙锁可以防止这种插入。 5. 读偏差（Read Skew） 读偏差（Read Skew）是一种事务并发异常，指的是在一个事务中读取多个相关数据时，部分数据已被其他事务修改并提交，导致读出的整体状态不一致，违反了业务逻辑上的一致性。 12345678910111213141516-- 初始状态：账户 A = 50, 账户 B = 50，总和应为 100-- 事务 ABEGIN;SELECT balance FROM account WHERE name = 'A'; -- 50-- 事务 B：把 A 的余额转给 BBEGIN;UPDATE account SET balance = balance - 50 WHERE name = 'A';UPDATE account SET balance = balance + 50 WHERE name = 'B';COMMIT;-- 事务 A 继续读SELECT balance FROM account WHERE name = 'B'; -- 100-- A 读到的总额为：50 + 100 = 150（读偏差） 6. 写偏差（Write Skew） 写偏差（Write Skew），又称写前提困境，是指事务在提交前所依赖的“读前提”在并发场景中被其他事务改变，但自己却“蒙在鼓里”仍然提交了基于旧前提的写入，最终导致了业务一致性破坏。 📌 特点： 写偏差通常发生在：读取前提和写入目标不是同一条记录 数据库本身不会检测到冲突，只有业务逻辑才知道出错了 📋 场景背景： 用户有会员等级（如 1~3 级），3 级享受 3 倍积分加成 会员降级条件：积分 &lt; 3000，每日定时任务会检查并降级 积分与等级不是同一字段，不存在主键/唯一约束冲突 123456789101112【事务 A：消费刷卡，计算积分】1. 查询会员等级 = 3（此时积分为 2800，刚好不满足等级条件）2. 根据 3 倍积分计算，加了 90 分（原价 30 * 3）【事务 B：定时任务，执行降级】1. 查询积分 &lt; 3000，满足降级条件2. 将会员等级从 3 → 2，更新数据库3. COMMIT ✅【事务 A 接着执行】3. 没意识到等级已降，仍用等级=3 的老数据计算4. 更新积分 +90，提交 ✅ 7. 丢失更新（Lost Update） 丢失更新：多个事务基于相同的旧数据进行修改，导致后提交的事务覆盖了前者的结果，前者的修改“丢失”了。 12345678910111213141516171819-- 初始值：余额 100-- 事务 ABEGIN;SELECT balance FROM account WHERE id = 1; -- 读取 100-- A 计算：balance + 10 = 110-- 事务 BBEGIN;SELECT balance FROM account WHERE id = 1; -- 读取 100-- B 计算：balance + 20 = 120UPDATE account SET balance = 120 WHERE id = 1;COMMIT;-- 事务 A 写入UPDATE account SET balance = 110 WHERE id = 1;COMMIT;-- 结果：最终余额为 110（B 的修改被 A 覆盖，更新丢失） 8. 并发问题总结 编号 并发问题 定义 典型特征 可能后果 解决方式 ① 脏读 Dirty Read 读到未提交事务的数据 读到了可能会回滚的数据 读到不真实、无效数据 设置隔离级别 ≥ RC ② 脏写 Dirty Write 两个未提交事务修改同一数据 后提交者擦除前者写入 数据被不正确覆盖 数据库默认禁用；加排它锁 ③ 不可重复读 Non-Repeatable Read 同一事务两次读同一条记录，结果不同 同一记录值发生变化 逻辑判断出错、缓存失效 设置隔离级别 ≥ RR（MVCC） ④ 幻读 Phantom Read 两次范围查询，结果记录数不同 记录条数变化 插入了意料之外的行 RR + 间隙锁（Gap Lock） or Serializable ⑤ 读偏差 Read Skew 跨多条记录读到不一致状态 总和、组合值异常 违反业务一致性（如转账总额不对） Serializable or 显式加锁 ⑥ 写偏差 Write Skew 基于旧的读前提，写入已不成立的修改 各自写不同字段，看似不冲突实则冲突 破坏业务规则，如“两人不能同时上岗” Serializable / 显式加锁 / 前提校验 ⑦ 丢失更新 Lost Update 并发事务读同一值修改并提交，后者覆盖前者 前者结果丢失 结果不正确（如充值金额少了） 乐观锁、悲观锁、自增操作、CAS 1-4是由于对单条数据的并发问题，5-7是多个数据业务相互依赖，从业务逻辑上导致的并发问题。 四、基于锁的隔离级别实现1、为什么需要锁？在数据库事务中，我们期望多条 SQL 组成一个“原子操作”，在并发环境下也能保持一致性和可靠性。然而，多个事务同时操作数据库会带来各种并发问题，比如： 脏读、脏写 不可重复读 幻读、写偏差、丢失更新 为了解决这些问题，我们需要一种机制来控制并发访问 —— 锁。 2、基础锁类型（1）共享锁（S锁，Share Lock） 只允许读，不允许写。 多个事务可以同时持有同一条记录的共享锁。 适用于 SELECT 等读操作。 （2）排它锁（X锁，Exclusive Lock） 允许读 + 写。 一条记录只能被一个事务持有排它锁。 适用于 UPDATE、DELETE 等写操作。 （3）锁兼容关系： 当前锁 S锁 X锁 S锁 ✅ ❌ X锁 ❌ ❌ 3、两阶段加锁协议（2PL）为了实现严格的串行化，需要事务按照以下规则来加锁和解锁： 📌 1. 基本两阶段加锁（2PL） 加锁阶段：事务可以随意加锁，不能解锁。 解锁阶段：开始解锁后，不能再加锁。 📌 2. 严格两阶段加锁（Strict 2PL） 只有在事务提交或回滚时，才释放所有锁。 ✅ 这样可以确保：只要某事务读取或写入了一条记录，其它事务就必须等待它提交或回滚后才能操作该记录，由此实现了可串行化。 4、多粒度锁 &amp; 意向锁（Intention Lock）✅ 多粒度锁？ 表锁：锁住整张表（影响大） 行锁：只锁一条记录（更细粒度，影响小） 问题： 当一个事务要加表级锁时，如何判断是否安全？即这张表中有没有其它事务已经对某些行加锁？ 传统方式： 遍历所有行锁 —— 💣 性能开销大 ✅ 意向锁的作用 💡 意向锁 = 告诉别人“我准备加行锁了”。相当于表级标记。 功能 描述 提示意图 提前在表级“打标记”，告知系统下层将加行锁 冲突判断 表锁申请前，仅判断表级意向锁是否冲突，无需遍历所有行锁 意向锁： 意向共享锁（Intention Shared，IS），表示将要对某些记录加 共享锁（读）。 意向排他锁（Intention Exclusive，IX），表示将要对某些记录加排他锁（写）。 ✅ 加锁顺序与兼容 加行锁之前 ， 先加对应的意向锁： 加IS 表锁 ➜ 加 S 行锁 意向锁锁兼容性：意向锁间是相互容的，与X、S同X、S关系一致。 例子： 事务 操作 A 想对某行加行级 X 锁 → 表上先加 IX 锁 B 想对整张表加表级 X 锁 → 发现表上已有 IX 锁 → 冲突，需等待 5、解决幻读：间隙锁 &amp; Next-Key Lock幻读场景：12345-- 事务 ASELECT * FROM student WHERE age = 18;-- 事务 BINSERT INTO student(name, age) VALUES('Tom', 18); 再次查询时，A发现多了一条记录“Tom”，即发生幻读。 1. 间隙锁（Gap Lock） 锁住两条记录之间的间隙，阻止插入。 不锁记录本身，只防止“新的记录”插入指定范围。 2. Next-Key Lock 是记录锁 + 间隙锁的组合，锁定一个前开后闭区间 (a, b]。 防止插入 + 防止更新，效果更强。 InnoDB 使用 Next-Key Lock，实质上Next-Key Lock目的仅为减少锁表存储空间。 6、并发问题的锁解决方案基于严格两阶段锁，读前共享锁，写前排他所，可以解决所有并发问题，属于InnoDB中的串行化级别。 1-3易理解，4幻读采用间隙锁解决，5-7，因为读前共享锁、写前排他锁，防止了陈旧数据的出现，因此避免了问题。 五、MVCC1、引入MVCC的动机基于严格二阶段加锁+XS锁的方式可实现串行化隔离级别。但现实中，某些业务读多写少，传统的锁方案并发效率低。 为了提升 读性能，并且在不牺牲一致性的前提下避免加锁带来的性能问题，数据库引入了 MVCC（Multi-Version Concurrency Control，多版本并发控制）： 在不加锁的前提下，让读取操作能看到一个一致的数据快照，避免读阻塞写，写也不阻塞读。 2、MVCC 的底层机制MVCC 的实现依赖两个核心结构：版本链（Undo Log）、快照视图（Read View）。 1. 版本链（Undo Log）每次对记录的更新（UPDATE / DELETE），都不会直接覆盖数据，而是把老版本保存在 Undo Log 中，并通过一个链条结构串联起来。 📌 每条记录都多了两个隐藏字段： 字段名 含义 trx_id 创建该版本的事务 ID roll_pointer 指向上一个版本的指针（版本链） 假设我们对一条记录 id=1 更新了两次： 12345678最新版本（当前行）[id=1, name='Tom', trx_id=15, roll_pointer] ---&gt;旧版本（第一次更新前）[id=1, name='Jack', trx_id=11, roll_pointer] ---&gt;最旧版本（插入时）[id=1, name='John', trx_id=9, roll_pointer] ---&gt; null 每次更新只在当前行上覆盖 name 和 trx_id，旧数据被保存到 undo log 中，通过 roll_pointer 串成链。 2.Read View（快照视图）Read View 并不是数据的完整快照，而是一组判断版本可见性的规则，记录了事务视图的一致性边界。 📌 它在 事务执行第一条语句时生成（Repeatable Read），或 每条语句生成（Read Committed）。 Read View 包含以下信息： creator_trx_id：当前事务的 ID min_trx_id：Read View 生成时，系统中最小活跃事务 ID max_trx_id：Read View 生成时，系统中尚未分配的新事务 ID m_ids：当前活跃事务 ID 列表 3、版本可见性判断逻辑当事务读取记录时，会依据 Read View 来决定当前记录是否可见。逻辑如下： ✅ 如果 trx_id == creator_trx_id：是当前事务自己写的 → 可见 ✅ 如果 trx_id &lt; min_trx_id：比当前视图早创建 → 可见 ❌ 如果 trx_id &gt;= max_trx_id：是视图生成后开始的事务 → 不可见 ❓ 如果 trx_id 在 m_ids 中 → 还没提交 → 不可见 ✅ 不在 m_ids 中 → 已提交 → 可见 3、不同隔离级别下 Read View 行为 隔离级别 Read View 创建时机 行为差异说明 Read Committed 每次 SQL 执行时 每次读取最新已提交数据版本 Repeatable Read 第一次 SQL 执行时生成一次 后续所有读取使用相同视图，保证一致 默认情况下，InnoDB 的隔离级别是 Repeatable Read，所以同一事务中读到的数据是一致的旧快照，不会看到其他事务中途更新的内容。 4、局限性实现的是可重复读的隔离级别。因此，仅能避免脏读、脏写、不可重复读问题，无法避免幻读、读写偏差、丢失更新。","link":"/2025/04/09/%E7%90%86%E8%A7%A3%E6%95%B0%E6%8D%AE%E5%BA%93%E4%BA%8B%E5%8A%A1/"},{"title":"生成式AI","text":"回归问题：通过一个函式，算出一个连续的数值。 分类问题：通过一个函式，算出一个类别。 结构性学习（Structured Learning），生成有结构的文件（如影响、文句），又称“生成式学习”（Generative Learning）。 chatGPT把生成式学习问题简化，拆成了多个分类问题。 深度学习中 找函式的三个步骤： 设定范围：定出候选函式的集合。Model 设定标准Loss 达成目标：找出最好的函式。Gradient Descent（Adam等） 常见的结构性文件: 生成结构的额策略： 策略一：各个击破 ​ 文字一个一个预测，图像4x4像素逐一生成。 策略二：一次到位 ​ 例如：每次固定生成固定时间长的文字。 策略三：混合模式 ​ 以语音生成为例，先通过文字每秒生成100个向量作为大方向，在通过这100个向量做一次到位，生成对应的语音。 ​ 或者以图像为例，一次生成一个较为模糊的图像，在一次一次是的图像颜色更丰富，更清晰。","link":"/2023/11/16/%E7%94%9F%E6%88%90%E5%BC%8FAI/"},{"title":"编译与链接","text":"本文介绍了c语言的编译、链接、动态链接、PIC地址无关代码、PLT延迟绑定、以及一些gcc指令与ELF分析指令。 1、编译c语言中，编译是将.c文件(文本文件)编译为机器指令。 我们将以如下add.c和main.c进行分析： add.c 1234int add(int a,int b){ return a+b;} main.c 123456789101112#include&lt;stdio.h&gt;int add(int a,int b);int main(){ int a=2,b=3; printf(&quot;satrt!\\n&quot;); a=add(a,b); printf(&quot;a+b:%d\\n&quot;,a); return 0;} 我们将这两个文件仅编译,目标文件为对应.o文件： 123456root@VM-4-3-ubuntu:~/c# gcc -c main.croot@VM-4-3-ubuntu:~/c# gcc -c add.croot@VM-4-3-ubuntu:~/c# ls *.oadd.o main.oroot@VM-4-3-ubuntu:~/c# file add.oadd.o: ELF 64-bit LSB relocatable, x86-64, version 1 (SYSV), not stripped 我们可以通过 查看main.o二进制的反汇编结果： 1root@VM-4-3-ubuntu:~/c# objdump -S main.o main.o: file format elf64-x86-64 Disassembly of section .text: 0000000000000000&lt;main&gt;: 0: f3 0f 1e fa endbr64 4: 55 push %rbp 5: 48 89 e5 mov %rsp,%rbp 8: 48 83 ec 10 sub $0x10,%rsp c: c7 45 f8 02 00 00 00 movl $0x2,-0x8(%rbp) 13: c7 45 fc 03 00 00 00 movl $0x3,-0x4(%rbp) 1a: 48 8d 3d 00 00 00 00 lea 0x0(%rip),%rdi # 21 21: e8 00 00 00 00 callq 26 26: 8b 55 fc mov -0x4(%rbp),%edx 29: 8b 45 f8 mov -0x8(%rbp),%eax 2c: 89 d6 mov %edx,%esi 2e: 89 c7 mov %eax,%edi 30: e8 00 00 00 00 callq 35 35: 89 45 f8 mov %eax,-0x8(%rbp) 38: 8b 45 f8 mov -0x8(%rbp),%eax 3b: 89 c6 mov %eax,%esi 3d: 48 8d 3d 00 00 00 00 lea 0x0(%rip),%rdi # 44 44: b8 00 00 00 00 mov $0x0,%eax 49: e8 00 00 00 00 callq 4e 4e: b8 00 00 00 00 mov $0x0,%eax 53: c9 leaveq 54: c3 retq 这便是编译 以下是执行文件的一些信息查看 通过readelf -h，我们可以找到可执行文件的头部进本信息，结果如下： 以及readelf -s 查看区块（selection）信息 2、链接（静态）事实上，链接就是将编译生成的目标文件，连同静态库、动态库，组合拼装成一个独立的可执行文件。 链接的过程其中包括，一些地址的修正。链接器需要根据重定位表，找到那些需要被重定位的函数、全局变量，从而修正他们的地址（重定位）。 我们在main.o 的机器指令中看 12321: e8 00 00 00 00 callq 26 30: e8 00 00 00 00 callq 3549: e8 00 00 00 00 callq 4e 这三条指令是printf和add函数的调用。因为add和printf分别是在add.o和库函数中定义，在main.c中仅有声明，为此这里的指向地址为00 00 00 00空。这里的函数地址会在链接的时候被修正。 另外，为了让链接器可以找到这些需要被修正的地址。在代码块中，存有重定位表（Relocation Table）指向需要被修改地址。 我们可以通过objdump -r main.o 查看，结果如下： 123456789101112131415root@VM-4-3-ubuntu:~/c# objdump -r main.omain.o: file format elf64-x86-64RELOCATION RECORDS FOR [.text]:OFFSET TYPE VALUE 000000000000001d R_X86_64_PC32 .rodata-0x00000000000000040000000000000022 R_X86_64_PLT32 puts-0x00000000000000040000000000000031 R_X86_64_PLT32 add-0x00000000000000040000000000000040 R_X86_64_PC32 .rodata+0x0000000000000003000000000000004a R_X86_64_PLT32 printf-0x0000000000000004RELOCATION RECORDS FOR [.eh_frame]:OFFSET TYPE VALUE 0000000000000020 R_X86_64_PC32 .text 其中22、31、4a的偏移量分别与main.o中三个调用对应。 我们如下编译：gcc main.o add.o -o main。在目录下我们可以找到生成的可执行文件main。 main可以直接运行，结果如下： 123root@VM-4-3-ubuntu:~/c# ./main satrt! a+b:5 3、动态链接静态链接会将编译产生的所有目标文件、连同用到所有库合并成独立的可执行文件。他不需要依赖任何其他的文件，便可独立运行。 但静态链接最大的问题在于生成的文件体积大，耗费内存资源。比如，libc.so是我们c语言程序基本都会用到的运行时库，大约在2M左右，如果计算机上有大量的进程，那都需要将这2M的代码放进内存，重复冗余。 动态链接，将共享的代码单独提取出来，保存成一个独立的动态运行库。等到程序运行时再把它加载到内存，这样可以节省内存空间。因为，同一模块在内存中只需要保存一份副本，可以被不同的进程共享。 1、基本动态库的创建和使用我们的上述main 可执行文件中，使用了printf函数，该函数便在libc的动态库中。我们通过readelf -d main 指令，结果如下： 12root@VM-4-3-ubuntu:~/c# readelf -d main | grep NEEDED0x0000000000000001 (NEEDED) Shared library: [libc.so.6] 接下来，我们改造我们的add.o,将其编译为动态链接库。 12gcc -shared -fPIC add.c -o libadd.sogcc main.c -ladd -L. -o main1 -shared是指Shared Object（共享对象）。-fPIC -ladd指定了所需动态链接的库，省略了libadd.so 的lib和.so。-L.指定了动态链接库所在的目录。 当我们执行./main1的时候，有如下错误： 12root@VM-4-3-ubuntu:~/c# ./main1./main1: error while loading shared libraries: libadd.so: cannot open shared object file: No such file or directory 这是因为Linux默认只会在系统路径/usr/local/lib下搜索动态库。有如下解决方案： 将我们的动态库libadd.so拷贝到/usr/local/lib路径下 将当前路径添加到LD_LIBRARY_PATH中。这样系统会现在指定的路径下搜索，找不到在去系统路径搜索。 123export LD_LIBRARY_PATH=&quot;$(pwd)&quot;echo $LD_LIBRARY_PATH./main1 以上，我们我们说清了一个基本动态库的创建和使用。 2、PIC技术静态链接将编译所产生的目标文件、所用到库合并成一整个可执行文件。动态链接，将共同的代码提取出来，作为共享代码段。在程序载入内存时，将相应的动态库（共享代码）加载到内存中，并可被多个进程所应用，即该部分代码在内存中仅有一份副本。 但是仍有一个问题需被解决，共享代码的重定向问题。 静态编译的过程中，我们将不同的模块整合到一块，并且修改相互调用（函数、全局变量）的地址，这便是重定位。 然而，如果动态连接时，我们继续在共享代码载入时对代码进行重定位（修改代码段中的跳转地址），这便会出现一些问题。并且，一般共享代码代码段都仅为只读。 为此PIC（Postion Independent Code，地址无关代码）给出了一个解决方案。 对于模块内部的代码、数据的调用，由于位置固定，所以采用相对寻址。 对于代码外部的跨模块调用，采用间接寻址，在数据段创建了GOT表（Global Offset Table），GOT表的条目保存了正确的指向地址。 这样共享代码段就不必被修改了。 在Linux2.x以后，每个进程都有独立的进程空间，具有进程内存空间独立性。为此，全局偏移表（GOT）在每个进程中都有一个副本，这是因为每个进程都可能包含不同的内存映射和地址空间，而全局偏移表中存储的地址需要根据当前进程的内存布局和加载地址来进行调整。GOT表很小，开销是可以接收到。 如下指令，可以看到.got 区块。 1readelf -S libadd.so 3、PLT（过程链接表、延迟绑定）由于程序加载的时候需要对大量的函数进行重定位，这将会耗费大量的时间。 PLT（Procedure Linkage Table，过程链接表），PLT 实际上是一组代码段，其中包含一系列桩（Stub）代码，这些桩代码负责在程序运行时进行动态链接和重定位。 PLC机制将程序载入时对函数的地址的绑定，推迟到程序第一次调用该动态库，因为绝大多数函数在程序的运行期间并不会被使用。 它的大致思路如下： got全局偏移表每个表项都指向一段桩程序，当该函数第一次被调用的时候，该桩程序代码会查询真正函数的跳转地址，并且更新GOT表。当函数再次被调用的时候，便正确指向了函数的真实地址。 相关指令1、gcc指令gcc 是 GNU 编译器集合中的一个，用于编译 C、C++、Objective-C 和其他相关语言的程序。它实际上会根据源文件的类型自动调用相应的编译器。 基本的 gcc 指令的格式如下： 1gcc [options] source_files -o output_file [options] 是编译器的选项，用于指定编译的参数、标志和特定行为。 source_files 是要编译的源文件列表，可以是一个或多个源文件。 常用选项： -o output_file 用于指定生成的可执行文件或目标文件的名称。 -c：只编译源文件，生成目标文件。（不链接） -g：生成调试信息。 -O：开启优化。 -l&lt;library&gt;：链接特定的库文件。 -I&lt;include_path&gt;：指定头文件搜索路径。 -L&lt;library_path&gt;：指定库文件搜索路径。 示例： 1gcc -Wall -o hello hello.c 这个命令编译名为 hello.c 的源文件，生成一个可执行文件 hello。-Wall 是一个编译器选项，表示开启所有警告信息。 2、objdump指令objdump 是一个用于显示目标文件或可执行文件内容的命令行工具。 objdump 是一个强大的工具，用于分析 ELF 格式文件，可以提供文件头信息、节信息、符号表、反汇编代码等多种信息，有助于理解程序的结构和内部细节。 基本的 objdump 命令格式如下： 1objdump [options] file [options] 是 objdump 命令的选项，用于控制输出内容的格式和信息。 file 是要分析的 ELF 格式文件（目标文件、可执行文件等）的路径。 常用选项： -f：显示文件头信息（ELF 文件的基本信息）。 -h：显示节（Section）头表信息。 -S：显示反汇编代码。 -t：显示符号表信息。 -d：显示全部可执行指令的反汇编代码。 -r：显示重定位信息。 -x：以十六进制形式显示所有数据。 -l：显示线号信息。 示例： 1objdump -d a.out 查看a.out 的反汇编代码 3、readelf指令readelf 是一个命令行工具，用于显示 ELF（Executable and Linkable Format，可执行与可链接格式）文件的信息，包括文件头、节头表、符号表、重定位表等。 基本的 readelf 命令格式如下： 1readelf [options] file [options] 是 readelf 命令的选项，用于控制输出内容的格式和信息。 file 是要显示信息的 ELF 文件的路径。 常用选项： -h：显示 ELF 文件的文件头（ELF Header）信息。 -S：显示节头表（Section Headers）信息。 -s：显示符号表（Symbol Table）信息。 -r：显示重定位表（Relocation Entries）信息。 -d：显示动态段（Dynamic Sections）信息。 -x &lt;number or name&gt;：显示特定的节内容。 -p &lt;name&gt;：显示特定的节内容（字符串节）。 示例： 1readelf -h executable_file 这个命令将显示名为 executable_file 的可执行文件的 ELF 文件头信息。 1readelf -s object_file 这个命令将显示名为 object_file 的目标文件的符号表信息。 readelf 是一个强大的工具，用于分析和了解 ELF 格式的文件，提供文件的结构、节信息、符号表、重定位表等各种详细信息，对于调试、分析和了解文件非常有帮助。 4、hexdump指令hexdump 是一个用于查看文件内容的工具，可以将文件内容以十六进制和ASCII码的形式显示出来，有助于查看文件的二进制内容和结构。 基本的 hexdump 命令格式如下： 1hexdump [options] file [options] 是 hexdump 命令的选项，用于控制输出格式和显示的内容。 file 是要显示内容的文件路径。 常用选项： -C：以十六进制和ASCII码组合的形式显示。 -b：按字节（byte）显示，每个字节显示一个地址。 -c：按字符显示。 -n &lt;length&gt;：限制显示的字节数。 -s &lt;offset&gt;：从指定的偏移量开始显示。 示例： 1hexdump -C your_file 这个命令将以十六进制和ASCII码组合的形式显示 your_file 文件的内容。每一行显示16个字节的内容，前8列显示十六进制值，后8列显示对应的ASCII字符表示。","link":"/2023/12/07/%E7%BC%96%E8%AF%91%E4%B8%8E%E9%93%BE%E6%8E%A5/"},{"title":"目标识别RCNN和FCN","text":"RCNN 分割出一些目标的Region Proposal （候选区域），然后送入CNN网络进行识别。 Selective Search产生RP，送入CNN进行特征提取，最后对4096的向量进行SVM进行判断。 Selective Search：首先使用Efficient Graph-BasedIMage Segmentation算法对图像进行过分割，每个region非常小，以此为基础，对相邻的region进行相似度判断并融合，形成不同尺度下的region。 缺点：计算非常缓慢、做了许多重复的计算（尤其在卷积上） 1）Selective Search 计算量很大（约5秒一张照片） 2）有太多的CNN通路（约两千个RP） 3）test time（50s） 4）1024d features 训练SVM，花费了太多的空间 FRCNN Fast RCNN FRCNN，认为RCNN中多了许多重复的卷积操作，为此先通过几层的CNN网络，对不同大小结果区域上进行ROI Pooling，做了一个归一化，然后进行分类与回归。 Faster RCNN yolo、yolo9000 语义分割——全卷积网络（Fully Convolution Networks） 池化层的上采样 卷积层的上采样（反卷积或称反卷积） FCN一个例子：视频场景人数估计 生成热度图（heat map）","link":"/2023/11/14/%E7%9B%AE%E6%A0%87%E8%AF%86%E5%88%ABRCNN%E5%92%8CFCN/"},{"title":"hexo阿里云部署与图片路径问题","text":"自己服务器部署还是遇到了一些问题，首先感谢两篇被引用的博客 1、hexo博客部署阿里云服务器从零搭建Hexo博客并部署阿里云服务器（奶妈级教学） 以下是博客内容 一、关于云服务器的操作1.1、配置安全组规则由于阿里云是默认不授权80端口的访问的，所以我们要手动配置。 打开阿里云服务器管理控制台-&gt;点击左侧安全组-&gt;点击右侧的配置规则-&gt;点击添加安全组规则 如下图 这是个大坑，如果不设置就无法访问服务器，所以放在第一点说。 1.2、配置服务器路由安装并启动服务器后，我们就完成了第一步，现在我们可以尝试使用自己的电脑去访问服务器的公网IP。我们可以惊喜地发现，公网IP可以打开一个nginx的默认网页。这样，我们就成功了第一步。 但是我们实际上是想要让这个地址指向我们的博客，而不是nginx的默认网址，这就需要我们去配置nginx的配置文件。我在配置的时候在网上查到的关于nginx配置文件的有关资料，大部分关于centOS的资料都是说配置位于etc/nginx/conf.d/ 下的dafault.conf 这个配置文件，但是我在配置的时候并没有找到它，后来查看了一下文件结构，阿里云默认的库下载的是fedora版本的nginx，所以我们应该配置的是位于 etc/nginx/ 下的 nginx.conf 。 我们先不急着打开这个文件，因为我并不建议直接配置这个文件，我们应该先创建一个新的文件，然后采用include的方式，将这个文件包含进nginx.conf中。 操作如下：在/etc/nginx/目录下创建一个文件夹 叫 vhost 1234cd /etc/nginxmkdir vhostcd vhostvim blog.conf 编辑 blog.conf文件内容 1234567server{ listen 80; root /home/www/website;这里填博客目录存放的地址 server_name 这里填域名如(www.baidu.com) 如果暂时没有域名就填阿里云的公网ip，以后有了再改回来; location /{ }} 保存并退出:wq 打开/etc/nginx/目录下的nginx.conf文件vi /etc/nginx/nginx.conf 如果以后还想添加新的网站，也可以在vhost目录下新建一个conf配置文件。 在刚才我们自己写的blog.conf配置文件中root的路径相应路径建立博客的目录： 1234cd /homemkdir wwwcd /wwwmkdir website 这样我们就可以得到 /home/www/website 作为博客的根路径，就和配置文件中的路径对应上了。 1.3、安装Git以及Node.js1.3.1、安装Node.js安装nodejs有很多种方式，我这边就说一种 123装nodejs有很多种方式，我这边就说一种curl -sL https://rpm.nodesource.com/setup_10.x | bash -yum install -y nodejs 安装完成后执行 node -v 和 npm -v 如果打印版本号则安装成功 1234[root@localhost /]# node -vv10.9.0[root@localhost /]# npm -v6.2.0 1.3.2、安装Git及配置仓库这一部分主要目的是让我们个人的电脑可以通过ssh方式连接到云服务器，然后我们就可以通过命令行方式将我们的博客Po到服务器上。操作如下：安装git: yum install git配置git用户adduser git修改用户权限: 12chmod 740 /etc/sudoersvi /etc/sudoers 找到这个位置添加下面这句话git ALL=(ALL) ALL 保存退出后 将sudoers文件权限改回原样chmod 400 /etc/sudoers设置git用户的密码sudo passwd git切换到git用户，然后在~目录下创建.ssh文件夹 1234su gitcd ~mkdir .sshcd .ssh 生成公钥密钥文件(这一步很重要，也是我踩过的坑)ssh-keygen此时在目录下就会有两个文件，分别是id_rsa 和 id_rsa.pub 其中 id_rsa.pub 就是公钥文件 我们复制一份cp id_rsa.pub authorized_keys这样目录下就会有一个authorized_keys文件，它和id_rsa.pub一模一样。最后我们修改它的权限 12chmod 600 ~/.ssh/authorized_keyschmod 700 ~/.ssh 然后我们在自己的电脑上自己的电脑上自己的电脑上（重要的事说三遍），打开cmd，使用ssh方式连接我们的云服务器。 最后提示Welcome to Alibaba Cloud Elastic Compute Service !说明登录成功了。现在我们要创建一个git的仓库，并且新建一个post-receive文件，操作如下: 123cd ~git init --bare blog.gitvi ~/blog.git/hooks/post-receive 输入以下内容：git --work-tree=/home/www/website --git-dir=/home/git/blog.git checkout -f保存退出并授予该文件可执行权限 chmod +x ~/blog.git/hooks/post-receive至此我们就完成了所有关于服务器端的配置。 二、关于本地主机的操作2.1、安装Node.js下载地址：Node.js 安装过程基本直接 下一步 就可以了。安装完成后使用cmd查看是否安装成功 12node -vnpm -v 出现版本号说明安装成功 2.2、安装Hexo由于使用npm直接下载会有很多人遇到卡顿的问题(国外服务器)，所以我们要做的第一步工作是将npm换成淘宝的服务器。cmd输入下面的命令 123npm config set registry https://registry.npm.taobao.org# 然后安装cnpmnpm install -g cnpm --registry=https://registry.npm.taobao.org 接下来就直接安装 hexo 1cnpm install -g hexo-cli 然后我们选一个目录用来初始化博客程序例如G:/Blog cmd输入： 123G:cd Bloghexo init 执行成功后安装两个插件 12npm install hexo-deployer-git --savenpm install hexo-server 之后我们就可以在自己的本机上查看自己的博客了 12hexo ghexo s 打开浏览器访问 http://localhost:4000 2.3、配置_config.yml完成服务器的部署在刚才生成hexo的目录下，找到_config.yml，打开它。找到deploy 做如下配置 12345deploy:type: gitrepo: git@这里改为服务器公网IP:/home/git/blog.git branch: master message: 保存退出然后尝试写一篇文章并且发布到服务器上 12hexo new &quot;Hello My First Blog&quot;hexo clean &amp;&amp; hexo generate --deploy 在服务器上重新运行nginx服务器nginx -s reload 2、博客图片相对路径问题hexo 图片显示问题及使用typora设置图片路径 以下是博客内容 2.1、hexo图片相对路径问题使用hexo生成静态资源后,由于url的问题会出现图片加载的问题,现在网上的文章及官方的解决方案大概分为三种: 将图片放入source/images目录下,每次generate都会生成图片,在使用相对或绝对路径进行引用 配置hexo的_config.yml文件, 将 post_asset_folder 设置为true, 这样每次new 生成一个文章时都会同步生成一个同名的文件夹,然后设置相对或绝对路径. 使用hexo官方的解决方案,使用模版变量, 但是在配置过程中发现这三种方式都多多少少存在一些问题,前两中首页跟内容页会有一个加载失败的问题,而第三种则失去了markdown的意义. 解决方法: 1234设置post_asset_folder 为 true, 安装插件 asset-imagenpm install https://github.com/CodeFalling/hexo-asset-image设置图片为相对路径hexo clean &amp;&amp; hexo generate &amp;&amp; hexo s 运行查看 效果如下: 2.2、配置typora进行本地图片的粘贴及正常显示设置typora,图像 以后直接粘贴图片就可以自动保存到 hexo 配置的 post_asset_folder 文件夹里,自动渲染了 注意修改图片路径中的 \\ 为 / ,并且不带 .或者./ 直接写目录/图片","link":"/2021/08/14/%E9%98%BF%E9%87%8C%E4%BA%91%E9%83%A8%E7%BD%B2%E4%B8%8E%E5%9B%BE%E7%89%87%E8%B7%AF%E5%BE%84%E9%97%AE%E9%A2%98/"},{"title":"静态代理、动态代理与Spring AOP","text":"在现代 Java 开发中，代理模式的概念贯穿着无数项目和框架。而在 Spring 框架中，代理机制更是无处不在，支撑着AOP、事务管理等诸多核心特性。 那么，静态代理和动态代理到底有什么区别？Spring 中的 AOP又是如何结合代理技术实现的？ 一、静态代理 vs 动态代理代理模式（Proxy Pattern）是一种结构型设计模式，它为其他对象提供一种代理以控制对这个对象的访问。 简单来说，代理就是替别人办事。 1.1 静态代理静态代理是指在程序编译期间就确定了代理类，并且由开发者手动编写代理类。 特点 代理类和目标对象实现同一接口。 代理类在编译期间就写死了。 每个接口对应一个代理类，代码重复量大，维护麻烦。 示例12345678910111213141516171819202122232425262728293031323334353637// 接口public interface Service { void serve();}// 真实对象public class RealService implements Service { @Override public void serve() { System.out.println(&quot;真实服务&quot;); }}// 静态代理public class StaticProxy implements Service { private Service realService; public StaticProxy(Service realService) { this.realService = realService; } @Override public void serve() { System.out.println(&quot;代理前处理&quot;); realService.serve(); System.out.println(&quot;代理后处理&quot;); }}// 测试public class Test { public static void main(String[] args) { Service realService = new RealService(); Service proxy = new StaticProxy(realService); proxy.serve(); }} 总结：静态代理适合小规模使用，但在面对大量接口和频繁变动时非常繁琐。 1.2 动态代理动态代理则是在程序运行时由 JVM 动态创建代理对象，无需手动写代理类。 特点 只需要定义接口和目标类。 使用统一的 InvocationHandler 实现代理逻辑。 灵活，可扩展，维护成本低。 示例（JDK 动态代理）12345678910111213141516171819202122232425262728293031323334353637383940414243444546import java.lang.reflect.InvocationHandler;import java.lang.reflect.Method;import java.lang.reflect.Proxy;// 接口public interface Service { void serve();}// 真实对象public class RealService implements Service { @Override public void serve() { System.out.println(&quot;真实服务&quot;); }}// 动态代理处理器public class DynamicProxyHandler implements InvocationHandler { private Object target; public DynamicProxyHandler(Object target) { this.target = target; } @Override public Object invoke(Object proxy, Method method, Object[] args) throws Throwable { System.out.println(&quot;代理前处理&quot;); Object result = method.invoke(target, args); System.out.println(&quot;代理后处理&quot;); return result; }}// 测试public class Test { public static void main(String[] args) { Service realService = new RealService(); Service proxy = (Service) Proxy.newProxyInstance( realService.getClass().getClassLoader(), realService.getClass().getInterfaces(), new DynamicProxyHandler(realService) ); proxy.serve(); }} 仅对特定方法代理（示例） 1234567891011@Overridepublic Object invoke(Object proxy, Method method, Object[] args) throws Throwable { if (&quot;specialMethod&quot;.equals(method.getName())) { System.out.println(&quot;【代理】specialMethod前置处理&quot;); Object result = method.invoke(target, args); System.out.println(&quot;【代理】specialMethod后置处理&quot;); return result; } else { return method.invoke(target, args); }} 基于注解代理（示例） 1234if (method.isAnnotationPresent(NeedLog.class)) { System.out.println(&quot;【日志代理】需要记录日志&quot;); // 特殊处理} 总结：动态代理真正做到了灵活、低耦合、强扩展，是大型框架（如Spring）的基础设施之一。 1.3 对比静态代理虽然直观，但在实际开发中存在明显的问题： 重复劳动 每个接口都要单独写一个代理类。 代理类内部方法大部分逻辑是重复的（调用真实对象 + 增强处理）。 维护成本高 接口新增或修改方法，所有相关代理类都要同步修改。 很容易出现漏改、出错的情况。 缺乏灵活性 想给不同对象增加不同处理逻辑，静态代理要修改多处代码。 动态代理只需要在 InvocationHandler 统一判断即可。 二、Spring AOP2.1 什么是AOPAOP（Aspect-Oriented Programming），面向切面编程。 一句话解释 AOP 是在不改动原业务逻辑代码的前提下，动态插入功能，比如：日志记录、事务控制、安全校验等。 更细一点： 假设你有很多个方法，每个方法执行前后都需要记录日志。 如果你在每个方法里都手动加日志，既冗余又容易出错。 AOP 就是把这些公共关注点（日志、事务、权限、监控）抽取成一个切面（Aspect），由框架帮你自动织入到合适的位置。 2.2 AOP核心概念 名词 解释 类比 Aspect（切面） 一个类，它里面可以包含多个通知（Advice），统一管理一组和业务无关的功能，如日志、安全认证、性能监控等。 团队经理 Join Point（连接点） 程序执行中的一个点（如方法调用前、~后、异常抛出时） 可以插手的时机 Pointcut（切点） 筛选哪些连接点需要织入功能。比如：只想对 com.example.service 包下的所有方法打日志、只对标了 @Transactional 的方法做事务控制 筛选器 Advice（通知） 要执行的具体操作（打印日志、事务开启） 工作任务 Weaving（织入） 将切面逻辑插入到目标对象过程。 自动安装插件 Spring AOP 本质上是通过 动态代理 来实现的： 如果接口存在 → JDK动态代理 如果没有接口 → CGLIB字节码增强（动态生成子类，重写方法，实现增强） Spring AOP底层就是在容器初始化阶段替换掉原Bean，换成一个代理对象，代理对象通过链式拦截器机制，在方法调用时织入各种横切逻辑。 流程： 123456789你的业务类（UserService） ↓Spring 检查有没有相关切面（@Aspect） ↓如果有，生成一个代理对象（Proxy） ↓以后调用 UserService，其实是在调用代理对象 ↓代理对象先执行通知（Advice），再调用真正的方法 2.3 AOP示例假设我们要做一件事情： 每次调用业务方法前后，打印日志。 整体顺序（简版流程）： 开发切面（Aspect） ➔ 定义切点（Pointcut） ➔ 写通知（Advice） ➔ 织入到连接点（Join Point） ➔ 最后运行时，Spring帮你完成Weaving（织入） 1. 引入依赖（如果是 Spring Boot）在你的 pom.xml 加上 AOP 相关依赖（Spring Boot 自带了，通常不用特意加） 12345&lt;!-- Spring AOP --&gt;&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-aop&lt;/artifactId&gt;&lt;/dependency&gt; 2. 创建一个普通业务类（Service）比如我们有一个用户服务 UserService： 12345678910package com.example.service;import org.springframework.stereotype.Service;@Servicepublic class UserService { public void createUser() { System.out.println(&quot;【业务逻辑】正在创建用户...&quot;); }} 这是最普通的业务类，没有任何AOP相关代码！ 3. 编写一个切面类（Aspect）我们来写一个切面，负责记录方法调用前后的日志。 12345678910111213141516171819202122232425package com.example.aspect;import org.aspectj.lang.annotation.*;import org.springframework.stereotype.Component;@Aspect@Componentpublic class LogAspect { // 定义切点：拦截 com.example.service 包下所有方法 @Pointcut(&quot;execution(* com.example.service.*.*(..))&quot;) public void serviceMethods() {} // 前置通知：方法执行前执行 @Before(&quot;serviceMethods()&quot;) public void beforeMethod() { System.out.println(&quot;【前置通知】方法即将执行...&quot;); } // 后置通知：方法执行后执行（无论是否抛出异常） @After(&quot;serviceMethods()&quot;) public void afterMethod() { System.out.println(&quot;【后置通知】方法已经执行结束...&quot;); }} ✔️ 注意： @Aspect：声明这是一个切面 @Component：让 Spring 管理这个切面 @Pointcut：定义要拦截的方法范围 @Before 和 @After：定义通知逻辑 4. 启动测试写个简单的 Controller 或 CommandLineRunner 测试： 123456789101112131415161718package com.example;import com.example.service.UserService;import org.springframework.beans.factory.annotation.Autowired;import org.springframework.boot.CommandLineRunner;import org.springframework.stereotype.Component;@Componentpublic class TestRunner implements CommandLineRunner { @Autowired private UserService userService; @Override public void run(String... args) throws Exception { userService.createUser(); }} 启动 Spring Boot 应用，控制台输出： 123【前置通知】方法即将执行...【业务逻辑】正在创建用户...【后置通知】方法已经执行结束... 5. 小总结 启动时，Spring 自动扫描到 @Aspect，创建了一个代理对象（UserService 的代理） 你调用 userService.createUser()，其实是代理对象接管了调用 AOP切面逻辑插入： 调用方法前 ➔ 执行 beforeMethod() 然后执行真正的 createUser() 方法执行完 ➔ 执行 afterMethod() 整个过程对业务代码透明，业务开发者啥都不用改！ 2.4 AOP底层原理（源码分析）1. 核心目的 在调用业务方法时，把切面（Advice）通过动态代理织入进去，不需要改业务代码。 AOP实现靠的是动态代理 + 责任链模式。 2. 代理对象的创建方式 场景 使用的动态代理 目标类实现接口 JDK动态代理 目标类无接口 CGLIB子类代理 3. spring生成代理的时机✅ 在Spring容器启动期间，实例化Bean的过程中，会判断是否需要为这个Bean生成代理。 具体是在 Bean初始化过程的 后置处理器（BeanPostProcessor）阶段完成的！ 特别是这个处理器： 1AnnotationAwareAspectJAutoProxyCreator 它是一个特殊的 BeanPostProcessor，负责： 在Spring实例化每个Bean之后，检查这个Bean是否需要AOP增强，如果需要就给它创建一个代理对象。 具体流程： Spring开始实例化Bean（比如UserService）。 实例化完成后，进入后置处理器链。 AnnotationAwareAspectJAutoProxyCreator.postProcessAfterInitialization(bean, beanName) 被调用。 在这里，Spring做几件事： 遍历所有切面（@Aspect注解的类）。 根据**切点表达式(Pointcut)**，判断这个Bean的哪些方法需要增强。 如果找到了匹配的切面（Advisor），就会为这个Bean生成代理对象。 否则，直接返回原来的Bean，不代理。 ✅ 总结：每个Bean在初始化后，Spring都会判断一次：要不要为它创建代理。 4. 核心执行链条（详细版，带代码理解） ✅ 核心逻辑： 拦截到方法调用 创建 ReflectiveMethodInvocation（持有拦截器链） 执行 proceed()，一层一层责任链执行 最后执行目标方法（你的业务代码） 4.1 Spring内部代理入口调用代理对象的方法，比如： 1userService.createUser(); 内部实际上是走到Spring代理（比如JdkDynamicAopProxy.invoke()）， 核心是构建ReflectiveMethodInvocation： 123ReflectiveMethodInvocation invocation = new ReflectiveMethodInvocation( proxy, target, method, args, targetClass, interceptorsAndDynamicMethodMatchers); ✅ interceptorsAndDynamicMethodMatchers：保存了所有拦截器链。 4.2 执行责任链 —— proceed()（超重要！）代码： 123456789101112131415161718public Object proceed() throws Throwable { // 1. 如果拦截器都执行完了，直接执行目标方法 if (this.currentInterceptorIndex == this.interceptorsAndDynamicMethodMatchers.size() - 1) { return invokeJoinpoint(); } // 2. 否则取下一个拦截器 Object interceptorOrInterceptionAdvice = this.interceptorsAndDynamicMethodMatchers.get(++this.currentInterceptorIndex); if (interceptorOrInterceptionAdvice instanceof MethodInterceptor) { // 3. 执行拦截器（拦截器内部通常会再调用proceed()推进） return ((MethodInterceptor) interceptorOrInterceptionAdvice).invoke(this); } else { // 4. 如果不是拦截器（极少情况），直接跳过 return proceed(); }} ✅ 责任链推进机制就是通过**拦截器的invoke()内部调用proceed()**递归推进！ 4.3 拦截器的内部处理举几个典型拦截器的代码示例： ① 事务拦截器（TransactionInterceptor）123456789101112public Object invoke(MethodInvocation invocation) throws Throwable { TransactionInfo txInfo = createTransactionIfNecessary(); Object retVal = null; try { retVal = invocation.proceed(); // 【推进责任链，执行业务逻辑】 commitTransactionAfterReturning(txInfo); // 正常提交事务 } catch (Throwable ex) { rollbackTransactionOnException(txInfo, ex); // 异常回滚 throw ex; } return retVal;} ✅ 在 proceed() 之前开启事务；proceed()之后提交/回滚事务。 ② 环绕通知拦截器（@Around）1234567891011121314@Around(&quot;execution(* com.example.service.*.*(..))&quot;)public Object around(ProceedingJoinPoint pjp) throws Throwable { System.out.println(&quot;环绕-方法开始执行&quot;); Object result = pjp.proceed(); // 【推进责任链】 System.out.println(&quot;环绕-方法执行完毕，返回值：&quot; + result); // 可以处理/修改返回值 if (result instanceof String) { result = result + &quot; 后缀&quot;; } return result;} ✅ 在 proceed() 之前做前置逻辑；之后做后置逻辑，甚至可以修改返回值！ 4.4 目标方法真正执行 —— invokeJoinpoint()当责任链推进到最后，Spring执行： 1return invokeJoinpoint(); ✅ 这一步才是真正调用到你写的 createUser()、getUser()这样的业务方法本体！ 5. 整体执行流程总结1234567891011121314151617代理对象方法调用 ↓JdkDynamicAopProxy.invoke() ↓构建ReflectiveMethodInvocation（维护拦截器链） ↓调用ReflectiveMethodInvocation.proceed() ↓ 执行拦截器1.invoke() → proceed() 执行拦截器2.invoke() → proceed() ... 最后执行目标方法（invokeJoinpoint） ← 返回结果← 按责任链倒序回溯（可以处理返回值、异常等）← 返回给调用方","link":"/2025/04/22/%E9%9D%99%E6%80%81%E4%BB%A3%E7%90%86%E3%80%81%E5%8A%A8%E6%80%81%E4%BB%A3%E7%90%86%E4%B8%8ESpring%20AOP/"},{"title":"高斯概率分类模型下的有趣现象","text":"摘要： ​ 这是从李宏毅老师的机器学习课程中看到的有趣结论。李老师通过高斯概率分布模型尝试去对一个七位特征进行二分类。高斯分类模型具有两个重要的参数，均值与斜方差矩阵，均值代表概率分布最高的点、也是特征值的平均点，协方差矩阵大致表示了这个分布的形状。当我们对两类东西的高斯分布使用同一个协方差矩阵，然后通过样本对参数进行最大似然估计学习。有两个有趣现象，第一在两类的平面图中，分界线变成了一条直线（可以通过三维想象易得），第二从数学的角度推理得到，这个学习的过程（共用协方差矩阵高斯概率模型分类），最终结果与sigma（wx+b）效果类似，其中w、b为所需学习的函数。 以下为一些课程截图：","link":"/2023/11/17/%E9%AB%98%E6%96%AF%E6%A6%82%E7%8E%87%E5%88%86%E7%B1%BB%E6%A8%A1%E5%9E%8B%E4%B8%8B%E7%9A%84%E6%9C%89%E8%B6%A3%E7%BB%93%E8%AE%BA/"},{"title":"几种线程的创建方式","text":"本文将展示几种主要的Java线程的创建方式： 继承Thread 实现Runnable接口（推荐） 实现Callable接口+Future（带线程返回值） Lamda 表达式创建 自定义线程池创建 这些线程的创建本质上是实现了Runnable接口。 1、继承 Thread 类12345678910111213class MyThread extends Thread { @Override public void run() { System.out.println(&quot;线程运行中: &quot; + Thread.currentThread().getName()); }}public class Main { public static void main(String[] args) { MyThread thread = new MyThread(); thread.start(); // 启动线程 }} 适合简单任务，但不推荐继承 Thread 和实现 Runnable 同时使用，因为 Java 不支持多继承。 2、实现 Runnable 接口（推荐）12345678910111213class MyRunnable implements Runnable { @Override public void run() { System.out.println(&quot;Runnable 线程运行中: &quot; + Thread.currentThread().getName()); }}public class Main { public static void main(String[] args) { Thread thread = new Thread(new MyRunnable()); thread.start(); }} 优点：更灵活，可以避免继承限制；可用于多个线程共享资源。 3、实现 Callable 接口 + FutureTask（有返回值）12345678910111213141516171819202122import java.util.concurrent.Callable;import java.util.concurrent.FutureTask;class MyCallable implements Callable&lt;String&gt; { @Override public String call() { return &quot;线程返回结果&quot;; }}public class Main { public static void main(String[] args) throws Exception { MyCallable callable = new MyCallable(); FutureTask&lt;String&gt; futureTask = new FutureTask&lt;&gt;(callable); Thread thread = new Thread(futureTask); thread.start(); // 获取返回结果（会阻塞直到完成） String result = futureTask.get(); System.out.println(&quot;结果：&quot; + result); }} 优点：可以有返回值，且支持异常处理。 4、lambda表达式创建（Java 8 及以上）123456public class Main { public static void main(String[] args) { Thread thread = new Thread(() -&gt; System.out.println(&quot;Lambda 线程运行&quot;)); thread.start(); }} 语法简洁，常用于简短任务。 5、线程池创建实际中最多使用的是自定义线程池ThreadPoolExcutor。避免使用Java提供的Excutor因为很多因素不可控。 12345678910111213ThreadPoolExecutor excutor1 = new ThreadPoolExecutor( 2, 5, 60, TimeUnit.SECONDS, new LinkedBlockingQueue&lt;&gt;(), new ThreadPoolExecutor.AbortPolicy());excutor1.execute(()-&gt;{ System.out.println(Thread.currentThread().getName()); System.out.println(&quot;Hello World&quot;);}); 适合高并发或大量任务执行场景，推荐在线程数量受控的情况下使用。 6、汇总代码实验12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182package org.example;import java.util.concurrent.*;class MyThread extends Thread { @Override public void run() { System.out.println(Thread.currentThread().getName()); System.out.println(&quot;Hello World&quot;); }}class MyRunable implements Runnable{ @Override public void run() { System.out.println(Thread.currentThread().getName()); System.out.println(&quot;Hello World&quot;); }}class MyCallable implements Callable&lt;Integer&gt;{ @Override public Integer call() throws Exception { System.out.println(Thread.currentThread().getName()); System.out.println(&quot;Hello World&quot;); return 100; }}public class ThreadCreate { public static void main(String[] args) { System.out.println(Thread.currentThread().getName()); //1. 继承 Thread 类 Thread t1 = new MyThread(); t1.start(); //2.实现runnable接口 Thread t2 = new Thread(new MyRunable()); t2.start(); //3.带返回值的Thread MyCallable myCallable = new MyCallable(); FutureTask&lt;Integer&gt; futureTask = new FutureTask&lt;&gt;(myCallable); Thread t3 = new Thread(futureTask); t3.start(); Integer res = -1; try { res = futureTask.get(); }catch (Exception e) { System.out.println(e.getMessage()); }finally { System.out.println(res); } //4.lamda表达式创建 Thread t4 = new Thread(() -&gt; { System.out.println(Thread.currentThread().getName()); System.out.println(&quot;Hello World&quot;); }); t4.start(); //5.通过线程池创建 ThreadPoolExecutor excutor1 = new ThreadPoolExecutor( 2, 5, 60, TimeUnit.SECONDS, new LinkedBlockingQueue&lt;&gt;(), new ThreadPoolExecutor.AbortPolicy() ); excutor1.execute(()-&gt;{ System.out.println(Thread.currentThread().getName()); System.out.println(&quot;Hello World&quot;); }); }}","link":"/2024/05/08/%E5%87%A0%E7%A7%8D%E7%BA%BF%E7%A8%8B%E7%9A%84%E5%88%9B%E5%BB%BA%E6%96%B9%E5%BC%8F/"},{"title":"并发编程的三大特性与问题复现","text":"​ 本文将讲解并发编程的三大特性：原子性、可见性、有序性。复现了其解决的问题，并且较少了Java的解决方法。 ​ JMM（Java memory model）定义了多线程环境下变量的访问规则，解决并发编程中“可见性”和“有序性”的问题，确保程序在不同平台上的行为一致性。 ​ 由于CPU存在L1、L2、L3等缓存，因此各核心（或线程）在运行时变量常为主内存的副本，写回时间不确定，因此存在着并发问题，例如“可见性问题”。另外，JIT编译优化、指令优化使得执行顺序并不唯一，会导致“有序性”的问题。详见JMM(Java内存模型)。 1. 原子性​ 定义：指一个操作是不可分割的，不可中断的。一次操作或者多次操作，要么所有的操作全部都得到执行，要么都不执行。 ​ 问题复现: 12345678910111213141516171819202122232425public class AtimoticTest { static int count = 0; static void increaseCount() throws InterruptedException{ //不加synchronized Thread.sleep(1); //仅为增加上下文切换频率 count++; } public static void main(String[] args) throws InterruptedException { Thread t1 = new Thread(() -&gt; { for (int i = 0; i &lt; 100; i++) { increaseCount(); } }); Thread t2 = new Thread(() -&gt; { for (int i = 0; i &lt; 100; i++) { increaseCount(); } }); t1.start(); t2.start(); t1.join(); t2.join(); System.out.println(count); }} 例如i++操作属于非原子型(读数据、+1、写回)，两个线程同时操作一个静态变量会导致，写丢失。 解决方法： ​ 在 Java 中，可以借助synchronized、各种 Lock 以及各种原子类实现原子性。 synchronized 和各种 Lock 可以保证任一时刻只有一个线程访问该代码块，因此可以保障原子性。各种原子类是利用 CAS (compare and swap) 操作（可能也会用到 volatile或者final关键字）来保证原子操作。 2. 可见性​ 由于线程使用工作内存缓存变量副本，因此主内存变量的改变，常对一些线程不可见，引发并发问题。为保证，一个线程对共享变量进行了修改，那么另外的线程都是立即可以看到修改后的最新值。 问题复现： 123456789101112131415161718192021public class kejianxing { public static boolean flag = true; //未加volatile public static void main(String[] args) throws InterruptedException { Thread t1 = new Thread(() -&gt; { while (flag) { // xxx } System.out.println(&quot;t1 finished&quot;); }); t1.start(); Thread.sleep(1000); flag = false; System.out.println(&quot;main set flag to false&quot;); t1.join(); System.out.println(&quot;main thread finished&quot;); }} 结果：主线程对flag赋值对t1不可见，t1线程一直不结束。 解决方案： ​ 在 Java 中，可以借助synchronized、volatile 以及各种 Lock 实现可见性。我们将变量声明为 volatile ，这就指示 JVM，这个变量是共享且不稳定的，每次使用它都到主存中进行读取。 3. 有序性​ 指令重排序可以保证串行语义一致（as-if-seria），但是没有义务保证多线程间的语义也一致 ，所以在多线程下，指令重排序可能会导致一些问题。 ​ 指令重排：Java 源代码会经历 编译器优化重排 —&gt; 指令并行重排 —&gt; 内存系统重排 的过程，最终才变成操作系统可执行的指令序列。在单线程情况可以执行加速，但是多线程情况产生并发错误。 例如，在单例模式DCL问题下，指令重排导致的问题。 1234567891011121314public class Singleton { private static Singleton instance; // 不使用 volatile public static Singleton getInstance() { if (instance == null) { // 第一次检查（非同步） synchronized (Singleton.class) { if (instance == null) { // 第二次检查（同步） instance = new Singleton(); // 可能发生指令重排！ } } } return instance; }} ​ instance = new Singleton() 在字节码层面分为3步：① 分配内存空间 ② 初始化对象（调用构造方法）③ 将引用赋值给 instance 如果发生指令重排（②和③交换）： 线程A 执行 instance = new Singleton()，但 instance 先被赋值（③），而对象未初始化（②未执行）。 线程B 进入 getInstance()，发现 instance != null，直接返回一个未初始化完成的对象，导致程序错误。其他线程，便会使用这个未初始化的对象， 解决方案 在 Java 中，volatile 关键字可以禁止指令进行重排序优化。 volatile本质上利用了JMM 提出了了 happens-before 原则。 happens-before规则 描述 程序顺序规则 单线程内，代码按顺序执行 锁规则 解锁先于加锁（释放锁前的修改，对后面拿锁可见） volatile 规则 写 volatile 先于读 线程启动规则 start() 先于子线程动作 线程终止规则 join() 先于线程结果可见 传递性规则 A → B，B → C，则 A → C 📌 只要两个操作之间存在 happens-before，就保证： 前者的修改对后者是可见的 前者的执行顺序在后者之前 ​","link":"/2025/05/10/%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B%E7%9A%84%E4%B8%89%E5%A4%A7%E7%89%B9%E6%80%A7%E4%B8%8E%E9%97%AE%E9%A2%98%E5%A4%8D%E7%8E%B0/"},{"title":"AQS浅析","text":"1. AQS简介AQS 的全称为 AbstractQueuedSynchronizer,抽象队列同步器，位置在java.util.concurrent.locks包下。 AQS本质上是一个抽象类，为同步器提供了通用的执行框架，定义了资源获取和释放的通用流程。例如，可重入锁（ReentrantLock）、信号量（Semaphore）和倒计时器（CountDownLatch）。 在CAS详解中可知，CAS在少量竞争时避免了频发上下文切换因此有较高的效率，但是在大量竞争情况下，CAS纯自旋方式占用CPU且大量时间，却一直饥饿等待，极大地消耗了资源。因此，AQS提出了自旋+阻塞的方案： 如果线程获取锁失败，会先短暂自旋尝试获取锁； 如果仍然失败，则线程会进入阻塞状态（双向队列控制），等待被唤醒，从而减少 CPU 的浪费。 2. AQS结构原理2.1 state资源AQS的核心属性：state(volatile int)和阻塞等待的线程队列（双向链表）。 这两个数据结构均属于享资源，AQS原理上通过CAS state来控制队列的同步访问，使得队列操作线程安全。 state 由子类定义其含义，AQS 本身不限制它的语义，常见用法： 同步器 state 的含义 ReentrantLock 重入次数（0 表示未加锁）,acquire(1)尝试 CAS 将 state 从 0 改为 1（加锁）,release(1) 将 state 从 1 减回 0（解锁） Semaphore 可用许可证数量。acquire(2)尝试将 state 从 5 减到 3（占用2个许可证）,release(2) 将 state 从 3 增回 5（归还2个许可证） CountDownLatch 倒计时的值 ReentrantReadWriteLock 读写计数复合状态（高位读，低位写） state的相关操作： getState()：读state setState(int newState)：写state非线程安全 compareAndSetState(int expect, int update)：写state，线程安全！ acquire（获取资源），会尝试增加或减少 state（通常是减少），表示尝试占用资源。 release（释放资源）：会尝试恢复或增加 state**，表示释放资源、让出锁或许可证。 2.2 waitStatus阻塞节点状态waitStatus 是每个节点的核心字段，表示该线程在同步队列中的状态。 状态名 数值 含义 CANCELLED 1 线程被取消，通常是中断或超时。不会被唤醒，节点最终从队列中被移除。 SIGNAL -1 当前节点的后继节点需要被唤醒（即当前节点释放锁后，要唤醒下一个）。 CONDITION -2 当前节点在 Condition 条件队列中等待。 PROPAGATE -3 用于共享模式下的资源传播，比如 ReentrantReadWriteLock。 0 0 新加入队列的初始状态。 状态变更转换： 新节点入队时，初始状态为 0 。 新节点入队时，它的前继节点状态会由 0 更新为 SIGNAL 。SIGNAL 状态表明该节点的后续节点需要被唤醒。 在唤醒后继节点时，需要清除当前节点的状态。通常发生在 head 节点，比如 head 节点的状态由 SIGNAL 更新为 0 ，表示已经对 head 节点的后继节点唤醒了。 AQS 内部引入了 PROPAGATE 状态，为了解决并发场景下，可能造成的线程节点无法唤醒的情况。（0–&gt;PROPAGATE） 2.3 AQS实现的阻塞排队逻辑假设总共有 3 个线程尝试获取锁，线程分别为 T1 、 T2 和 T3 。 此时，假设线程 T1 先获取到锁，线程 T2 排队等待获取锁。在线程 T2 进入队列之前，需要对 AQS 内部队列进行初始化。head 节点在初始化后状态为 0 。AQS 内部初始化后的队列如下图： 线程 T2 尝试获取锁。由于线程 T1 持有锁，因此线程 T2 会进入队列中等待获取锁。同时会将前继节点（ head 节点）的状态由 0 更新为 SIGNAL ，表示需要对 head 节点的后继节点进行唤醒。此时，AQS 内部队列如下图所示： 此时，线程 T3 尝试获取锁。由于线程 T1 持有锁，因此线程 T3 会进入队列中等待获取锁。同时会将前继节点（线程 T2 节点）的状态由 0 更新为 SIGNAL ，表示线程 T2 节点需要对后继节点进行唤醒。此时，AQS 内部队列如下图所示： 此时，假设线程 T1 释放锁，会唤醒后继节点 T2 。线程 T2 被唤醒后获取到锁，并且会从等待队列中退出。 这里线程 T2 节点退出等待队列并不是直接从队列移除，而是令线程 T2 节点成为新的 head 节点，以此来退出资源获取的等待。此时 AQS 内部队列如下所示： 此时，假设线程 T2 释放锁，会唤醒后继节点 T3 。线程 T3 获取到锁之后，同样也退出等待队列，即将线程 T3 节点变为 head 节点来退出资源获取的等待。此时 AQS 内部队列如下所示： 3 基于AQS自定义同步器使用3.1 钩子方法基于 AQS 可以实现自定义的同步器， AQS 提供了 5 个模板方法（模板方法模式）。AQS 使用只需继承 AbstractQueuedSynchronizer，并且重写必要的钩子方法即可。 12345678910//独占方式。尝试获取资源，成功则返回true，失败则返回false。protected boolean tryAcquire(int)//独占方式。尝试释放资源，成功则返回true，失败则返回false。protected boolean tryRelease(int)//共享方式。尝试获取资源。负数表示失败；0表示成功，但没有剩余可用资源；正数表示成功，且有剩余资源。protected int tryAcquireShared(int)//共享方式。尝试释放资源，成功则返回true，失败则返回false。protected boolean tryReleaseShared(int)//该线程是否正在独占资源。只有用到condition才需要去实现它。protected boolean isHeldExclusively() 除了上面提到的钩子方法之外，AQS 类中的其他方法都是 final ，所以无法被其他类重写。 3.2 acquire、releaseacquire方法是获取资源的主要入口（加锁一般基于acquire） 123456// AQSpublic final void acquire(int arg) { if (!tryAcquire(arg) &amp;&amp; acquireQueued(addWaiter(Node.EXCLUSIVE), arg)) selfInterrupt();} 在 acquire() 中，线程会先尝试获取共享资源；如果获取失败，会将线程封装为 Node 节点加入到 AQS 的等待队列中；加入队列之后，会让等待队列中的线程尝试获取资源，并且会对线程进行阻塞操作。分别对应以下三个方法： tryAcquire() ：尝试获取锁（模板方法），AQS 不提供具体实现，由子类实现。 addWaiter() ：如果获取锁失败，会将当前线程封装为 Node 节点加入到 阻塞队列中等待获取锁。 acquireQueued() ：对线程进行阻塞，并唤醒后调用 tryAcquire() 方法让队列中的线程尝试获取锁。 release是释放资源的（解锁关键） 123456789101112// AQSpublic final boolean release(int arg) { // 1、尝试释放锁 if (tryRelease(arg)) { Node h = head; // 2、唤醒后继节点 if (h != null &amp;&amp; h.waitStatus != 0) unparkSuccessor(h); return true; } return false;} 在 release() 方法中，主要做两件事：尝试释放锁和唤醒后继节点 3.3 一些实现独占的一些例子例子1：ThreadPoolExecutor的Worker就一个极简的AQS锁实现（即不排队也不可重入），参照 ThreadPoolExecutor源码分析 2.5 worker。 例子2：ReentrantLock中非公平锁的tryAcquire() 会调用如下nonfairTryAcquire() 1234567891011121314151617181920212223242526// ReentrantLockfinal boolean nonfairTryAcquire(int acquires) { final Thread current = Thread.currentThread(); // 1、获取 AQS 中的 state 状态 int c = getState(); // 2、如果 state 为 0，证明锁没有被其他线程占用 if (c == 0) { // 2.1、通过 CAS 对 state 进行更新 if (compareAndSetState(0, acquires)) { // 2.2、如果 CAS 更新成功，就将锁的持有者设置为当前线程 setExclusiveOwnerThread(current); return true; } } // 3、如果当前线程和锁的持有线程相同，说明发生了「锁的重入」 else if (current == getExclusiveOwnerThread()) { int nextc = c + acquires; if (nextc &lt; 0) // overflow throw new Error(&quot;Maximum lock count exceeded&quot;); // 3.1、将锁的重入次数加 1 setState(nextc); return true; } // 4、如果锁被其他线程占用，就返回 false，表示获取锁失败 return false;} 在 nonfairTryAcquire() 方法内部，主要通过两个核心操作去完成资源的获取： 通过 CAS 更新 state 变量。state == 0 表示资源没有被占用。state &gt; 0 表示资源被占用，此时 state 表示重入次数。 通过 setExclusiveOwnerThread() 设置持有资源的线程。 如果线程更新 state 变量成功，就表明获取到了资源， 因此将持有资源的线程设置为当前线程即可。 Reentrantlock的tryRelease() 方法释放锁 1234567891011121314151617// ReentrantLockprotected final boolean tryRelease(int releases) { int c = getState() - releases; // 1、判断持有锁的线程是否为当前线程 if (Thread.currentThread() != getExclusiveOwnerThread()) throw new IllegalMonitorStateException(); boolean free = false; // 2、如果 state 为 0，则表明当前线程已经没有重入次数。因此将 free 更新为 true，表明该线程会释放锁。 if (c == 0) { free = true; // 3、更新持有资源的线程为 null setExclusiveOwnerThread(null); } // 4、更新 state 值 setState(c); return free;} 在 tryRelease() 方法中，会先计算释放锁之后的 state 值，判断 state 值是否为 0。 如果 state == 0 ，表明该线程没有重入次数了，更新 free = true ，并修改持有资源的线程为 null，表明该线程完全释放这把锁。 如果 state != 0 ，表明该线程还存在重入次数，因此不更新 free 值，free 值为 false 表明该线程没有完全释放这把锁。 之后更新 state 值，并返回 free 值，free 值表明线程是否完全释放锁。 3.4 共享例子如信号量、读写锁都用了不同于独占的思路与方式，其重点在于获取释放的资源数不再为1，并且唤醒的逻辑不同如setHeadAndPropagate()等，这里便不过多介绍了。","link":"/2025/05/10/AQS%E6%B5%85%E6%9E%90/"},{"title":"CAS详解","text":"1.什么是CAS​ CAS （Compare and Swap）是一种 无锁（Lock-Free）并发编程方式，用于实现原子操作。具有如下形式： 1CAS(V, E, N) ​ 这条操作是原子性的，由 CPU 提供的底层指令支持。含义：如果内存位置V的值等于预期值E，就将其更新为新值N，否则不做任何操作。 2. Java 中的 CAS 实现​ Java 主要通过 sun.misc.Unsafe 类和 java.util.concurrent.atomic 包中的原子类来实现 CAS 操作。 2.1 Unsafe 类中的 CAS 方法123public final native boolean compareAndSwapObject(Object o, long offset, Object expected, Object x);public final native boolean compareAndSwapInt(Object o, long offset, int expected, int x);public final native boolean compareAndSwapLong(Object o, long offset, long expected, long x); 2.2 原子类 (Atomic Classes)Java 提供了一系列原子类，如： AtomicInteger AtomicLong AtomicBoolean AtomicReference AtomicIntegerArray 等 这些类内部都使用了 CAS 操作来保证线程安全。 简单线程安全计数器的视线： 12345678910111213141516public class Counter { private AtomicInteger count = new AtomicInteger(0); public void increment() { int oldValue; int newValue; do { oldValue = count.get(); newValue = oldValue + 1; } while (!count.compareAndSet(oldValue, newValue)); } public int getCount() { return count.get(); }} 3. CAS的优缺点优点 无锁并发：避免了传统锁机制带来的线程阻塞和上下文切换开销 高性能：在低竞争环境下性能优于锁 硬件支持：由CPU直接提供原子性保证 缺点 单一变量限制：只能保证对单个变量的原子操作，无法实现多行代码的原子性 ABA问题： 场景：线程1读取值为A，线程2将值改为B后又改回A，线程1的CAS操作仍会成功 解决方案：追加版本号（如AtomicStampedReference） 自旋开销：在高竞争环境下，失败的线程会不断重试，消耗CPU资源 实现复杂度：正确实现非阻塞算法比使用锁更复杂","link":"/2025/05/10/CAS%E8%AF%A6%E8%A7%A3/"},{"title":"ThreadPoolExecutor源码分析","text":"线程池实现了线程资源的复用，避免了频繁创建销毁线程的开销。 本文将从ThreadPoolExecutor的使用，并从源码进行剖析： 自定义线程池的使用 源码剖析 核心属性ctl、线程池的状态转换 execute addWorker Worker工作线程 runWorker getTask processWorkerExit 1、自定义线程池的基本使用一个常规自定义线程池的创建如下： 123456789public ThreadPoolExecutor(int corePoolSize, //核心工作线程数int maximumPoolSize, //最大工作线程数long keepAliveTime, //非核心线程在阻塞队列中超时等待的时间TimeUnit unit, //等待时间单位BlockingQueue&lt;Runnable&gt; workQueue, //线程的构建工作RejectedExecutionHandler handler //当最大线程数+队列满了时，执行当前的拒绝策略) 2、源码剖析2.1 核心属性ctl1private final AtomicInteger ctl = new AtomicInteger(ctlOf(RUNNING, 0)); ​ ctl通过AtomicInteger来保证操作的原子性，32为的整形，高3为表线程池状态，第29为表工作线程的数量。因此，通过ctl便可计算得线程池的状态与工作线程数量。 线程池状态（5种）： state value 二进制 说明 RUNNING -1 111 执行处理任务，并阻塞队列中的任务 SHUTDOWN 0 000 不接受新的任务，正在处理、队列中的任务会继续执行 STOP 1 001 不接受新的任务，中断正在处理线程，不执行队列剩余任务 TIDYING 2 010 过渡阶段，代表线程池马上关闭 TERMINATED 3 011 由TIDYING经过terminated方法转变 2.2 execute() 3个核心分支： 核心线程未满，创建核心线程执行。（懒加载） 核心线程已满，阻塞队列未满，加队列。 核心线程满、队列满，加非核心线程 线程池状态非运行、全满，拒绝策略 代码注释： 123456789101112131415161718192021public void execute(Runnable command) { if (command == null) throw new NullPointerException(); int c = ctl.get(); // 1、若工作线程的数量&lt;核心线程数量，创建核心线程 if (workerCountOf(c) &lt; corePoolSize) { if (addWorker(command, true)) return; c = ctl.get(); //创建失败，并发问题（核心线程创建完毕），重新获取ctl } // 2、工作线程&gt;核心线程数，尝试添加到阻塞队列 if (isRunning(c) &amp;&amp; workQueue.offer(command)) { int recheck = ctl.get(); //状态非运行 or 阻塞队列加满了 if (! isRunning(recheck) &amp;&amp; remove(command)) //状态非运行，移除该任务，并拒绝 reject(command); else if (workerCountOf(recheck) == 0) //核心线程满了，加入队列，但没线程 addWorker(null, false); //则加一个非核心线程处理 } else if (!addWorker(command, false)) //核心线程满了，队列满了，则执行拒绝策略 reject(command); } 2.3 addWorker()主要工作： 进行线程池状态判断 进行数量判断 并发线程安全的创建并添加线程 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869private boolean addWorker(Runnable firstTask, boolean core) { retry: for (;;) { int c = ctl.get(); int rs = runStateOf(c);// =======================判断运行状态===============================//状态比SHUTDOWN差（除shutdown状态，队列有未处理，且加了个拉取处理的线程），则拒绝 if (rs &gt;= SHUTDOWN &amp;&amp; ! (rs == SHUTDOWN &amp;&amp; firstTask == null &amp;&amp; ! workQueue.isEmpty())) return false;// =======================判断运行线程数量=============================== for (;;) { int wc = workerCountOf(c); //工作线程大于容量 or 大于当前类型线程的数量，则拒绝 if (wc &gt;= CAPACITY || wc &gt;= (core ? corePoolSize : maximumPoolSize)) return false; //CAS成功 增加工作线程wc，退出检查，新增 if (compareAndIncrementWorkerCount(c)) break retry; //CAS失败 再次尝试 c = ctl.get(); if (runStateOf(c) != rs) //状态改变（非正常） continue retry; // 继续检查数量 } } boolean workerStarted = false; boolean workerAdded = false; Worker w = null; try { w = new Worker(firstTask); final Thread t = w.thread; if (t != null) { final ReentrantLock mainLock = this.mainLock; mainLock.lock(); //保护工作线程集合 try { int rs = runStateOf(ctl.get()); if (rs &lt; SHUTDOWN || (rs == SHUTDOWN &amp;&amp; firstTask == null)) { if (t.isAlive()) //防止重复启动 throw new IllegalThreadStateException(); workers.add(w); int s = workers.size(); if (s &gt; largestPoolSize) largestPoolSize = s; workerAdded = true; } } finally { mainLock.unlock(); } if (workerAdded) { t.start(); workerStarted = true; } } } finally { if (! workerStarted) addWorkerFailed(w); } return workerStarted;} 2.4 Worker工作线程worker的作用：封装了thread、firstTask、以及一个轻量级的锁（禁止中断等） 重点关注： run() 调用了外部类实例的runWorker函数。执行逻辑 继承了AQS，利用AQS的State实现了轻量的不可重入锁（该处不必实现重入功能） 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758private final class Worker extends AbstractQueuedSynchronizer implements Runnable{ private static final long serialVersionUID = 6138294804551838833L; final Thread thread; Runnable firstTask; volatile long completedTasks; Worker(Runnable firstTask) { setState(-1); //逻辑上禁止中断，使用AQS轻量互斥锁。外部获取状态-1，不对我中断 this.firstTask = firstTask; this.thread = getThreadFactory().newThread(this); } public void run() { runWorker(this); //调用外部类实例的runWorker(this)方法，执行处理 } protected boolean isHeldExclusively() { return getState() != 0; } // 尝试获取锁 protected boolean tryAcquire(int unused) { if (compareAndSetState(0, 1)) { setExclusiveOwnerThread(Thread.currentThread()); return true; } return false; } protected boolean tryRelease(int unused) { setExclusiveOwnerThread(null); setState(0); //状态变为可中断，锁可获得 return true; } // 基于AQS实现的轻量不可重入锁 public void lock() { acquire(1); } public boolean tryLock() { return tryAcquire(1); } public void unlock() { release(1); } public boolean isLocked() { return isHeldExclusively(); } // 外部尝试中断，若不可中断-1则不中断该线程、 void interruptIfStarted() { Thread t; if (getState() &gt;= 0 &amp;&amp; (t = thread) != null &amp;&amp; !t.isInterrupted()) { try { t.interrupt(); } catch (SecurityException ignore) { } } }} 2.5 runWorker(Worker w)虽然 runWorker() 是由一个线程单独执行的，但**Worker 实例本身可能在其他线程中被并发操作（比如被中断、被检查状态、被回收），所以需要加锁来保护线程之间的协作可见性和内存一致性**。 123456789101112131415161718192021222324252627282930313233343536373839final void runWorker(Worker w) { Thread wt = Thread.currentThread(); Runnable task = w.firstTask; w.firstTask = null; w.unlock(); //允许中断 boolean completedAbruptly = true; try { while (task != null || (task = getTask()) != null) { w.lock(); if ((runStateAtLeast(ctl.get(), STOP) || //检查STOP状态进行中断 (Thread.interrupted() &amp;&amp; runStateAtLeast(ctl.get(), STOP))) &amp;&amp; !wt.isInterrupted()) wt.interrupt(); //中断 try { beforeExecute(wt, task); //前置增强 Throwable thrown = null; try { task.run(); //任务执行 } catch (RuntimeException x) { thrown = x; throw x; } catch (Error x) { thrown = x; throw x; } catch (Throwable x) { thrown = x; throw new Error(x); } finally { afterExecute(task, thrown); //后置增强 } } finally { task = null; w.completedTasks++; //统计 w.unlock(); } } completedAbruptly = false; //完整执行（前后增强中未抛出异常） } finally { processWorkerExit(w, completedAbruptly); }} 流程整理： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647runWorker(w)│├── 初始准备：│ ├── task = w.firstTask│ ├── w.unlock() // 允许被中断│ └── completedAbruptly = true│├── 进入 while 循环：while (task != null || (task = getTask()) != null)││ ┌── 每一轮循环逻辑：│ ││ ├── 1. 如果 task 为 null，调用 getTask()│ │ ├── 如果任务队列为空：│ │ │ → getTask() 进入阻塞（take 或 poll）│ │ ├── 如果线程被中断：│ │ │ → timeOut=false，重新处理，保持线程稳定性│ │ │ → catch 后不退出，继续循环│ │ ├── 如果线程池状态已 STOP 且队列空：│ │ │ → return null → 跳出 while 循环│ ││ ├── 2. w.lock() → 上锁，准备执行任务│ ││ ├── 3. 检查线程池状态 &amp; 中断标志：│ │ ├── 如果线程池为 STOP 状态，确保线程被中断（wt.interrupt()）│ ││ ├── 4. 执行钩子 &amp; task.run()：│ │ ├── beforeExecute()│ │ ├── task.run()（用户代码）│ │ ├── afterExecute()│ ││ ├── 5. finally：│ │ ├── task = null│ │ ├── w.completedTasks++│ │ ├── w.unlock()│ ││ └── 回到 while 条件判断 → 决定是否继续│├── 退出 while 循环（正常或 getTask() 返回 null）│ └── 设置 completedAbruptly = false│└── finally → 调用 processWorkerExit(w, completedAbruptly) ├── 减少线程数（如果异常退出） ├── 移除 Worker ├── 尝试终止线程池 └── 可能创建替补线程 2.6 processWorkerExit线程撤销处理 12345678910111213141516171819202122232425262728private void processWorkerExit(Worker w, boolean completedAbruptly) { if (completedAbruptly) //是否完整执行任务。 decrementWorkerCount(); //不完整执行，统计完成 final ReentrantLock mainLock = this.mainLock; mainLock.lock(); try { completedTaskCount += w.completedTasks; workers.remove(w); } finally { mainLock.unlock(); } tryTerminate(); int c = ctl.get(); if (runStateLessThan(c, STOP)) { if (!completedAbruptly) { int min = allowCoreThreadTimeOut ? 0 : corePoolSize; if (min == 0 &amp;&amp; ! workQueue.isEmpty()) min = 1; if (workerCountOf(c) &gt;= min) return; // replacement not needed } addWorker(null, false); }}","link":"/2024/05/08/ThreadPoolExecutor%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90/"},{"title":"Mysql三大日志","text":"MySql InnoDB中有个三个重要日志： Undo Log（回滚日志） Redo Log（重放日志） Bin Log（归档日志） 其中，Undo Log（回滚日志）主要作用：事务回滚用于撤销事务未提交前对数据的更改；MVCC 快照读：为其他事务提供“旧版本”数据，实现一致性读。 Redo Log（重做日志），崩溃恢复（Crash Recovery）：保证已提交的事务修改不丢失，即使系统宕机；WAL（Write-Ahead Logging）机制：修改先写日志，后写磁盘，提高性能和可靠性。 Binlog（归档日志 / 二进制日志），数据恢复（PITR）：结合全备 + binlog，可做时间点恢复，记录数据库变更历史。程序员业务上根据此进行数据库备份、回溯。主从复制：从库根据主库的 binlog 重放 SQL 操作； 1、Mysql 执行原理 1.1 sql Server层 客户端通过连接驱动（如 JDBC）发起 SQL 请求，进入 连接池。MySQL Server 层的缓存机制默认是关闭的，至在 MySQL 8.0 中已被彻底移除，主要原因是：并发性能差、命中率低、缓存管理开销大。入不敷出。 （1） SQL 解析器（Parser）——“看懂你写了啥” 主要作用：检查SQL 文本语句的语法，并解析成数据库内部能理解的数据结构（语法树 AST） （2）SQL预处理器（Preprocessor）——“语义检查官 + 安全管家” 主要作用：对解析器生成的语法树做进一步的语义检查和权限校验 （3）SQL 优化器（Optimizer）——“帮你挑个最快的方案” 主要作用：根据语法树，生成多个执行计划，并选出代价最小的那一个来执行。 如：选择合适的索引，决定表连接的顺序（如多表 JOIN），子查询是否改写为 JOIN，是否使用排序优化、索引下推、覆盖索引等。 （4）执行器（Executor）——“执行部队” 主要作用：按优化器生成的执行计划，调用存储引擎接口（如 InnoDB）一行行地执行 SQL 工作内容：遍历执行计划节点（如 Table Scan、Index Lookup、Join）、调用存储引擎的 handler 接口（例如：读一行、写一行）、处理结果、聚合、排序、分页等、结果返回给客户端。 1.2 存储层（InnoDB）中的日志流程 首先声明InnoDB是事务型存储引擎，哪怕你没有写 BEGIN，它也会隐式地为每条 DML 语句开启一个“短事务”。 三大日志处理流程具体如下： 编号 操作 日志/组件 作用 1 写 Undo Log Undo Log（内存） 回滚和 MVCC 快照 2 写 Buffer Pool Buffer Pool（内存） 修改数据页 3 写 Redo Log（prepare） Redo Log（内存） 崩溃恢复（先写日志） 4 刷 Binlog Binlog + fsync 主从复制/归档 5 redo commit + 异步刷盘 磁盘 + dump/IO 线程 正式提交、异步持久化 1.3 事务提交（2PC两阶段提交流程）：当使用 InnoDB + Binlog 时，MySQL 采用 两阶段提交（2PC） 保证 redo log 与 binlog 的一致性。 步骤如下： 事务执行阶段 生成 undo log、修改 Buffer Pool、生成 redo log 准备提交（Prepare 阶段） 把 redo log 写入磁盘并标记为 &quot;prepare&quot;。flush redo log将redo log 载入磁盘。 写 binlog + fsync 把 binlog 写入磁盘（如果启用了 binlog） 提交 redo log（写 COMMIT 标记） redo log 写入 &quot;commit&quot; 标记。 真正的提交点为：redo log 已刷盘 + binlog 已刷盘 + redo log 标记为 COMMIT 2、三大日志详细2.1 Undo LogUndo Log记录项的主要内容： 当前事务 ID（trx_id）： 修改前的旧值 指向前一个版本的指针（roll_pointer）：形成版本链，支持多版本读取（MVCC）。MVCC 内容详见理解数据库事务 MVCC内容。 不同操作记录的 Undo 内容略有不同： UPDATE 操作：更新前的字段值。 DELETE 操作：整行数据（被删前的） INSERT 操作：记录：删除标记（即标记“这行是我插入的”，回滚时应删除） 回滚rollback逻辑：从事务尾部往前读取 Undo Log，按记录的原值逐条“撤销”数据修改。 2.2 Redo Log Redo Log（重做日志） 是 InnoDB 存储引擎使用的一种 物理日志，用于崩溃恢复，确保已提交事务的修改不会因为宕机而丢失。 数据页直接刷盘不就好了，还有 redo log 什么事？ 修改的数据页每个可能仅改了几个字节，大量的页写入耗时。而RedoLog只要写几Byte即可。 数据页的修改大概率需要分散的随机访问，性能差。而redolog顺序写更快。 2.2.1 存储结构Redo Log数据由两部分组成： Log Buffer：内存中的 redo 日志缓冲区 Log File：磁盘上的 redo log 文件（ib_logfile0、ib_logfile1 …）。 RedoLog File采用循环文件的方式。该循环文件类似于循环队列，write pos、checkpoint分别为当前记录的位置、前已落盘位置（可覆盖）。相关操作如下: 写操作，write pos边写边后移动。 循环文件满时（write pos追上checkpoint），InnoDB 会阻塞新事务，等待 flush 脏页，推进 checkpoint 2.2.2 刷盘时机 Redo Log 的主要目的是为了保证BufferPool未刷入磁盘数据不丢失（如崩溃等因素）。 Redo Log 默认会在事务“提交前”（preCommit）刷新到磁盘，确保事务提交后即使宕机也不丢数据。 Redo在很多种情况下都会刷盘： 事务提交 redolog buffer空间不足 事务日志缓冲区满 Checkpoint（检查点）：InnoDB 定期会执行检查点操作。 关闭服务器 其中，在提交事务时候，可设置innodb_flush_log_at_trx_commit进行刷盘策略： 值 含义 刷盘时机 持久性 性能 0 提交时不写磁盘，只写 redo log buffer 每秒由后台线程 flush 一次 差 高 1 每次事务提交都写 redo log buffer 并 flush 到磁盘 提交时立即刷盘 强（推荐） 低 2 提交时写 redo log buffer，但不 flush 到磁盘 每秒刷盘一次 较强（仍可能丢失1秒内数据） 较高 2.3 Bin LogBinlog 是 MySQL 的 Server 层日志，用于记录所有更改了数据库数据的操作（即 DML、DDL 语句），不包括查询语句（SELECT）。 文件名：通常是 mysql-bin.000001 这样命名。 位置：由 log_bin 参数控制，存放在数据目录下。 类型：是追加写入的二进制文件。 BinLog的作用: (1) 主从复制（MySQL Replication） 主从复制就是靠 binlog 实现的。主库写 binlog，从库读取并执行，保持数据一致。从数据库连接到dump线程后，合适的实际会将BinLog发送到从数据库，只需将BinLog记录到从库端的Relay Log，即同步成功。后续从库会在合适的时间根据relay log 更新数据库。 （2）数据恢复 可以配合全量备份（如 mysqldump）进行增量恢复，恢复到任意时间点（类似时间机器）。业务上，回溯数据库就是借此实现。","link":"/2025/05/13/Mysql%E4%B8%89%E5%A4%A7%E6%97%A5%E5%BF%97/"},{"title":"API接口&amp;mysql的简单压测","text":"1、JMeter（API压测）并发接口压测 官网下载：https://jmeter.apache.org/download_jmeter.cgi。JMeter用 JAVA实现，进入bin目录解压运行java -jar ApacheJMeter.jar，即可。 右键添加线程组（测试计划中） 右键，添加采样器 – HTTP。 添加配置原件，CSV数据。（可用于请求参数的列举，线程组中会分配好，每条最多执行一次）（CSV设置文件中设置分隔符、变量名，参数说明在http页面添加属性中${xxx}使） 右键，添加监听器 – 查看结构树 右键，添加监听器 – 汇总报告 参考：https://www.bilibili.com/video/BV1Mm411o7Yo/?spm_id_from=333.1391.0.0&amp;vd_source=0ff05116367aae8f8480fddf5a565ea6 2、mysqlslap 测QPS、TPS123456mysqlslap --user=root --password=1122 \\ --concurrency=1 \\ # 并发线程数为 1，模拟单线程访问数据库 --iterations=1 \\ # 只运行一次测试（即测试轮数为 1） --number-of-queries=100000 \\ # 总共执行 100,000 次查询（不是每轮每线程，是整轮总数） --query=&quot;SELECT * FROM order_info WHERE id = 1547;&quot; \\ # 要执行的 SQL 查询语句（模拟业务场景） --create-schema=miaosha # 使用名为 &quot;miaosha&quot; 的数据库（schema）","link":"/2025/05/19/API%E6%8E%A5%E5%8F%A3-mysql%E7%9A%84%E7%AE%80%E5%8D%95%E5%8E%8B%E6%B5%8B/"},{"title":"Redis常见数据结构与使用","text":"类型 键 值 常用命令 说明 String ✅ ✅ SET, GET 最基础的键值对，value 可以是任意字符串（二进制安全） List ✅ 📄 LPUSH, LRANGE 值是一个列表（有序，支持重复） Hash ✅ 🧩 HSET, HGET 值是一个键值对集合，类似 HashMap Set ✅ 🔀 SADD, SMEMBERS 值是一个无序集合（唯一元素） ZSet（Sorted Set） ✅ 📊 ZADD, ZRANGE 值是带分数的有序集合 Stream ✅ 🔁 XADD, XREAD 日志流结构，支持消息队列 Bitmap、HyperLogLog、Geo ✅ 特殊结构 特定场景专用 以下给出详细redis命令、jredis使用 1、String——K/V123456789101112131415161718192021222324# 设置一个字符串键值对SET mykey &quot;hello&quot;# 获取键的值GET mykey# 删除键DEL mykey# 设置带过期时间的键值对（5 秒）SETEX tempkey 5 &quot;temp value&quot;# 获取临时键的值GET tempkey# 等 5 秒后再次 GET，会返回 nil（表示已过期）# 仅当 key 不存在时设置键值（用于加锁）SETNX lock:task &quot;1&quot;# 给已存在的 key 设置过期时间（10 秒）EXPIRE lock:task 10# 查看 key 剩余生存时间（秒）TTL lock:task Jredis 123456789101112131415161718192021222324252627282930313233343536373839404142import redis.clients.jedis.Jedis;public class JedisStringExample { public static void main(String[] args) { try (Jedis jedis = new Jedis(&quot;localhost&quot;, 6379)) { System.out.println(&quot;连接成功: &quot; + jedis.ping()); // 1. SET - 设置键值 jedis.set(&quot;mykey&quot;, &quot;hello&quot;); System.out.println(&quot;mykey = &quot; + jedis.get(&quot;mykey&quot;)); // 输出 hello // 2. DEL - 删除键 jedis.del(&quot;mykey&quot;); System.out.println(&quot;mykey after delete = &quot; + jedis.get(&quot;mykey&quot;)); // 输出 null // 3. SETEX - 设置键值并设置过期时间（单位：秒） jedis.setex(&quot;tempkey&quot;, 5, &quot;tempvalue&quot;); System.out.println(&quot;tempkey = &quot; + jedis.get(&quot;tempkey&quot;)); Thread.sleep(6000); // 等待 6 秒 System.out.println(&quot;tempkey after expire = &quot; + jedis.get(&quot;tempkey&quot;)); // 输出 null // 4. SETNX - 如果 key 不存在则设置（分布式锁常用） Long lockResult = jedis.setnx(&quot;lock:key&quot;, &quot;1&quot;); if (lockResult == 1) { jedis.expire(&quot;lock:key&quot;, 10); // 设置过期时间避免死锁 System.out.println(&quot;成功获得锁&quot;); } else { System.out.println(&quot;锁已存在，获取失败&quot;); } // 5. EXPIRE - 为已存在的键设置过期时间 jedis.set(&quot;session:user1&quot;, &quot;active&quot;); jedis.expire(&quot;session:user1&quot;, 30); // 设置 30 秒后过期 System.out.println(&quot;session:user1 TTL = &quot; + jedis.ttl(&quot;session:user1&quot;) + &quot; 秒&quot;); } catch (Exception e) { e.printStackTrace(); } }} 2、ListRedis 的 List 是一个双向链表，可以从左侧或右侧插入/弹出元素，常用于： 消息队列（FIFO） 栈（LIFO） 延迟任务、聊天记录等 123456789101112131415161718192021# 从左侧插入元素（LPUSH）LPUSH mylist &quot;a&quot;LPUSH mylist &quot;b&quot;LPUSH mylist &quot;c&quot;# mylist: [&quot;c&quot;, &quot;b&quot;, &quot;a&quot;]# 从右侧插入元素（RPUSH）RPUSH mylist &quot;d&quot;# mylist: [&quot;c&quot;, &quot;b&quot;, &quot;a&quot;, &quot;d&quot;]# 从左侧弹出（LPOP）LPOP mylist# -&gt; &quot;c&quot;, list: [&quot;b&quot;, &quot;a&quot;, &quot;d&quot;]# 从右侧弹出（RPOP）RPOP mylist# -&gt; &quot;d&quot;, list: [&quot;b&quot;, &quot;a&quot;]# 获取所有元素LRANGE mylist 0 -1# -&gt; [&quot;b&quot;, &quot;a&quot;] Jredis 12345678910111213141516171819202122232425262728293031323334353637import redis.clients.jedis.Jedis;import java.util.List;public class RedisListExample { public static void main(String[] args) { try (Jedis jedis = new Jedis(&quot;localhost&quot;, 6379)) { String key = &quot;mylist&quot;; // 清空旧数据 jedis.del(key); // 左插入（LPUSH） jedis.lpush(key, &quot;a&quot;); jedis.lpush(key, &quot;b&quot;); jedis.lpush(key, &quot;c&quot;); // List 现在是 [&quot;c&quot;, &quot;b&quot;, &quot;a&quot;] // 右插入（RPUSH） jedis.rpush(key, &quot;d&quot;); // List 现在是 [&quot;c&quot;, &quot;b&quot;, &quot;a&quot;, &quot;d&quot;] // 读取所有元素 List&lt;String&gt; list = jedis.lrange(key, 0, -1); System.out.println(&quot;当前列表: &quot; + list); // 左弹出 String left = jedis.lpop(key); System.out.println(&quot;左弹出: &quot; + left); // 右弹出 String right = jedis.rpop(key); System.out.println(&quot;右弹出: &quot; + right); System.out.println(&quot;最终列表: &quot; + jedis.lrange(key, 0, -1)); } }} 3、SET1234567891011121314151617181920# 添加元素到集合SADD myset &quot;apple&quot;SADD myset &quot;banana&quot; &quot;cherry&quot;# 获取集合所有元素SMEMBERS myset# -&gt; {&quot;apple&quot;, &quot;banana&quot;, &quot;cherry&quot;}# 判断元素是否存在SISMEMBER myset &quot;banana&quot;# -&gt; 1 (true)# 获取集合大小SCARD myset# -&gt; 3# 删除元素SREM myset &quot;apple&quot;SMEMBERS myset# -&gt; {&quot;banana&quot;, &quot;cherry&quot;} Jredis 1234567891011121314151617181920212223242526import redis.clients.jedis.Jedis;import java.util.Set;public class RedisSetExample { public static void main(String[] args) { try (Jedis jedis = new Jedis(&quot;localhost&quot;, 6379)) { // 清空旧数据 jedis.del(&quot;myset&quot;); // 添加元素 jedis.sadd(&quot;myset&quot;, &quot;apple&quot;, &quot;banana&quot;, &quot;cherry&quot;); // 判断元素是否存在 boolean hasBanana = jedis.sismember(&quot;myset&quot;, &quot;banana&quot;); System.out.println(&quot;是否包含 banana: &quot; + hasBanana); // 获取所有成员 Set&lt;String&gt; members = jedis.smembers(&quot;myset&quot;); System.out.println(&quot;当前集合内容: &quot; + members); // 删除元素 jedis.srem(&quot;myset&quot;, &quot;apple&quot;); System.out.println(&quot;删除 apple 后的集合: &quot; + jedis.smembers(&quot;myset&quot;)); } }} 4、HashRedis 的 Hash 类型是一个 键值对集合（map），它的值本身是一个小型字典，适合表示对象（如用户、商品、配置等）。 可以理解为： 12345&quot;user:1001&quot; = { &quot;name&quot;: &quot;Alice&quot;, &quot;age&quot;: &quot;30&quot;, &quot;email&quot;: &quot;alice@example.com&quot;} 命令行： 123456789101112131415161718192021# 设置字段值HSET user:1001 name &quot;Alice&quot;HSET user:1001 age &quot;30&quot;HSET user:1001 email &quot;alice@example.com&quot;# 获取单个字段HGET user:1001 name# -&gt; &quot;Alice&quot;# 获取所有字段HGETALL user:1001# -&gt; name =&gt; Alice, age =&gt; 30, email =&gt; alice@example.com# 获取所有字段名HKEYS user:1001# 获取所有字段值HVALS user:1001# 删除字段HDEL user:1001 email 123456789101112131415161718192021222324252627282930import redis.clients.jedis.Jedis;import java.util.Map;public class RedisHashExample { public static void main(String[] args) { try (Jedis jedis = new Jedis(&quot;localhost&quot;, 6379)) { String key = &quot;user:1001&quot;; // 清空旧数据 jedis.del(key); // 设置字段 jedis.hset(key, &quot;name&quot;, &quot;Alice&quot;); jedis.hset(key, &quot;age&quot;, &quot;30&quot;); jedis.hset(key, &quot;email&quot;, &quot;alice@example.com&quot;); // 获取单个字段 String name = jedis.hget(key, &quot;name&quot;); System.out.println(&quot;Name: &quot; + name); // 获取所有字段和值 Map&lt;String, String&gt; userInfo = jedis.hgetAll(key); System.out.println(&quot;用户信息: &quot; + userInfo); // 删除字段 jedis.hdel(key, &quot;email&quot;); System.out.println(&quot;删除 email 后: &quot; + jedis.hgetAll(key)); } }} 5、ZSETRedis 的 ZSet 是一种带分数的集合，每个元素都关联一个 score（浮点数），元素不可重复，按 score 排序。适合做排行榜、排行榜分页、按权重排序等功能。 12345678910111213141516171819202122232425# 添加元素ZADD leaderboard 100 &quot;Alice&quot;ZADD leaderboard 200 &quot;Bob&quot;ZADD leaderboard 150 &quot;Charlie&quot;# 按分数升序获取成员ZRANGE leaderboard 0 -1 WITHSCORES# -&gt; &quot;Alice&quot; (100), &quot;Charlie&quot; (150), &quot;Bob&quot; (200)# 按分数降序（排行榜）ZREVRANGE leaderboard 0 -1 WITHSCORES# -&gt; &quot;Bob&quot;, &quot;Charlie&quot;, &quot;Alice&quot;# 获取某成员的分数ZSCORE leaderboard &quot;Charlie&quot;# -&gt; 150# 获取某成员的排名（从 0 开始）ZRANK leaderboard &quot;Charlie&quot;# -&gt; 1（升序）ZREVRANK leaderboard &quot;Charlie&quot;# -&gt; 1（降序）# 删除成员ZREM leaderboard &quot;Alice&quot; 12345678910111213141516171819202122232425262728293031323334import redis.clients.jedis.Jedis;import java.util.Set;import redis.clients.jedis.Tuple;public class RedisZSetExample { public static void main(String[] args) { try (Jedis jedis = new Jedis(&quot;localhost&quot;, 6379)) { String key = &quot;leaderboard&quot;; // 清空旧数据 jedis.del(key); // 添加成员和分数 jedis.zadd(key, 100, &quot;Alice&quot;); jedis.zadd(key, 200, &quot;Bob&quot;); jedis.zadd(key, 150, &quot;Charlie&quot;); // 按分数降序输出排行榜 Set&lt;Tuple&gt; leaderboard = jedis.zrevrangeWithScores(key, 0, -1); System.out.println(&quot;排行榜:&quot;); for (Tuple tuple : leaderboard) { System.out.println(tuple.getElement() + &quot; =&gt; &quot; + tuple.getScore()); } // 获取 Charlie 的分数和排名 Double score = jedis.zscore(key, &quot;Charlie&quot;); Long rank = jedis.zrevrank(key, &quot;Charlie&quot;); System.out.println(&quot;Charlie 分数: &quot; + score); System.out.println(&quot;Charlie 排名: 第 &quot; + (rank + 1) + &quot; 名&quot;); } }} 6、StreamRedis 的 Stream（流）类型 是一个功能强大的数据结构，适合做消息队列、事件流、日志处理等任务。 1234567891011# 读取消息（XRANGE / XREAD）,查看 mystream 中的所有消息（- 表示最早，+ 表示最新）XRANGE mystream - +# 添加消息到流（XADD）XADD mystream * sensor-id 1234 temperature 22.5# 作为消费者读取（阻塞式）XREAD COUNT 2 STREAMS mystream 0# XDEL mystream 1687339244000-0XDEL mystream 1687339244000-0 Jredis: 12345678910111213141516171819202122232425262728import redis.clients.jedis.Jedis;import redis.clients.jedis.StreamEntry;import redis.clients.jedis.StreamEntryID;import redis.clients.jedis.StreamPendingEntry;import redis.clients.jedis.StreamEntryList;import java.util.*;public class RedisStreamExample { public static void main(String[] args) { try (Jedis jedis = new Jedis(&quot;localhost&quot;, 6379)) { String streamKey = &quot;mystream&quot;; // 添加消息到 Stream Map&lt;String, String&gt; message = new HashMap&lt;&gt;(); message.put(&quot;sensor-id&quot;, &quot;1234&quot;); message.put(&quot;temperature&quot;, &quot;22.5&quot;); StreamEntryID messageId = jedis.xadd(streamKey, StreamEntryID.NEW_ENTRY, message); System.out.println(&quot;添加消息 ID: &quot; + messageId); // 读取消息 List&lt;StreamEntry&gt; entries = jedis.xrange(streamKey, null, null, 10); for (StreamEntry entry : entries) { System.out.println(&quot;ID: &quot; + entry.getID()); System.out.println(&quot;内容: &quot; + entry.getFields()); } } }}","link":"/2025/05/21/Redis%E5%B8%B8%E8%A7%81%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E4%B8%8E%E4%BD%BF%E7%94%A8/"},{"title":"maven项目常用包","text":"1.Springboot POM模版12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667&lt;project xmlns=&quot;http://maven.apache.org/POM/4.0.0&quot; xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot; xsi:schemaLocation=&quot;http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd&quot;&gt; &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt; &lt;!-- 基础信息 --&gt; &lt;groupId&gt;com.example&lt;/groupId&gt; &lt;artifactId&gt;springboot-demo&lt;/artifactId&gt; &lt;version&gt;0.0.1-SNAPSHOT&lt;/version&gt; &lt;name&gt;Spring Boot Demo&lt;/name&gt; &lt;description&gt;Spring Boot 项目示例&lt;/description&gt; &lt;packaging&gt;jar&lt;/packaging&gt; &lt;!-- 继承 Spring Boot 父 POM（统一依赖管理） --&gt; &lt;parent&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-parent&lt;/artifactId&gt; &lt;version&gt;3.4.3&lt;/version&gt; &lt;relativePath/&gt; &lt;!-- lookup parent from repository --&gt; &lt;/parent&gt; &lt;!-- 项目公共属性 --&gt; &lt;properties&gt; &lt;java.version&gt;17&lt;/java.version&gt; &lt;!-- 推荐使用17或更高 --&gt; &lt;/properties&gt; &lt;!-- 依赖管理 --&gt; &lt;dependencies&gt; &lt;!-- Web 应用 --&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt; &lt;/dependency&gt; &lt;!-- JPA 数据访问 （按需添加）--&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-data-jpa&lt;/artifactId&gt; &lt;/dependency&gt; &lt;!-- H2 数据库 (开发测试用)（按需添加） --&gt; &lt;dependency&gt; &lt;groupId&gt;com.h2database&lt;/groupId&gt; &lt;artifactId&gt;h2&lt;/artifactId&gt; &lt;scope&gt;runtime&lt;/scope&gt; &lt;/dependency&gt; &lt;!-- Spring Boot 测试依赖 --&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-test&lt;/artifactId&gt; &lt;scope&gt;test&lt;/scope&gt; &lt;/dependency&gt; &lt;/dependencies&gt; &lt;build&gt; &lt;plugins&gt; &lt;!-- Spring Boot Maven 插件 --&gt; &lt;plugin&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-maven-plugin&lt;/artifactId&gt; &lt;/plugin&gt; &lt;/plugins&gt; &lt;/build&gt;&lt;/project&gt; 其中，springboot相关的依赖定义具体在，该文件父文件（spring-boot-starter-parent）的父文件spring-boot-dependencies中，本质是个BOM文件 2.Ai-codereview123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;&lt;project xmlns=&quot;http://maven.apache.org/POM/4.0.0&quot; xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot; xsi:schemaLocation=&quot;http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd&quot;&gt; &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt; &lt;groupId&gt;person.symbol&lt;/groupId&gt; &lt;artifactId&gt;ai-code-review&lt;/artifactId&gt; &lt;version&gt;1.0&lt;/version&gt; &lt;packaging&gt;pom&lt;/packaging&gt; &lt;modules&gt; &lt;module&gt;ai-code-review-sdk&lt;/module&gt; &lt;/modules&gt; &lt;properties&gt; &lt;maven.compiler.source&gt;17&lt;/maven.compiler.source&gt; &lt;maven.compiler.target&gt;17&lt;/maven.compiler.target&gt; &lt;project.build.sourceEncoding&gt;UTF-8&lt;/project.build.sourceEncoding&gt; &lt;slf4j.version&gt;2.0.6&lt;/slf4j.version&gt; &lt;/properties&gt; &lt;dependencyManagement&gt; &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;com.google.guava&lt;/groupId&gt; &lt;artifactId&gt;guava&lt;/artifactId&gt; &lt;version&gt;32.1.3-jre&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;commons-lang&lt;/groupId&gt; &lt;artifactId&gt;commons-lang&lt;/artifactId&gt; &lt;version&gt;2.6&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;commons-codec&lt;/groupId&gt; &lt;artifactId&gt;commons-codec&lt;/artifactId&gt; &lt;version&gt;1.15&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;com.alibaba.fastjson2&lt;/groupId&gt; &lt;artifactId&gt;fastjson2&lt;/artifactId&gt; &lt;version&gt;2.0.49&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;junit&lt;/groupId&gt; &lt;artifactId&gt;junit&lt;/artifactId&gt; &lt;version&gt;4.13.1&lt;/version&gt; &lt;scope&gt;test&lt;/scope&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;com.auth0&lt;/groupId&gt; &lt;artifactId&gt;java-jwt&lt;/artifactId&gt; &lt;version&gt;4.2.2&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.eclipse.jgit&lt;/groupId&gt; &lt;artifactId&gt;org.eclipse.jgit&lt;/artifactId&gt; &lt;version&gt;5.13.0.202109080827-r&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.slf4j&lt;/groupId&gt; &lt;artifactId&gt;slf4j-api&lt;/artifactId&gt; &lt;version&gt;${slf4j.version}&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.slf4j&lt;/groupId&gt; &lt;artifactId&gt;slf4j-simple&lt;/artifactId&gt; &lt;version&gt;${slf4j.version}&lt;/version&gt; &lt;/dependency&gt; &lt;/dependencies&gt; &lt;/dependencyManagement&gt;&lt;/project&gt;","link":"/2025/06/10/maven%E9%A1%B9%E7%9B%AE%E5%B8%B8%E7%94%A8%E5%8C%85/"},{"title":"Java包管理与项目构建--maven工具","text":"一、Maven 简介Maven 是 Java 生态中最常用的项目构建和依赖管理工具。它通过统一的项目结构、声明式的依赖配置和插件机制，大大简化了 Java 应用的编译、打包、测试、部署等过程。 简单来说，Maven 的核心功能包括： 依赖管理：自动下载项目依赖的 JAR 包和插件； 生命周期管理：提供标准化的构建流程（如 compile、test、package、install）； 插件机制：通过插件扩展功能，如代码编译、测试、打包为 JAR/WAR 等； 一致性：所有 Maven 项目遵循统一结构和流程，便于协作与维护。 二、Maven 安装在 macOS 上推荐使用brew安装： 1brew install maven 安装完成后可通过以下命令验证： 1mvn -v 如果是手动安装，则从 Apache 官方网站下载并配置环境变量 MAVEN_HOME 及 PATH。 三、配置镜像加速（settings.xml）Maven 默认从中央仓库（Maven Central）下载依赖，速度较慢。可以通过配置镜像加速，例如使用阿里云镜像： 编辑用户目录下的 ~/.m2/settings.xml 文件（如没有可手动创建）： 12345678910&lt;settings xmlns=&quot;http://maven.apache.org/SETTINGS/1.0.0&quot;&gt; &lt;mirrors&gt; &lt;mirror&gt; &lt;id&gt;aliyun&lt;/id&gt; &lt;mirrorOf&gt;central&lt;/mirrorOf&gt; &lt;name&gt;Aliyun Maven Mirror&lt;/name&gt; &lt;url&gt;https://maven.aliyun.com/repository/public&lt;/url&gt; &lt;/mirror&gt; &lt;/mirrors&gt;&lt;/settings&gt; 该配置对所有 Maven 项目生效，与项目目录无关。 四、仓库概念 本地仓库：~/.m2/repository，缓存已下载的依赖，避免重复下载。 远程仓库： 中央仓库（Central）：Maven 官方托管的公共依赖仓库。 私有仓库：如公司内部搭建的 Nexus、Artifactory、Harbor 等，用于存储自定义或私有依赖。 五、常用 Maven 命令123456mvn clean # 清除 target 目录mvn compile # 编译源码mvn package # 打包生成 JAR/WARmvn install # 安装到本地仓库供其他项目使用mvn test # 执行测试代码mvn dependency:resolve # 解析并下载依赖 Maven 命令默认对当前目录生效，会从当前或其父目录中查找最近的 pom.xml 文件，作为项目入口。如果找不到，会报错。 在多模块项目中，若希望构建某个子模块，需要 cd 到该子模块目录； 若希望构建整个项目，则在根目录（父 POM 所在位置）执行命令即可自动构建所有模块。 六、POM 文件结构简述Maven 的配置核心是 pom.xml（Project Object Model 文件），其基本结构如下： 12345678910111213141516171819&lt;project&gt; &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt; &lt;groupId&gt;com.example&lt;/groupId&gt; &lt;!-- 组织唯一标识，如公司域名倒写； --&gt; &lt;artifactId&gt;demo-app&lt;/artifactId&gt; &lt;!-- 项目名称 --&gt; &lt;version&gt;1.0.0&lt;/version&gt; &lt;dependencies&gt; &lt;!-- 项目依赖 --&gt; &lt;/dependencies&gt; &lt;build&gt; &lt;plugins&gt; &lt;!-- 构建插件 --&gt; &lt;/plugins&gt; &lt;/build&gt; &lt;/project&gt; 父子模块结构：父 POM.xml 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586878889909192939495&lt;project xmlns=&quot;http://maven.apache.org/POM/4.0.0&quot; xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot; xsi:schemaLocation=&quot;http://maven.apache.org/POM/4.0.0 https://maven.apache.org/xsd/maven-4.0.0.xsd&quot;&gt; &lt;!-- 使用的 POM 模型版本 --&gt; &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt; &lt;!-- 父项目的 GAV 坐标 --&gt; &lt;groupId&gt;com.example&lt;/groupId&gt; &lt;artifactId&gt;my-app&lt;/artifactId&gt; &lt;version&gt;1.0.0&lt;/version&gt; &lt;packaging&gt;pom&lt;/packaging&gt; &lt;!-- 聚合项目需要设置为 pom --&gt; &lt;!-- 项目信息 --&gt; &lt;name&gt;My Application&lt;/name&gt; &lt;description&gt;项目描述&lt;/description&gt; &lt;!-- 子模块列表 --&gt; &lt;modules&gt; &lt;module&gt;module1&lt;/module&gt; &lt;!-- 指定包含的模块 --&gt; &lt;/modules&gt; &lt;!-- 公共属性（可在子模块中引用） --&gt; &lt;properties&gt; &lt;maven.compiler.source&gt;17&lt;/maven.compiler.source&gt; &lt;maven.compiler.target&gt;17&lt;/maven.compiler.target&gt; &lt;project.build.sourceEncoding&gt;UTF-8&lt;/project.build.sourceEncoding&gt; &lt;spring-ai.version&gt;1.0.0-M6&lt;/spring-ai.version&gt; &lt;spring-boot.version&gt;3.4.3&lt;/spring-boot.version&gt; &lt;/properties&gt; &lt;!-- 统一管理依赖版本，子模块引用时不必声明版本号 --&gt; &lt;dependencyManagement&gt; &lt;dependencies&gt; &lt;!-- 普通的版本声明 --&gt; &lt;dependency&gt; &lt;groupId&gt;com.alibaba&lt;/groupId&gt; &lt;artifactId&gt;fastjson&lt;/artifactId&gt; &lt;version&gt;2.0.28&lt;/version&gt; &lt;/dependency&gt; &lt;!-- BOM（Bill of Materials）：统一引入 spring-ai 各模块的版本控制。 非JAR包，只用来规定相关模块的统一版本，使用 scope=import 表示将这个 POM 的依 赖版本信息“导入”进当前项目。注意：BOM只能引入在dependencyManagement中 子模块可以只写 groupId 和 artifactId，不必每次都写 version。 --&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.ai&lt;/groupId&gt; &lt;artifactId&gt;spring-ai-bom&lt;/artifactId&gt; &lt;version&gt;${spring-ai.version}&lt;/version&gt; &lt;type&gt;pom&lt;/type&gt; &lt;scope&gt;import&lt;/scope&gt; &lt;/dependency&gt; &lt;/dependencies&gt; &lt;/dependencyManagement&gt; &lt;!-- 统一插件版本管理 --&gt; &lt;pluginManagement&gt; &lt;plugins&gt; &lt;plugin&gt; &lt;groupId&gt;org.apache.maven.plugins&lt;/groupId&gt; &lt;artifactId&gt;maven-surefire-plugin&lt;/artifactId&gt; &lt;version&gt;3.1.2&lt;/version&gt; &lt;/plugin&gt; &lt;/plugins&gt; &lt;/pluginManagement&gt; &lt;!-- 远程仓库配置（如阿里云） --&gt; &lt;repositories&gt; &lt;repository&gt; &lt;id&gt;aliyun-central&lt;/id&gt; &lt;url&gt;https://maven.aliyun.com/repository/public&lt;/url&gt; &lt;/repository&gt; &lt;/repositories&gt; &lt;!-- 构建环境配置，可通过 -P 选择激活 --&gt; &lt;profiles&gt; &lt;profile&gt; &lt;id&gt;dev&lt;/id&gt; &lt;activation&gt; &lt;activeByDefault&gt;true&lt;/activeByDefault&gt; &lt;!-- 默认激活 --&gt; &lt;/activation&gt; &lt;properties&gt; &lt;env&gt;development&lt;/env&gt; &lt;/properties&gt; &lt;/profile&gt; &lt;profile&gt; &lt;id&gt;prod&lt;/id&gt; &lt;properties&gt; &lt;env&gt;production&lt;/env&gt; &lt;/properties&gt; &lt;/profile&gt; &lt;/profiles&gt;&lt;/project&gt; 子文件： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960&lt;project xmlns=&quot;http://maven.apache.org/POM/4.0.0&quot; xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot; xsi:schemaLocation=&quot;http://maven.apache.org/POM/4.0.0 https://maven.apache.org/xsd/maven-4.0.0.xsd&quot;&gt; &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt; &lt;!-- 继承父项目 --&gt; &lt;parent&gt; &lt;groupId&gt;com.example&lt;/groupId&gt; &lt;artifactId&gt;my-app&lt;/artifactId&gt; &lt;version&gt;1.0.0&lt;/version&gt; &lt;/parent&gt; &lt;!-- 本模块信息 --&gt; &lt;artifactId&gt;com.example&lt;/artifactId&gt; &lt;name&gt;模块名&lt;/name&gt; &lt;description&gt;模块描述&lt;/description&gt; &lt;!-- 本模块的依赖 --&gt; &lt;dependencies&gt; &lt;!-- Spring --&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.ai&lt;/groupId&gt; &lt;artifactId&gt;spring-ai-mcp-server-spring-boot-starter&lt;/artifactId&gt; &lt;/dependency&gt; &lt;!-- JSON 序列化组件 --&gt; &lt;dependency&gt; &lt;groupId&gt;com.alibaba&lt;/groupId&gt; &lt;artifactId&gt;fastjson&lt;/artifactId&gt; &lt;/dependency&gt; &lt;!-- Lombok 插件 --&gt; &lt;dependency&gt; &lt;groupId&gt;org.projectlombok&lt;/groupId&gt; &lt;artifactId&gt;lombok&lt;/artifactId&gt; &lt;version&gt;1.18.38&lt;/version&gt; &lt;!-- 独有，可单独指定 --&gt; &lt;/dependency&gt; &lt;/dependencies&gt; &lt;!-- 构建配置 --&gt; &lt;build&gt; &lt;!-- 资源文件配置 --&gt; &lt;resources&gt; &lt;resource&gt; &lt;directory&gt;src/main/resources&lt;/directory&gt; &lt;includes&gt; &lt;include&gt;**/*.yml&lt;/include&gt; &lt;include&gt;**/*.properties&lt;/include&gt; &lt;/includes&gt; &lt;/resource&gt; &lt;/resources&gt; &lt;!-- 插件配置 --&gt; &lt;plugins&gt; &lt;/plugins&gt; &lt;/build&gt;&lt;/project&gt;","link":"/2025/06/11/Java%E5%8C%85%E7%AE%A1%E7%90%86%E4%B8%8E%E9%A1%B9%E7%9B%AE%E6%9E%84%E5%BB%BA-maven%E5%B7%A5%E5%85%B7/"}],"tags":[{"name":"刷题","slug":"刷题","link":"/tags/%E5%88%B7%E9%A2%98/"},{"name":"数据库","slug":"数据库","link":"/tags/%E6%95%B0%E6%8D%AE%E5%BA%93/"},{"name":"DHCP","slug":"DHCP","link":"/tags/DHCP/"},{"name":"JVM","slug":"JVM","link":"/tags/JVM/"},{"name":"socket","slug":"socket","link":"/tags/socket/"},{"name":"linux","slug":"linux","link":"/tags/linux/"},{"name":"文件锁","slug":"文件锁","link":"/tags/%E6%96%87%E4%BB%B6%E9%94%81/"},{"name":"redis","slug":"redis","link":"/tags/redis/"},{"name":"javaSE","slug":"javaSE","link":"/tags/javaSE/"},{"name":"Spring","slug":"Spring","link":"/tags/Spring/"},{"name":"typora添加数学公式","slug":"typora添加数学公式","link":"/tags/typora%E6%B7%BB%E5%8A%A0%E6%95%B0%E5%AD%A6%E5%85%AC%E5%BC%8F/"},{"name":"UnixDomainSocket","slug":"UnixDomainSocket","link":"/tags/UnixDomainSocket/"},{"name":"c语言","slug":"c语言","link":"/tags/c%E8%AF%AD%E8%A8%80/"},{"name":"conda","slug":"conda","link":"/tags/conda/"},{"name":"cmake","slug":"cmake","link":"/tags/cmake/"},{"name":"face_recogntion","slug":"face-recogntion","link":"/tags/face-recogntion/"},{"name":"未分类","slug":"未分类","link":"/tags/%E6%9C%AA%E5%88%86%E7%B1%BB/"},{"name":"git","slug":"git","link":"/tags/git/"},{"name":"hexo博客","slug":"hexo博客","link":"/tags/hexo%E5%8D%9A%E5%AE%A2/"},{"name":"hexo","slug":"hexo","link":"/tags/hexo/"},{"name":"组播","slug":"组播","link":"/tags/%E7%BB%84%E6%92%AD/"},{"name":"密码学","slug":"密码学","link":"/tags/%E5%AF%86%E7%A0%81%E5%AD%A6/"},{"name":"self-attention","slug":"self-attention","link":"/tags/self-attention/"},{"name":"cross-attention","slug":"cross-attention","link":"/tags/cross-attention/"},{"name":"transformer","slug":"transformer","link":"/tags/transformer/"},{"name":"Java","slug":"Java","link":"/tags/Java/"},{"name":"网络抓包","slug":"网络抓包","link":"/tags/%E7%BD%91%E7%BB%9C%E6%8A%93%E5%8C%85/"},{"name":"unix xv6","slug":"unix-xv6","link":"/tags/unix-xv6/"},{"name":"回调函数","slug":"回调函数","link":"/tags/%E5%9B%9E%E8%B0%83%E5%87%BD%E6%95%B0/"},{"name":"yaml","slug":"yaml","link":"/tags/yaml/"},{"name":"共享内存","slug":"共享内存","link":"/tags/%E5%85%B1%E4%BA%AB%E5%86%85%E5%AD%98/"},{"name":"布隆过滤器","slug":"布隆过滤器","link":"/tags/%E5%B8%83%E9%9A%86%E8%BF%87%E6%BB%A4%E5%99%A8/"},{"name":"工具图","slug":"工具图","link":"/tags/%E5%B7%A5%E5%85%B7%E5%9B%BE/"},{"name":"编译与链接","slug":"编译与链接","link":"/tags/%E7%BC%96%E8%AF%91%E4%B8%8E%E9%93%BE%E6%8E%A5/"},{"name":"JUC","slug":"JUC","link":"/tags/JUC/"},{"name":"DB","slug":"DB","link":"/tags/DB/"},{"name":"Redis","slug":"Redis","link":"/tags/Redis/"},{"name":"Maven","slug":"Maven","link":"/tags/Maven/"}],"categories":[{"name":"Linux C编程","slug":"Linux-C编程","link":"/categories/Linux-C%E7%BC%96%E7%A8%8B/"},{"name":"hexo","slug":"hexo","link":"/categories/hexo/"},{"name":"网络","slug":"网络","link":"/categories/%E7%BD%91%E7%BB%9C/"},{"name":"深度学习","slug":"深度学习","link":"/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"},{"name":"密码学","slug":"网络/密码学","link":"/categories/%E7%BD%91%E7%BB%9C/%E5%AF%86%E7%A0%81%E5%AD%A6/"},{"name":"未分类","slug":"未分类","link":"/categories/%E6%9C%AA%E5%88%86%E7%B1%BB/"},{"name":"工具图","slug":"工具图","link":"/categories/%E5%B7%A5%E5%85%B7%E5%9B%BE/"}]}